{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project  - Ecommerce    \n",
    "## Prepared and Submitted By: Saroj Kumar Bisi\n",
    "\n",
    "**DESCRIPTION**\n",
    "\n",
    "**Problem Statement**\n",
    "\n",
    " * Amazon is an online shopping website that now caters to millions of people everywhere. Over 34,000 consumer reviews for Amazon brand products like Kindle, Fire TV Stick and more are provided.\n",
    " \n",
    " * The dataset has attributes like brand, categories, primary categories, reviews.title, reviews.text, and the sentiment. Sentiment is a categorical variable with three levels \"Positive\", \"Negative“, and \"Neutral\". For a given unseen data, the sentiment needs to be predicted. \n",
    " \n",
    " * You are required to predict Sentiment or Satisfaction of a purchase based on multiple features and review text.\n",
    "\n",
    "**Data Snapshot**\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix,classification_report,roc_auc_score,roc_curve,f1_score,accuracy_score\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier,XGBRFClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import nltk\n",
    "import gensim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Task: Week 1\n",
    "\n",
    "**Class Imbalance Problem:**\n",
    "\n",
    "1. Perform an EDA on the dataset\n",
    "         \n",
    "    a. See what a positive, negative, and neutral review looks like.\n",
    "    \n",
    "    b. Check the class count for each class. It’s a class imbalance problem.\n",
    "    \n",
    "2. Convert the reviews into Tf-Idf Document Term Matrix \n",
    "\n",
    "3. Run multinomial Naive Bayes classifier. Everything will be classified as positive because of the class imbalance.\n",
    "\n",
    "\n",
    "### Code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load  Data\n",
    "train=pd.read_csv('train_data.csv')\n",
    "test_hidden=pd.read_csv('test_data_hidden.csv')\n",
    "test=pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of train data:  (4000, 8)\n",
      "the shape of test data:  (1000, 7)\n",
      "the shape of test_hidden data:  (1000, 8)\n"
     ]
    }
   ],
   "source": [
    "print('the shape of train data: ', train.shape)\n",
    "print('the shape of test data: ', test.shape)\n",
    "print('the shape of test_hidden data: ', test_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>primaryCategories</th>\n",
       "      <th>reviews.date</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All-New Fire HD 8 Tablet, 8\" HD Display, Wi-Fi...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2016-12-26T00:00:00.000Z</td>\n",
       "      <td>Purchased on Black FridayPros - Great Price (e...</td>\n",
       "      <td>Powerful tablet</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name   brand  \\\n",
       "0  All-New Fire HD 8 Tablet, 8\" HD Display, Wi-Fi...  Amazon   \n",
       "\n",
       "                                          categories primaryCategories  \\\n",
       "0  Electronics,iPad & Tablets,All Tablets,Fire Ta...       Electronics   \n",
       "\n",
       "               reviews.date  \\\n",
       "0  2016-12-26T00:00:00.000Z   \n",
       "\n",
       "                                        reviews.text    reviews.title  \\\n",
       "0  Purchased on Black FridayPros - Great Price (e...  Powerful tablet   \n",
       "\n",
       "  sentiment  \n",
       "0  Positive  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>primaryCategories</th>\n",
       "      <th>reviews.date</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fire Tablet, 7 Display, Wi-Fi, 16 GB - Include...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Fire Tablets,Computers/Tablets &amp; Networking,Ta...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2016-05-23T00:00:00.000Z</td>\n",
       "      <td>Amazon kindle fire has a lot of free app and c...</td>\n",
       "      <td>very handy device</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name   brand  \\\n",
       "0  Fire Tablet, 7 Display, Wi-Fi, 16 GB - Include...  Amazon   \n",
       "\n",
       "                                          categories primaryCategories  \\\n",
       "0  Fire Tablets,Computers/Tablets & Networking,Ta...       Electronics   \n",
       "\n",
       "               reviews.date  \\\n",
       "0  2016-05-23T00:00:00.000Z   \n",
       "\n",
       "                                        reviews.text      reviews.title  \n",
       "0  Amazon kindle fire has a lot of free app and c...  very handy device  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>primaryCategories</th>\n",
       "      <th>reviews.date</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fire Tablet, 7 Display, Wi-Fi, 16 GB - Include...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Fire Tablets,Computers/Tablets &amp; Networking,Ta...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2016-05-23T00:00:00.000Z</td>\n",
       "      <td>Amazon kindle fire has a lot of free app and c...</td>\n",
       "      <td>very handy device</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name   brand  \\\n",
       "0  Fire Tablet, 7 Display, Wi-Fi, 16 GB - Include...  Amazon   \n",
       "\n",
       "                                          categories primaryCategories  \\\n",
       "0  Fire Tablets,Computers/Tablets & Networking,Ta...       Electronics   \n",
       "\n",
       "               reviews.date  \\\n",
       "0  2016-05-23T00:00:00.000Z   \n",
       "\n",
       "                                        reviews.text      reviews.title  \\\n",
       "0  Amazon kindle fire has a lot of free app and c...  very handy device   \n",
       "\n",
       "  sentiment  \n",
       "0  Positive  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hidden.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of merged data is:  (5000, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>primaryCategories</th>\n",
       "      <th>reviews.date</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All-New Fire HD 8 Tablet, 8\" HD Display, Wi-Fi...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2016-12-26T00:00:00.000Z</td>\n",
       "      <td>Purchased on Black FridayPros - Great Price (e...</td>\n",
       "      <td>Powerful tablet</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon - Echo Plus w/ Built-In Hub - Silver</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Echo,Smart Home,Networking,Home &amp; Tools...</td>\n",
       "      <td>Electronics,Hardware</td>\n",
       "      <td>2018-01-17T00:00:00.000Z</td>\n",
       "      <td>I purchased two Amazon in Echo Plus and two do...</td>\n",
       "      <td>Amazon Echo Plus AWESOME</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon Echo Show Alexa-enabled Bluetooth Speak...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Echo,Virtual Assistant Speakers,Electro...</td>\n",
       "      <td>Electronics,Hardware</td>\n",
       "      <td>2017-12-20T00:00:00.000Z</td>\n",
       "      <td>Just an average Alexa option. Does show a few ...</td>\n",
       "      <td>Average</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fire HD 10 Tablet, 10.1 HD Display, Wi-Fi, 16 ...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>eBook Readers,Fire Tablets,Electronics Feature...</td>\n",
       "      <td>Office Supplies,Electronics</td>\n",
       "      <td>2017-08-04T00:00:00.000Z</td>\n",
       "      <td>very good product. Exactly what I wanted, and ...</td>\n",
       "      <td>Greattttttt</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brand New Amazon Kindle Fire 16gb 7\" Ips Displ...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Computers/Tablets &amp; Networking,Tablets &amp; eBook...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2017-01-23T00:00:00.000Z</td>\n",
       "      <td>This is the 3rd one I've purchased. I've bough...</td>\n",
       "      <td>Very durable!</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name   brand  \\\n",
       "0  All-New Fire HD 8 Tablet, 8\" HD Display, Wi-Fi...  Amazon   \n",
       "1        Amazon - Echo Plus w/ Built-In Hub - Silver  Amazon   \n",
       "2  Amazon Echo Show Alexa-enabled Bluetooth Speak...  Amazon   \n",
       "3  Fire HD 10 Tablet, 10.1 HD Display, Wi-Fi, 16 ...  Amazon   \n",
       "4  Brand New Amazon Kindle Fire 16gb 7\" Ips Displ...  Amazon   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "1  Amazon Echo,Smart Home,Networking,Home & Tools...   \n",
       "2  Amazon Echo,Virtual Assistant Speakers,Electro...   \n",
       "3  eBook Readers,Fire Tablets,Electronics Feature...   \n",
       "4  Computers/Tablets & Networking,Tablets & eBook...   \n",
       "\n",
       "             primaryCategories              reviews.date  \\\n",
       "0                  Electronics  2016-12-26T00:00:00.000Z   \n",
       "1         Electronics,Hardware  2018-01-17T00:00:00.000Z   \n",
       "2         Electronics,Hardware  2017-12-20T00:00:00.000Z   \n",
       "3  Office Supplies,Electronics  2017-08-04T00:00:00.000Z   \n",
       "4                  Electronics  2017-01-23T00:00:00.000Z   \n",
       "\n",
       "                                        reviews.text  \\\n",
       "0  Purchased on Black FridayPros - Great Price (e...   \n",
       "1  I purchased two Amazon in Echo Plus and two do...   \n",
       "2  Just an average Alexa option. Does show a few ...   \n",
       "3  very good product. Exactly what I wanted, and ...   \n",
       "4  This is the 3rd one I've purchased. I've bough...   \n",
       "\n",
       "              reviews.title sentiment  \n",
       "0           Powerful tablet  Positive  \n",
       "1  Amazon Echo Plus AWESOME  Positive  \n",
       "2                   Average   Neutral  \n",
       "3               Greattttttt  Positive  \n",
       "4             Very durable!  Positive  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the train0 and train_hidden0 are having same features its good to merge them together and perform the EDA\n",
    "#Data merge\n",
    "dataSet=pd.concat([train,test_hidden])\n",
    "print('shape of merged data is: ',dataSet.shape)\n",
    "dataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Purchased on Black FridayPros - Great Price (e...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I purchased two Amazon in Echo Plus and two do...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just an average Alexa option. Does show a few ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>very good product. Exactly what I wanted, and ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is the 3rd one I've purchased. I've bough...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        reviews.text sentiment\n",
       "0  Purchased on Black FridayPros - Great Price (e...  Positive\n",
       "1  I purchased two Amazon in Echo Plus and two do...  Positive\n",
       "2  Just an average Alexa option. Does show a few ...   Neutral\n",
       "3  very good product. Exactly what I wanted, and ...  Positive\n",
       "4  This is the 3rd one I've purchased. I've bough...  Positive"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets take only relevent columns for the analysis(reviews.text and sentiment)\n",
    "dataSet=dataSet[['reviews.text','sentiment']]\n",
    "dataSet.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   reviews.text  5000 non-null   object\n",
      " 1   sentiment     5000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 117.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dataSet.info() # There is no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    4686\n",
       "Neutral      197\n",
       "Negative     117\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2af23ae4148>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Check for data imbalance\n",
    "sns.countplot(x='sentiment',data=dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see from above figure It’s a class imbalance problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing function\n",
    "def text_preprocessing(df):\n",
    "\n",
    "    #step1.Converting to list for easy manipulation\n",
    "    reviews_list=df['reviews.text'].values\n",
    "    print('Text Preprocessing Step-1:Converting to list for easy manipulation \\n',reviews_list[0],'\\n')\n",
    "\n",
    "    #step2.standardize the case into lowercase\n",
    "    reviews_list=[doc.lower() for doc in reviews_list]\n",
    "\n",
    "    #step3.Tokenize\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    tokenized_reviews=[word_tokenize(doc) for doc in reviews_list]\n",
    "\n",
    "    print('Text Preprocessing Step-2&3:Word standardize and Tokenize \\n',tokenized_reviews[0],'\\n')\n",
    "\n",
    "    ###step4.Import stop words and punctuations\n",
    "    from nltk.corpus import stopwords\n",
    "    from string import punctuation\n",
    "    nltk_stop=stopwords.words('english')\n",
    "    punct=list(punctuation)\n",
    "\n",
    "    stop_punct=nltk_stop+punct #combine stop waords and punctuations\n",
    "\n",
    "    #print('Text Preprocessing Step-4:stop words and punctuations list \\n',stop_punct,'\\n')\n",
    "\n",
    "\n",
    "    ###step5.Remove stop words and punctuations from the tokenized_reviews\n",
    "    def del_stop(sent):\n",
    "        return [term for term in sent if term not in stop_punct]\n",
    "\n",
    "    reviews_nonstop = [del_stop(doc) for doc in tokenized_reviews]\n",
    "    print('Text Preprocessing Step-5:Remove stop words and punctuations \\n',reviews_nonstop[0],'\\n')\n",
    "\n",
    "\n",
    "    #Stemming OR Lemmatize depending on the need\n",
    "    #Stemming\n",
    "    #from nltk.stem import PorterStemmer\n",
    "    #stemmer = PorterStemmer()\n",
    "\n",
    "    #stemmed_docs=[]\n",
    "    #for terms in reviews_nonstop:\n",
    "        #stemmed_docs.append([stemmer.stem(word) for word in terms])\n",
    "\n",
    "    #print(stemmed_docs[0])\n",
    "\n",
    "    #step.6.Lemmatize\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "    lemmatized_docs=[]\n",
    "    for terms in reviews_nonstop:\n",
    "        lemmatized_docs.append([lemmatizer.lemmatize(word) for word in terms])\n",
    "\n",
    "    print('Text Preprocessing Step-6:lemmatized_docs \\n',lemmatized_docs[0],'\\n')\n",
    "\n",
    "    ##step7.Delete numeric tokens. \n",
    "    import re\n",
    "    def del_numeric(doc):\n",
    "        clean_docs=[]\n",
    "        for each_token in doc:\n",
    "            if re.search('[a-zA-Z]', each_token):\n",
    "                 clean_docs.append(each_token)\n",
    "        return clean_docs \n",
    "\n",
    "    reviews_clean = [del_numeric(sent) for sent in lemmatized_docs]\n",
    "\n",
    "    print('Text Preprocessing Step-7:Delete numeric tokens \\n',reviews_clean[0],'\\n')\n",
    "\n",
    "    ###step8.Creating back the Clean documents\n",
    "    clean_docs = [\" \".join(sent) for sent in reviews_clean]\n",
    "\n",
    "    print('Text Preprocessing Step-8:Clean  documents \\n',clean_docs[0],'\\n')\n",
    "    return clean_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Preprocessing for Train Data , Test Data and  on Train+Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing Step-1:Converting to list for easy manipulation \n",
      " Purchased on Black FridayPros - Great Price (even off sale)Very powerful and fast with quad core processors Amazing soundWell builtCons -Amazon ads, Amazon need this to subsidize the tablet and will remove the adds if you pay them $15.Inability to access other apps except the ones from Amazon. There is a way which I was able to accomplish to add the Google Play storeNet this is a great tablet for the money \n",
      "\n",
      "Text Preprocessing Step-2&3:Word standardize and Tokenize \n",
      " ['purchased', 'on', 'black', 'fridaypros', '-', 'great', 'price', '(', 'even', 'off', 'sale', ')', 'very', 'powerful', 'and', 'fast', 'with', 'quad', 'core', 'processors', 'amazing', 'soundwell', 'builtcons', '-amazon', 'ads', ',', 'amazon', 'need', 'this', 'to', 'subsidize', 'the', 'tablet', 'and', 'will', 'remove', 'the', 'adds', 'if', 'you', 'pay', 'them', '$', '15.inability', 'to', 'access', 'other', 'apps', 'except', 'the', 'ones', 'from', 'amazon', '.', 'there', 'is', 'a', 'way', 'which', 'i', 'was', 'able', 'to', 'accomplish', 'to', 'add', 'the', 'google', 'play', 'storenet', 'this', 'is', 'a', 'great', 'tablet', 'for', 'the', 'money'] \n",
      "\n",
      "Text Preprocessing Step-5:Remove stop words and punctuations \n",
      " ['purchased', 'black', 'fridaypros', 'great', 'price', 'even', 'sale', 'powerful', 'fast', 'quad', 'core', 'processors', 'amazing', 'soundwell', 'builtcons', '-amazon', 'ads', 'amazon', 'need', 'subsidize', 'tablet', 'remove', 'adds', 'pay', '15.inability', 'access', 'apps', 'except', 'ones', 'amazon', 'way', 'able', 'accomplish', 'add', 'google', 'play', 'storenet', 'great', 'tablet', 'money'] \n",
      "\n",
      "Text Preprocessing Step-6:lemmatized_docs \n",
      " ['purchased', 'black', 'fridaypros', 'great', 'price', 'even', 'sale', 'powerful', 'fast', 'quad', 'core', 'processor', 'amazing', 'soundwell', 'builtcons', '-amazon', 'ad', 'amazon', 'need', 'subsidize', 'tablet', 'remove', 'add', 'pay', '15.inability', 'access', 'apps', 'except', 'one', 'amazon', 'way', 'able', 'accomplish', 'add', 'google', 'play', 'storenet', 'great', 'tablet', 'money'] \n",
      "\n",
      "Text Preprocessing Step-7:Delete numeric tokens \n",
      " ['purchased', 'black', 'fridaypros', 'great', 'price', 'even', 'sale', 'powerful', 'fast', 'quad', 'core', 'processor', 'amazing', 'soundwell', 'builtcons', '-amazon', 'ad', 'amazon', 'need', 'subsidize', 'tablet', 'remove', 'add', 'pay', '15.inability', 'access', 'apps', 'except', 'one', 'amazon', 'way', 'able', 'accomplish', 'add', 'google', 'play', 'storenet', 'great', 'tablet', 'money'] \n",
      "\n",
      "Text Preprocessing Step-8:Clean  documents \n",
      " purchased black fridaypros great price even sale powerful fast quad core processor amazing soundwell builtcons -amazon ad amazon need subsidize tablet remove add pay 15.inability access apps except one amazon way able accomplish add google play storenet great tablet money \n",
      "\n",
      "Text Preprocessing Step-1:Converting to list for easy manipulation \n",
      " Amazon kindle fire has a lot of free app and can be used by any one that wants to get online anywhere \n",
      "\n",
      "Text Preprocessing Step-2&3:Word standardize and Tokenize \n",
      " ['amazon', 'kindle', 'fire', 'has', 'a', 'lot', 'of', 'free', 'app', 'and', 'can', 'be', 'used', 'by', 'any', 'one', 'that', 'wants', 'to', 'get', 'online', 'anywhere'] \n",
      "\n",
      "Text Preprocessing Step-5:Remove stop words and punctuations \n",
      " ['amazon', 'kindle', 'fire', 'lot', 'free', 'app', 'used', 'one', 'wants', 'get', 'online', 'anywhere'] \n",
      "\n",
      "Text Preprocessing Step-6:lemmatized_docs \n",
      " ['amazon', 'kindle', 'fire', 'lot', 'free', 'app', 'used', 'one', 'want', 'get', 'online', 'anywhere'] \n",
      "\n",
      "Text Preprocessing Step-7:Delete numeric tokens \n",
      " ['amazon', 'kindle', 'fire', 'lot', 'free', 'app', 'used', 'one', 'want', 'get', 'online', 'anywhere'] \n",
      "\n",
      "Text Preprocessing Step-8:Clean  documents \n",
      " amazon kindle fire lot free app used one want get online anywhere \n",
      "\n",
      "Text Preprocessing Step-1:Converting to list for easy manipulation \n",
      " Purchased on Black FridayPros - Great Price (even off sale)Very powerful and fast with quad core processors Amazing soundWell builtCons -Amazon ads, Amazon need this to subsidize the tablet and will remove the adds if you pay them $15.Inability to access other apps except the ones from Amazon. There is a way which I was able to accomplish to add the Google Play storeNet this is a great tablet for the money \n",
      "\n",
      "Text Preprocessing Step-2&3:Word standardize and Tokenize \n",
      " ['purchased', 'on', 'black', 'fridaypros', '-', 'great', 'price', '(', 'even', 'off', 'sale', ')', 'very', 'powerful', 'and', 'fast', 'with', 'quad', 'core', 'processors', 'amazing', 'soundwell', 'builtcons', '-amazon', 'ads', ',', 'amazon', 'need', 'this', 'to', 'subsidize', 'the', 'tablet', 'and', 'will', 'remove', 'the', 'adds', 'if', 'you', 'pay', 'them', '$', '15.inability', 'to', 'access', 'other', 'apps', 'except', 'the', 'ones', 'from', 'amazon', '.', 'there', 'is', 'a', 'way', 'which', 'i', 'was', 'able', 'to', 'accomplish', 'to', 'add', 'the', 'google', 'play', 'storenet', 'this', 'is', 'a', 'great', 'tablet', 'for', 'the', 'money'] \n",
      "\n",
      "Text Preprocessing Step-5:Remove stop words and punctuations \n",
      " ['purchased', 'black', 'fridaypros', 'great', 'price', 'even', 'sale', 'powerful', 'fast', 'quad', 'core', 'processors', 'amazing', 'soundwell', 'builtcons', '-amazon', 'ads', 'amazon', 'need', 'subsidize', 'tablet', 'remove', 'adds', 'pay', '15.inability', 'access', 'apps', 'except', 'ones', 'amazon', 'way', 'able', 'accomplish', 'add', 'google', 'play', 'storenet', 'great', 'tablet', 'money'] \n",
      "\n",
      "Text Preprocessing Step-6:lemmatized_docs \n",
      " ['purchased', 'black', 'fridaypros', 'great', 'price', 'even', 'sale', 'powerful', 'fast', 'quad', 'core', 'processor', 'amazing', 'soundwell', 'builtcons', '-amazon', 'ad', 'amazon', 'need', 'subsidize', 'tablet', 'remove', 'add', 'pay', '15.inability', 'access', 'apps', 'except', 'one', 'amazon', 'way', 'able', 'accomplish', 'add', 'google', 'play', 'storenet', 'great', 'tablet', 'money'] \n",
      "\n",
      "Text Preprocessing Step-7:Delete numeric tokens \n",
      " ['purchased', 'black', 'fridaypros', 'great', 'price', 'even', 'sale', 'powerful', 'fast', 'quad', 'core', 'processor', 'amazing', 'soundwell', 'builtcons', '-amazon', 'ad', 'amazon', 'need', 'subsidize', 'tablet', 'remove', 'add', 'pay', '15.inability', 'access', 'apps', 'except', 'one', 'amazon', 'way', 'able', 'accomplish', 'add', 'google', 'play', 'storenet', 'great', 'tablet', 'money'] \n",
      "\n",
      "Text Preprocessing Step-8:Clean  documents \n",
      " purchased black fridaypros great price even sale powerful fast quad core processor amazing soundwell builtcons -amazon ad amazon need subsidize tablet remove add pay 15.inability access apps except one amazon way able accomplish add google play storenet great tablet money \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lets take only relevent columns for the preprocessing of Train Data(reviews.text and sentiment)\n",
    "traindata=train[['reviews.text','sentiment']]\n",
    "\n",
    "train_clean_reviews=text_preprocessing(traindata)\n",
    "\n",
    "#Lets take only relevent columns for the preprocessing of Test Data (reviews.text and sentiment)\n",
    "testdata=test_hidden[['reviews.text','sentiment']]\n",
    "\n",
    "test_clean_reviews=text_preprocessing(testdata)\n",
    "\n",
    "#Lets take only relevent columns for the preprocessing of Full Dataset (reviews.text and sentiment)\n",
    "fulldata=dataSet[['reviews.text','sentiment']]\n",
    "\n",
    "fulldata_clean_reviews=text_preprocessing(fulldata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Preprocessing for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing Step-1:Converting to list for easy manipulation \n",
      " Amazon kindle fire has a lot of free app and can be used by any one that wants to get online anywhere \n",
      "\n",
      "Text Preprocessing Step-2&3:Word standardize and Tokenize \n",
      " ['amazon', 'kindle', 'fire', 'has', 'a', 'lot', 'of', 'free', 'app', 'and', 'can', 'be', 'used', 'by', 'any', 'one', 'that', 'wants', 'to', 'get', 'online', 'anywhere'] \n",
      "\n",
      "Text Preprocessing Step-5:Remove stop words and punctuations \n",
      " ['amazon', 'kindle', 'fire', 'lot', 'free', 'app', 'used', 'one', 'wants', 'get', 'online', 'anywhere'] \n",
      "\n",
      "Text Preprocessing Step-6:lemmatized_docs \n",
      " ['amazon', 'kindle', 'fire', 'lot', 'free', 'app', 'used', 'one', 'want', 'get', 'online', 'anywhere'] \n",
      "\n",
      "Text Preprocessing Step-7:Delete numeric tokens \n",
      " ['amazon', 'kindle', 'fire', 'lot', 'free', 'app', 'used', 'one', 'want', 'get', 'online', 'anywhere'] \n",
      "\n",
      "Text Preprocessing Step-8:Clean  documents \n",
      " amazon kindle fire lot free app used one want get online anywhere \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lets take only relevent columns for the preprocessing (reviews.text and sentiment)\n",
    "testdata=test_hidden[['reviews.text','sentiment']]\n",
    "\n",
    "test_clean_reviews=text_preprocessing(testdata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare for X_train,X_test,y_train and y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of X_train and  y_train:  4000 (4000,)\n",
      "the shape of X_test and  y_test:  1000 (1000,)\n"
     ]
    }
   ],
   "source": [
    "X_train=train_clean_reviews\n",
    "X_test=test_clean_reviews\n",
    "y_train=train['sentiment']\n",
    "y_test=test_hidden['sentiment']\n",
    "\n",
    "print('the shape of X_train and  y_train: ', len(X_train), y_train.shape)\n",
    "print('the shape of X_test and  y_test: ', len(X_test),y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Document term matrix using TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 4342), (1000, 4342))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Prepare Document term matrix using TfIdf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features = 4500)\n",
    "\n",
    "# Model fitting\n",
    "X_train_ds =vectorizer.fit(X_train)\n",
    "X_train_bow = vectorizer.transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "X_train_bow.shape, X_test_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>10</th>\n",
       "      <th>10th</th>\n",
       "      <th>10x</th>\n",
       "      <th>11yr</th>\n",
       "      <th>128gb</th>\n",
       "      <th>13th</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16g</th>\n",
       "      <th>...</th>\n",
       "      <th>äôve</th>\n",
       "      <th>äù</th>\n",
       "      <th>äúalexa</th>\n",
       "      <th>äúbest</th>\n",
       "      <th>äúdropping</th>\n",
       "      <th>äúdual</th>\n",
       "      <th>äúshow</th>\n",
       "      <th>äúskills</th>\n",
       "      <th>äústar</th>\n",
       "      <th>äúthings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.219932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4342 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00   10  10th  10x  11yr  128gb  13th   14        15  16g  ...  äôve   äù  \\\n",
       "0  0.0  0.0   0.0  0.0   0.0    0.0   0.0  0.0  0.219932  0.0  ...   0.0  0.0   \n",
       "1  0.0  0.0   0.0  0.0   0.0    0.0   0.0  0.0  0.000000  0.0  ...   0.0  0.0   \n",
       "2  0.0  0.0   0.0  0.0   0.0    0.0   0.0  0.0  0.000000  0.0  ...   0.0  0.0   \n",
       "3  0.0  0.0   0.0  0.0   0.0    0.0   0.0  0.0  0.000000  0.0  ...   0.0  0.0   \n",
       "4  0.0  0.0   0.0  0.0   0.0    0.0   0.0  0.0  0.000000  0.0  ...   0.0  0.0   \n",
       "\n",
       "   äúalexa  äúbest  äúdropping  äúdual  äúshow  äúskills  äústar  äúthings  \n",
       "0      0.0     0.0         0.0     0.0     0.0       0.0     0.0       0.0  \n",
       "1      0.0     0.0         0.0     0.0     0.0       0.0     0.0       0.0  \n",
       "2      0.0     0.0         0.0     0.0     0.0       0.0     0.0       0.0  \n",
       "3      0.0     0.0         0.0     0.0     0.0       0.0     0.0       0.0  \n",
       "4      0.0     0.0         0.0     0.0     0.0       0.0     0.0       0.0  \n",
       "\n",
       "[5 rows x 4342 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the document vector matrix into dataframe (OPTIONAl Step..this is just to see the data)\n",
    "features_name=X_train_ds.get_feature_names()\n",
    "train_df=pd.DataFrame(X_train_bow.todense(),columns=features_name)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model building and testing using multinomial Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score is:0.93725 and test score is: 0.937\n",
      "classification_report TRAIN Data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00        93\n",
      "     Neutral       0.00      0.00      0.00       158\n",
      "    Positive       0.94      1.00      0.97      3749\n",
      "\n",
      "    accuracy                           0.94      4000\n",
      "   macro avg       0.31      0.33      0.32      4000\n",
      "weighted avg       0.88      0.94      0.91      4000\n",
      "\n",
      "classification_report TEST Data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00        24\n",
      "     Neutral       0.00      0.00      0.00        39\n",
      "    Positive       0.94      1.00      0.97       937\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.31      0.33      0.32      1000\n",
      "weighted avg       0.88      0.94      0.91      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model building using multinomial Naive Bayes classifier\n",
    "model_MNB = MultinomialNB()\n",
    "model_MNB.fit( X_train_bow.toarray(),y_train)\n",
    "\n",
    "#Get Train and Test Accuracy Score\n",
    "train_score=model_MNB.score(X_train_bow.toarray(),y_train)\n",
    "test_score=model_MNB.score(X_test_bow.toarray(),y_test)\n",
    "print('train score is:{} and test score is: {}'.format(train_score,test_score))\n",
    "\n",
    "#Get precision    recall  and f1-score\n",
    "cr=classification_report(y_true=y_train,y_pred=model_MNB.predict( X_train_bow.toarray() ))\n",
    "print('classification_report TRAIN Data\\n',cr)\n",
    "\n",
    "#Get precision    recall  and f1-score\n",
    "cr=classification_report(y_true=y_test,y_pred=model_MNB.predict( X_test_bow.toarray() ))\n",
    "print('classification_report TEST Data\\n',cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "test_ds_predicted = model_MNB.predict( X_test_bow.toarray() )\n",
    "test_ds_predicted[0:50]\n",
    "\n",
    "# as seen belw :Everything is  predicted as positive because of the class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation - 1\n",
    "\n",
    "> Everything is  predicted as positive because of the class imbalance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Task: Week 2\n",
    "\n",
    "**Tackling Class Imbalance Problem:**\n",
    "    \n",
    "1. Oversampling or undersampling can be used to tackle the class imbalance problem. \n",
    "\n",
    "2. In case of class imbalance criteria, use the following metrices for evaluating model performance: precision, recall, F1-score, AUC-ROC curve. Use F1-Score as the evaluation criteria for this project.\n",
    "\n",
    "3. Use Tree-based classifiers like Random Forest and XGBoost.\n",
    "\n",
    "**Note**: Tree-based classifiers work on two ideologies namely, Bagging or Boosting and have fine-tuning parameter which takes care of the imbalanced class\n",
    "\n",
    "\n",
    "### Code :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code for over sampling approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of X_train_bow and y_train before Oversampling 4000 4000\n",
      "length of X_test_bow and y_test before Oversampling 1000 1000\n",
      "length of X_train_bow and y_train after Oversampling 11247 11247\n",
      "length of X_test_bow and y_test after Oversampling 2811 2811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2af245c4748>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "print('length of X_train_bow and y_train before Oversampling',X_train_bow.shape[0],len(y_train))\n",
    "print('length of X_test_bow and y_test before Oversampling',X_test_bow.shape[0],len(y_test))\n",
    "\n",
    "OS=SMOTE(random_state=42)\n",
    "X_train_bow_OS,y_train_OS=OS.fit_resample(X_train_bow,y_train)\n",
    "X_test_bow_OS,y_test_OS=OS.fit_resample(X_test_bow,y_test)\n",
    "\n",
    "print('length of X_train_bow and y_train after Oversampling',X_train_bow_OS.shape[0],len(y_train_OS))\n",
    "\n",
    "print('length of X_test_bow and y_test after Oversampling',X_test_bow_OS.shape[0],len(y_test_OS))\n",
    "\n",
    "#Check for data balance\n",
    "sns.countplot(x=y_train_OS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code for under sampling approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of X_train_bow and y_train before Undersampling 4000 4000\n",
      "length of X_test_bow and y_test before Undersampling 1000 1000\n",
      "length of X_train_bow and y_train after Undersampling 279 279\n",
      "length of X_test_bow and y_test after Undersampling 72 72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2af19cf0ec8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQ0ElEQVR4nO3de5BkZX3G8e8DC3JRBNzRKKsuMajBG5ctFFGLiEXQRLmIt4pmJRiMiSASEtFYSjSWUKBoiGXcgLAkXiCAAqaCEgIRNS7uIsoCUQgiIgiDYlTEy+Ivf/QZaWZnd3vGPTPMvt9PVVf3eftcfjPv9NNnTp/zdqoKSVI7NpvrAiRJs8vgl6TGGPyS1BiDX5IaY/BLUmMWzHUBo1i4cGEtXrx4rsuQpHll1apVd1XV2OT2eRH8ixcvZuXKlXNdhiTNK0m+PVW7h3okqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4Jakx8+LK3enY86/OmusSNnmrTvrj3tZ9y7ue1tu6NfC4d1zTy3r3OXWfXtar+33xyC9ulPW4xy9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9Jjek1+JO8Ocm1SVYn+USSrZLsnGRFkhuSnJ1kyz5rkCQ9UG/Bn2Qn4ChgSVU9FdgceCVwInBKVe0C3A0c3lcNkqS19X2oZwGwdZIFwDbA7cDzgXO755cDB/VcgyRpSG/BX1XfBU4GbmEQ+P8HrAJ+WFVrutluBXaaavkkRyRZmWTl+Ph4X2VKUnP6PNSzA3AgsDPwGGBb4IVTzFpTLV9Vy6pqSVUtGRsb66tMSWpOn4d6XgB8q6rGq+qXwPnAs4Htu0M/AIuA23qsQZI0SZ/BfwvwrCTbJAmwH3AdcBlwaDfPUuCCHmuQJE3S5zH+FQw+xL0KuKbb1jLgLcAxSW4EHgGc3lcNkqS1LdjwLDNXVe8E3jmp+SZgrz63K0laN6/claTGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGtNr8CfZPsm5Sf4nyfVJ9k6yY5JLktzQ3e/QZw2SpAfqe4//g8DFVfVk4BnA9cBxwKVVtQtwaTctSZolvQV/ku2A5wGnA1TVL6rqh8CBwPJutuXAQX3VIElaW597/L8NjANnJPlqktOSbAs8qqpuB+juHznVwkmOSLIyycrx8fEey5SktvQZ/AuAPYAPV9XuwD1M47BOVS2rqiVVtWRsbKyvGiWpOX0G/63ArVW1ops+l8EbwR1JHg3Q3d/ZYw2SpEl6C/6q+h7wnSRP6pr2A64DLgSWdm1LgQv6qkGStLYFPa//SOBjSbYEbgIOY/Bmc06Sw4FbgJf1XIMkaUivwV9VVwNLpnhqvz63K0laN6/claTGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDVmpOBPcukobZKkB7/1XrmbZCtgG2Bh901Z6Z7aDnhMz7VJknqwoSEbXg8czSDkV3F/8P8I+FCPdUmSerLe4K+qDwIfTHJkVZ06SzVJkno00iBtVXVqkmcDi4eXqaqzeqpLktSTkYI/yT8DTwCuBu7rmgsw+CVpnhl1WOYlwK5VVX0WI0nq36jn8a8GfqvPQiRJs2PUPf6FwHVJrgR+PtFYVS/ppSpJUm9GDf7j+yxCkjR7Rj2r57/6LkSSNDtGPavnxwzO4gHYEtgCuKeqtuurMElSP0bd43/Y8HSSg4C9eqlIktSrGY3OWVWfBp6/kWuRJM2CUQ/1HDI0uRmD8/o9p1+S5qFRz+p58dDjNcDNwIEbvRpJUu9GPcZ/WN+FSJJmx6hfxLIoyaeS3JnkjiTnJVnUd3GSpI1v1A93zwAuZDAu/07ARV2bJGmeGTX4x6rqjKpa093OBMZ6rEuS1JNRg/+uJK9Osnl3ezXw/T4LkyT1Y9Tg/xPg5cD3gNuBQwE/8JWkeWjU0znfDSytqrsBkuwInMzgDUGSNI+Musf/9InQB6iqHwC791OSJKlPowb/Zkl2mJjo9vhH/W9BkvQgMmp4vw/4UpJzGQzV8HLgPb1VJUnqzahX7p6VZCWDgdkCHFJV1/VamSSpFyMfrumC3rCXpHluRsMyT0d33v9Xk3ymm945yYokNyQ5O8mWfdcgSbpf78EPvAm4fmj6ROCUqtoFuBs4fBZqkCR1eg3+biC3PwBO66bD4HOCc7tZlgMH9VmDJOmB+t7j/wDw18CvuulHAD+sqjXd9K0MBn1bS5IjkqxMsnJ8fLznMiWpHb0Ff5I/BO6sqlXDzVPMOuU3eVXVsqpaUlVLxsYcD06SNpY+L8LaB3hJkhcBWwHbMfgPYPskC7q9/kXAbT3WIEmapLc9/qp6a1UtqqrFwCuB/6yqPwIuYzDIG8BS4IK+apAkrW02zuqZ7C3AMUluZHDM//Q5qEGSmjUr4+1U1eXA5d3jm4C9ZmO7kqS1zcUevyRpDhn8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhrTW/AneWySy5Jcn+TaJG/q2ndMckmSG7r7HfqqQZK0tj73+NcAf1lVvws8C/iLJLsCxwGXVtUuwKXdtCRplvQW/FV1e1Vd1T3+MXA9sBNwILC8m205cFBfNUiS1jYrx/iTLAZ2B1YAj6qq22Hw5gA8ch3LHJFkZZKV4+Pjs1GmJDWh9+BP8lDgPODoqvrRqMtV1bKqWlJVS8bGxvorUJIa02vwJ9mCQeh/rKrO75rvSPLo7vlHA3f2WYMk6YH6PKsnwOnA9VX1/qGnLgSWdo+XAhf0VYMkaW0Lelz3PsBrgGuSXN21vQ04ATgnyeHALcDLeqxBkjRJb8FfVV8Aso6n9+tru5Kk9fPKXUlqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1Zk6CP8kBSb6R5MYkx81FDZLUqlkP/iSbAx8CXgjsCrwqya6zXYcktWou9vj3Am6sqpuq6hfAJ4ED56AOSWpSqmp2N5gcChxQVa/rpl8DPLOq3jhpviOAI7rJJwHfmNVCZ9dC4K65LkIzYt/Nb5t6/z2+qsYmNy6Yg0IyRdta7z5VtQxY1n85cy/JyqpaMtd1aPrsu/mt1f6bi0M9twKPHZpeBNw2B3VIUpPmIvi/AuySZOckWwKvBC6cgzokqUmzfqinqtYkeSPwWWBz4KNVde1s1/Eg08QhrU2UfTe/Ndl/s/7hriRpbnnlriQ1xuCXpMYY/NOQpJK8b2j62CTH97Cdt02a/tLG3oY2bn8m2T7Jn89w2ZuTLJzJsi1Kcl+Sq5OsTvKvSbaZwTpOmxgxoMXXm8E/PT8HDpmFF+kD/hCr6tk9b69VG7M/twemDP5umBJtPPdW1W5V9VTgF8CfTXcFVfW6qrqum2zu9WbwT88aBmcBvHnyE0nGkpyX5CvdbZ+h9kuSXJXkI0m+PRE0ST6dZFWSa7srlUlyArB1t0fzsa7tJ9392UleNLTNM5O8NMnmSU7qtvv1JK/v/TexaZhJfx6f5Nih+VYnWQycADyh67eTkuyb5LIkHweu6eZdq7/1G7sC+B2AJMd0/bE6ydFd27ZJ/i3J17r2V3TtlydZ0uzrraq8jXgDfgJsB9wMPBw4Fji+e+7jwHO6x48Dru8e/wPw1u7xAQyuUl7YTe/Y3W8NrAYeMbGdydvt7g8GlnePtwS+0y17BPD2rv0hwEpg57n+fT3YbzPsz+OBY4fWsRpY3N1WD7XvC9wz3A/r6e+bJ/4mvI3Wb939AuAC4A3AngzeYLcFHgpcC+wOvBT4p6FlH97dXw4sGV7fFOvfZF9vczFkw7xWVT9KchZwFHDv0FMvAHZNfj0ixXZJHgY8h8EfEFV1cZK7h5Y5KsnB3ePHArsA31/P5v8d+PskD2HwJvL5qro3yf7A07txkGAQYrsA35rpz9mKGfTndFxZVcN9MN3+1tS2TnJ19/gK4HQG4f+pqroHIMn5wHOBi4GTk5wIfKaqrpjGdjbZ15vBPzMfAK4Czhhq2wzYu6qGw4MMJcek9n0ZhMveVfXTJJcDW61vo1X1s26+3wdeAXxiYnXAkVX12Wn/JILp9ecaHniIdH19ds/Qcvsyzf7WOt1bVbsNN6zrdVZV30yyJ/Ai4L1JPldV7xplI5vy681j/DNQVT8AzgEOH2r+HPDrEUaTTPxhfgF4ede2P7BD1/5w4O4uBJ4MPGtoXb9MssU6Nv9J4DAGezMTf3ifBd4wsUySJybZdoY/XnOm2Z83A3t0bXsAO3ftPwbW9x/B+vpbv7nPAwcl2ab72z8YuCLJY4CfVtW/ACfT9d0kzb3eDP6Zex+DIV0nHAUs6T7suY77zzT4W2D/JFcx+PKZ2xmExMXAgiRfB94NfHloXcuAr0982DTJ54DnAf9Rg+8zADgNuA64Kslq4CP439x0jdqf5wE7doca3gB8E6Cqvg98sfsA8aQp1r++/tZvqKquAs4ErgRWAKdV1VeBpwFXdv31N8DfTbF4c683h2zoWXd88L4ajFG0N/Dhyf+mStJsmlfvUvPU44BzkmzG4JzjP53jeiQ1zj1+SWqMx/glqTEGvyQ1xuCXpMYY/NIGJNlt0pgtL0lyXM/b3DfJJj9YmOaGwS9t2G4MrvwEoKourKoTet7mvoDBr154Vo82ad0VlecAixh8x/O7gRuB9zMYzOsu4LVVdXt3ef4K4PcYDLN8eDd9I4PBub4LvLd7vKSq3pjkTAZj/DwZeDyDqzyXAnsDK6rqtV0d+zO4mO8hwP8Ch1XVT5LcDCwHXgxsAbwM+BmDC7zuA8YZDA8wnTFmpPVyj1+bugOA26rqGTUYv/1i4FTg0KraE/go8J6h+RdU1V7A0cA7u6s13wGcXYMx4M+eYhs7AM9nMLzzRcApwFOAp3WHiRYCbwdeUFV7MBjN8Zih5e/q2j/MYOTPm4F/BE7ptmnoa6PyAi5t6q5haHRG4G7gqcAl3bhemzMYRmPC+d39KgZDLY/ioqqqJNcAd1TVxPj713brWATsymBIBxgM8fvf69jmIdP42aQZMfi1SZs8OiNwCXBtVe29jkV+3t3fx+ivj4llfjX0eGJ6QbeuS6rqVRtxm9KMeahHm7QpRmd8JjDWjZtEki2SPGUDq9nQyJsb8mVgnyQT3xS1TZIn9rxNaZ0Mfm3qJo/O+A7gUODEJF8DrmbDZ89cxuBLWa6e+Oq+6aiqceC1wCe60Tm/zODD4PW5CDi42+Zzp7tNaX08q0eSGuMevyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9Jjfl/aCa2UAqrodIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler,NearMiss\n",
    "print('length of X_train_bow and y_train before Undersampling',X_train_bow.shape[0],len(y_train))\n",
    "print('length of X_test_bow and y_test before Undersampling',X_test_bow.shape[0],len(y_test))\n",
    "\n",
    "US=NearMiss()\n",
    "X_train_bow_US,y_train_US=US.fit_resample(X_train_bow,y_train)\n",
    "X_test_bow_US,y_test_US=US.fit_resample(X_test_bow,y_test)\n",
    "\n",
    "print('length of X_train_bow and y_train after Undersampling',X_train_bow_US.shape[0],len(y_train_US))\n",
    "print('length of X_test_bow and y_test after Undersampling',X_test_bow_US.shape[0],len(y_test_US))\n",
    "\n",
    "#Check for data balance\n",
    "sns.countplot(x=y_train_US)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach-1: Use of multinomial Naive Bayes classifier with Oversampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score is:0.9718147061438606 \n",
      "test score is:0.6125933831376734 \n",
      "classification_report TRAIN Data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.98      1.00      0.99      3749\n",
      "     Neutral       0.95      1.00      0.97      3749\n",
      "    Positive       1.00      0.92      0.96      3749\n",
      "\n",
      "    accuracy                           0.97     11247\n",
      "   macro avg       0.97      0.97      0.97     11247\n",
      "weighted avg       0.97      0.97      0.97     11247\n",
      "\n",
      "classification_report TEST Data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.87      0.53      0.66       937\n",
      "     Neutral       0.61      0.43      0.51       937\n",
      "    Positive       0.52      0.88      0.65       937\n",
      "\n",
      "    accuracy                           0.61      2811\n",
      "   macro avg       0.67      0.61      0.61      2811\n",
      "weighted avg       0.67      0.61      0.61      2811\n",
      "\n",
      "Wall time: 929 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Model building using multinomial Naive Bayes classifier\n",
    "model_MNB_OS = MultinomialNB()\n",
    "model_MNB_OS.fit( X_train_bow_OS.toarray(),y_train_OS)\n",
    "\n",
    "#Get Train and Test Accuracy Score\n",
    "train_score=model_MNB_OS.score(X_train_bow_OS.toarray(),y_train_OS)\n",
    "test_score=model_MNB_OS.score(X_test_bow_OS.toarray(),y_test_OS)\n",
    "print('train score is:{} '.format(train_score))\n",
    "print('test score is:{} '.format(test_score))\n",
    "\n",
    "#Get precision    recall  and f1-score on Train data\n",
    "cr=classification_report(y_true=y_train_OS,y_pred=model_MNB_OS.predict( X_train_bow_OS.toarray() ))\n",
    "print('classification_report TRAIN Data\\n',cr)\n",
    "\n",
    "#Get precision    recall  and f1-score on Test data\n",
    "cr=classification_report(y_true=y_test_OS,y_pred=model_MNB_OS.predict( X_test_bow_OS.toarray() ))\n",
    "print('classification_report TEST Data\\n',cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Neutral', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Neutral',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Positive'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "test_ds_predicted = model_MNB_OS.predict( X_test_bow_OS.toarray() )\n",
    "test_ds_predicted[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare  roc and auc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score: 0.8979081265967248\n",
      "roc_auc_score: 0.7256622955935802\n",
      "roc_auc_score: 0.8987834422399881\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxV5Z3H8c8vYQ2EJYQ1EAKEfVEwgqJVEERwo1pqUWvV2tLN6Uw7VXCtSxfH1qWdcbRYsdoZlxZEo2C1WhEXEOKWQARkJ4R9CZCQkOWZP27i3MZAbsi599zl+369eHlv7uHe3yHh68NznvN7zDmHiIjEviS/CxAREW8o0EVE4oQCXUQkTijQRUTihAJdRCROtPDrg9PT011WVpZfHy8iEpM+/PDDvc65rg295lugZ2VlkZeX59fHi4jEJDPbcrzXNOUiIhInFOgiInFCgS4iEicU6CIicUKBLiISJxoNdDObZ2a7zWzVcV43M/u9ma03s3wzG+N9mSIi0phQRuh/Aqae4PVpwMDaX7OAR5tfloiINFWj69Cdc0vNLOsEh0wHnnaBPrzLzayTmfV0zu3wqEYRkcjIexIK5oft7audo7K6hja9T4Vp93n+/l7MoWcA24KeF9V+7UvMbJaZ5ZlZ3p49ezz4aBERj+Q9Ca/8G2x5NyxvX3K0kvyig6zbdRhHePah8OJOUWvgaw1W65ybC8wFyMnJ0c4aIuKv4BF5XZBf/DDkXO/ZR5QcreTXiz/jubXbyOqSwn1fG4X17+LZ+wfzItCLgD5Bz3sDxR68r4iI9xoK8b5nB36NnOFpmFfXOL726Pts3HOE753bn59MHkSblsmevX99XgR6LnCjmT0HjANKNH8uIr460Vx4mEMc4EDpMTqltCQ5yfjZlMH06tSGUb07efoZDWk00M3sWWACkG5mRcDPgZYAzrnHgMXAhcB6oAzw9k9GRCRYKBcug0O7vjCFOIBzjhc/2c7dLxcye+oQrhybydQRPTz/nOMJZZXLlY287oAfeVaRiCSmUFeYnCis64QxtI+n+OBRbltYwFtr9zA6sxM5fTtH7LPr+NY+V0QShJdBXfd6hMO6MS99sp3bFq6iusZx58XDuHZ8FslJDa0XCS8Fuoh4q36Ax3BQh6pj25ac2qcTv758JH3SUnyrQ4EuIs3TWIDHcFAfT1V1DU+8u4nK6hpuPG8gEwZ349xBXTGL/Kg8mAJdRJomAQM8WGHxIWYvyKdgewkXjeqJcw4z8z3MQYEuIo1J8ACvU1FVzX/9Yz2PLtlAp5SW/PfVY5g2okdUBHkdBbqIBBzv4mWCBnh9m/eW8djbG7j01F7ccdEwOrdr5XdJX6JAF5GAgvmwswB6jPznrydogAOUVlTx98JdfHV0BoN7pPLmTyeQ2cW/i56NUaCLyP/rMRKuX+R3FVHhnc/3cMsLBWw/eJQRGR3I7pYa1WEO2rFIRCAw3RKmLoOxpqSskpvnf8o1T6ygVXISz886k+xuqX6XFRKN0EUSXV3bWAhMrSSw6hrH1x57n017S/nhhAH8eNLAsDbT8poCXSSRBYe5x21jY8n+0mN0ahtopnXTBYPJ6NSWERkd/S6ryTTlIpKoFOY451jwYRETf7uE51YG9um5YHiPmAxz0AhdJPHULU8M04YOsaLoQBm3LlzF0nV7OK1vZ8b2S/O7pGZToIskivpBnsDLERd+XMTtC1fhgLsvHc41Z/QlyYdmWl5ToIvEOwX5l6S1a81pWWn86rIR9O4c3UsRm0KBLhKvFORfqKyu4fF3NlJV7fjxpIGcO6gr5wxMj6rb9r2gQBeJFyfquZKgQQ6wansJsxfks7r4EJec0iuqmml5TYEuEg+CV6wkeM+VOuWV1fz+zc/5w9KNdE5pxWPfHMPUET39LiusFOgisaqh3esTdMVKQ7bsK+PxdzZy+egMbr9oGB1TWvpdUtgp0EViUf0ReYKPxuuUVlTx2uqdXD6mN4N7pPKPf5/g6w5CkaZAF4kVGpGf0Nvr9nDrCwUUlxxlVO+OZHdLTagwBwW6SPRraLWKRuRfOFB6jHsXFfLCR9sZ0LUdf/1e7DTT8poCXSSa1Z9aUYj/k7pmWlv2lXHjxGxuPC87ppppeU2BLhKt1GvluPYdqaBzSiuSk4w5U4eQ0bktw3vFZv8VL6k5l0g0Upg3yDnHX/K2MfG3S3h25VYApgzvoTCvpRG6SDRR46zj2ra/jFsXFvDO53sZm5XGmf27+F1S1FGgi/hJd3eG5IWPirj9xVUYcO9XR3D12My4aKblNQW6iF90d2fI0tu3Zmy/NH552UgyOrX1u5yopUAXiSStJQ9JZXUNf3h7A9U18K+TB3LOoK6cM6ir32VFPQW6SCRoLXnIVm0v4ab5+Xy24xDTT/3/ZlrSOAW6SCQUzIedBQrxEyivrObhNz7n8Xc2ktauFX+45jQuGN7D77JiSkiBbmZTgd8BycAfnXP31Xs9E3gK6FR7zBzn3GKPaxWJTXlPBkbmfc+G6xf5XU3U2rq/jCfe3ciMMb259cKhCdFMy2uNBrqZJQOPAOcDRcBKM8t1zhUGHXY78Bfn3KNmNgxYDGSFoV6R2NDQXPnIGf7VE6UOl1fyt1U7+XpOHwZ1T+Wtn02Iqx2EIi2UEfpYYL1zbiOAmT0HTAeCA90BHWofdwSKvSxSJKaoE2JI3lqzm9sWFrDzUDmjMzuR3S1VYd5MoQR6BrAt6HkRMK7eMXcBr5vZvwDtgMkNvZGZzQJmAWRmZja1VpHoppuCQrK/9Bj3vlLIwo+3M7Bbe+b/YHzCNtPyWiiB3tDlZVfv+ZXAn5xzD5jZmcCfzWyEc67mn36Tc3OBuQA5OTn130MkNmnvzpBV1zhmPPo+W/eX8eNJA/nRxAG0bpG4zbS8FkqgFwF9gp735stTKjcAUwGcc8vMrA2QDuz2okiRqKVuiCHZc7iCLu0CzbRuvXAoGZ3bMrRnh8Z/ozRJKM25VgIDzayfmbUCZgK59Y7ZCkwCMLOhQBtgj5eFikSd+g20rl+kMK/HOcfzK7dy3gNLeGZFoJnW5GHdFeZh0ugI3TlXZWY3Aq8RWJI4zzm32szuAfKcc7nAvwOPm9lPCEzHXOec05SKxC91Q2zU1n1lzHkhn/c37GNcvzTOzk73u6S4F9I69No15Yvrfe3OoMeFwFneliYShXThMyTzPyzijhdXkZxk/PKyEVx5upppRYLuFBVpTENryjVffkLdO7Rm/IAu/OKyEfTsqGZakaJAF6nvRC1tFeQNOlZVw6NLNlDjHD85fxBfGdiVrwxUM61IU6CLBFNL2yb7dNtBbp6fz9pdh7l8dIaaaflIgS5SRxc6m+TosWoe/Ptannh3E91S2/DHb+UweVh3v8tKaAp0EVCYn4RtB8p46v0tzBybyZxpQ+jQRs20/KZAl8SlzSaa7FBtM60raptpLblpAr20g1DUUKBL4tFmEyflH2t2cesLq9h9uJwxmZ3J7tZeYR5lFOgS3+qvWAEtPWyifUcquOeVQl76pJjB3VN57JrTyO7W3u+ypAEKdIlfDa1YqXusIA9JdY3j648tY9uBMn4yeRA/mDCAVi1C6RgiflCgS/w43vpxzYs32e7D5aS3a01yknHbRUPp3TmFwT3U4jbaKdAl9jU0J173X43Em6SmxvHsyq38evEaZk8bwjVn9GXSUC1FjBUKdIltal/rmc17S5nzQj7LN+5n/IAunKs7PWOOAl1il9aOe+Yvedu448VVtEpO4r7LR/KN0/vobs8YpECX2KQw91RGp7acM6gr904fQY+ObfwuR06SAl1ih24E8kxFVTX//dYGnHP8dMpgzspO5yz1K495CnSJDfXnyjVfftI+3nqA2QvyWbfrCF8b01vNtOKIAl2in6ZXPFF2rIoHXl/HvPc20aNDG+Zdl8N5Q7SCJZ4o0CV6aXcgT20/cJQ/L9/C1eMymT11CKlqphV3FOgSfRpaV67plZNScrSSVwt2MHNsJgO7p/L2TRO0g1AcU6BLdNG6cs+8vnont7+4in2lx8jJSiO7W3uFeZxToEt00PSKZ/YeqeCu3NW8kr+DIT1S+eO1OWqmlSAU6OIvTa94qrrGMePR9yk+WM7Ppgzie+cOoGWymmklCgW6+EfTK57Zdaicru0DzbR+fslwenduy8DuaqaVaBTo4g8tRfRETY3jf1ds5T9eXcPsqYO55swsJg7p5ndZ4hMFukSewtwTG/ccYc4LBazYtJ+zs9OZMFhBnugU6BJZCnNPPL9yK3e+tJrWLZK4f8Yovn5ab93tKQp0iRCtYvFU784pTBgcaKbVrYOaaUmAAl3CTxc/m62iqpr/fHM9AD+7QM20pGEKdAkfjco98eGW/dw8P58Ne0q5IkfNtOT4FOgSHhqVN1tpRRW/eW0tTy3bTK+ObXnq22M5d5B2EZLjCynQzWwq8DsgGfijc+6+Bo65ArgLcMCnzrmrPKxTYoVG5Z4pPniUZ1Zs5Vtn9OWmqUNo31rjLzmxRn9CzCwZeAQ4HygCVppZrnOuMOiYgcAtwFnOuQNmpvVTiUZ3fHqipKySRQU7uGpcoJnWOzdPpLsuekqIQvlf/lhgvXNuI4CZPQdMBwqDjvku8Ihz7gCAc26314VKFNP0iif+tmond7y0iv2lxxjXP40BXdsrzKVJQgn0DGBb0PMiYFy9YwYBmNl7BKZl7nLO/a3+G5nZLGAWQGZm5snUK34L3gaujqZXmmX34XLuyl3N4oKdDOvZgSevO50BXdVMS5oulEBv6HK6a+B9BgITgN7AO2Y2wjl38J9+k3NzgbkAOTk59d9DolH9AA+eUqmjUflJq65xXPHYMopLyrnpgsHMOqe/mmnJSQsl0IuAPkHPewPFDRyz3DlXCWwys7UEAn6lJ1WKfwrmw84C6DEy8Fzh7YkdJUfpntom0Ezr0uH06ZyiFrfSbKEE+kpgoJn1A7YDM4H6K1heBK4E/mRm6QSmYDZ6WahEWN3IvC7Mr1/kd0VxoabG8fSyzdz/2lrmTBvCt87MYqJ6sIhHGg1051yVmd0IvEZgfnyec261md0D5Dnncmtfm2JmhUA1cJNzbl84C5cwaugipzTb+t1HmLMgn7wtBzhnUFfOU1dE8Zg5589Udk5OjsvLy/Pls+U4tIY8bJ5bsZU7c1fTtmUyd148jMvHZOhuTzkpZvahcy6nodd0p0IiO9EFT82TeyqzSwqTh3bj7ktH0DW1td/lSJxSoCeihm4CqvuvgtwT5ZXV/P7NzwG4eeoQxg9IZ/wANdOS8FKgJxLdzRkReZv3c/OCfDbuKWXm6X3UTEsiRoGeCBTkEXGkoorf/G0NTy/fQkantjz97bGco2ZaEkEK9ERQt/xQQR5WO0uO8tzKbVx7ZhY3XTCYdmqmJRGmn7hEobXkYXGg9BivFOzgmjP6kt0t0ExLOwiJXxTo8S7vycBUS/Ct+tJszjleXbWTO19axcGySsYP6MKAru0V5uIrBXo8C75BSDcHeWb3oXLueGkVr63exciMjjz97XFqpiVRQYEez+rWmOsGIc9U1zi+/odl7Cwp55ZpQ7jh7H60UDMtiRIK9HjX92yFuQeKDx6lR4dAM617po+gT+e29NeoXKKMhhbxqm7uXJqlusbx5HubmPTA2/zPB1sAOHdQV4W5RCWN0ONN/TXnmjs/aet3H+bm+fl8tPUgEwZ3ZdLQ7n6XJHJCCvR4ozXnnnjmg63clbuadq2Teegbp/DVU9VMS6KfAj1eqH+5p7LSU5gyvDt3XTqc9PZqpiWxQYEey4K7Jda/rV+apLyymofeWIdhzJmmZloSmxTosaChjZnhn0NcUywn7YON+5jzQgGb9pZy9bhMNdOSmKVAj3b1dw8KphBvlsPllfzH39bwP8u3kpmWwjPfGcf4bI3KJXYp0P12vNF3He0eFDa7DlUw/8MivnN2P346ZRAprfTXQWKbfoL9cLy574ZoFO6p/aXHWJRfzDVnZpHdrT3v3HyedhCSuKFAj7T6UygK7IhwzvFK/g7uyl3NofJKzspOp3/X9gpziSsK9EjRBsy+2XWonNsWruKNz3YxqndH/nfGON3pKXFJgR5OJ1pWqDCPiOoaxxW1zbRuu3Ao15+VpWZaErcU6OEUfKOPgjyiig6U0bNjW5KTjHunjyAzLYWs9HZ+lyUSVgr0cAneWEJ3bUZMXTOt376+llumDeXa8Vna11MShgI9HLSxhC/W7jzMzQvy+XTbQSYN6caU4WqmJYlFge614DDXhc+I+Z/lW7j75dWktmnJ72aeyqWn9NLdnpJwFOheUphHXN1t+tnd2nPhyJ7cefEwuqiZliQoBboXtCQx4o4eq+bBv68lKcm4ZdpQzujfhTP6d/G7LBFfKdBPlpYk+mbZhn3MeSGfLfvKuOaMvmqmJVJLgd5U9UfjutszYg6VV/LrxWt4dsVW+nZJ4ZnvjlOLW5EgCvRQNRTkCvGI2n2oghc/3s6sc/rzk8mDaNsq2e+SRKJKSIFuZlOB3wHJwB+dc/cd57gZwF+B051zeZ5V6bf6/VcU5BGz70gFL39azHVn9SO7W3venT1RFz1FjqPRQDezZOAR4HygCFhpZrnOucJ6x6UCPwY+CEehvtHKFV8458j9tJi7cldzpKKKcwZ1pX/X9gpzkRMIZYQ+FljvnNsIYGbPAdOBwnrH3QvcD/zM0wr9opUrvik+eJTbX1zFP9bs5tQ+nbh/xig10xIJQSiBngFsC3peBIwLPsDMRgN9nHOvmNlxA93MZgGzADIzM5tebaRoisU3VdU1zJy7nD2HK7jj4mFcNz6L5CStYBEJRSiB3tDfJvfFi2ZJwEPAdY29kXNuLjAXICcnxzVyuD80xeKLbfvL6NWpLS2Sk/jVZSPJTEshs0uK32WJxJRQAr0I6BP0vDdQHPQ8FRgBLKldC9wDyDWzS2PmwmhDa8oV5hFRVV3DvPc28cDr67hl2hCuO6sfZw/UUkSRkxFKoK8EBppZP2A7MBO4qu5F51wJ8MXfQDNbAvwsZsIc1ObWJ5/tOMTsBfnkF5Vw/rDuTBvZ0++SRGJao4HunKsysxuB1wgsW5znnFttZvcAec653HAXGTZ1I/O6MFeb24j587LN3P1yIR3btuS/rhrNRSN76m5PkWYKaR26c24xsLje1+48zrETml9WhASHudrcRkTdbfqDuqdyySm9uOPiYaS1a+V3WSJxIXHvFNUGFBFVdqyK3762jhbJxq0XDmVc/y6MUzMtEU8l7uaKdRdBNTIPu/fW7+WCh5cy771NHKuqwbnoXOAkEusSc4QePDrXxc+wKTlaya8Wfcbzedvol96Ov3zvTMb2S/O7LJG4lXiBru3hImbvkQpezi/m++cO4N8mD6RNSzXTEgmnxAp03TQUdnsOB5ppffvsfgzo2p53Z5+ni54iEZIYga6+LGHnnOPFT7Zz98uFlFVUM3FIN/qlt1OYi0RQ/Ae6+rKE3faDR7ltYQFL1u5hTGagmVa/9HZ+lyWScOI70DXFEnaBZlrL2HfkGHddMoxrzlQzLRG/xHeg1y1NVJh7buu+MjI6B5pp3Xf5KDLTUuiTpmZaIn6K33XoWpoYFlXVNTy6ZAOTH3qbp5dtBuCs7HSFuUgUiN8Rum4c8tzq4hJmL8hn1fZDXDC8OxepmZZIVInPQNfo3HNPvb+Ze18ppFNKKx69eow6I4pEofgLdN045Km6ZlpDeqQy/dQM7rh4KJ1StBRRJBrFV6BrVYtnSiuq+M1ra2mZbNx20TA10xKJAfER6LpxyFNL1+3hlhcKKC45yrVnZn0xSheR6BYfgV7X11w3DjVLSVkl9y4qZP6HRfTvGmimdXqWmmmJxIrYD3T1NffM3tIKXi3YwQ8nDODHk9RMSyTWxH6ga3lis+w+XE7uJ8V85yv9v2im1Vn9V0RiUmwHupYnnjTnHAs+2s69rxRytLKaSUO70y+9ncJcJIbFdqBrdH5Stu0v49aFBbzz+V5y+nbmvq+pmZZIPIjtQAeNzpuoqrqGKx9fzoHSY9w7fThXj+tLkpppicSF2A90CcnmvaX0SUuhRXIS988INNPq3Vn9V0TiSfw25xIAKqtreOSt9Ux5aOkXzbTGD0hXmIvEIY3Q49iq7SXcPD+fwh2HuGhkTy4e1cvvkkQkjBTocerJ9zbxi0WfkdauFY998zSmjujhd0kiEmYK9DhTd5v+8F4duXx0BrdfNIyOKS39LktEIiB2Az14DbpwpKKK+/+2hlbJSdx+8TDG9ktjbD/dti+SSGL3oqjWoH9hydrdXPDQUv68fAuOwChdRBJP7I7QIeHXoB8oPca9iwp54aPtZHdrz/zvj+e0vp39LktEfBLbgZ7gDpQd4/XVu/jxedn86LxsWrdQMy2RRBbSlIuZTTWztWa23szmNPD6T82s0MzyzexNM+vrfakCsPtQOXOXbsA5R/+u7Xlv9nn8dMpghbmINB7oZpYMPAJMA4YBV5rZsHqHfQzkOOdGAfOB+70uNNE55/jLym1MevBtHnh9HZv3lQFoBYuIfCGUEfpYYL1zbqNz7hjwHDA9+ADn3FvOubLap8uB3t6WWU/dCpcEsW1/Gdc8sYKbF+QztGcHXv3Xr6iZloh8SShz6BnAtqDnRcC4Exx/A/BqQy+Y2SxgFkBmZmaIJTYggVa41DXTOlhWyS++OoKrxmaqmZaINCiUQG8oPRpcF2dm3wRygHMbet05NxeYC5CTk9O8tXVxvsJl095SMmubaf1mxin07ZJCr05t/S5LRKJYKFMuRUCfoOe9geL6B5nZZOA24FLnXIU35SWeyuoa/vPNz7ngoaU89f5mAM4c0EVhLiKNCmWEvhIYaGb9gO3ATOCq4APMbDTwB2Cqc26351UmiPyig9w8P581Ow9zySm9uPRUNdMSkdA1GujOuSozuxF4DUgG5jnnVpvZPUCecy4X+A3QHvirmQFsdc5dGsa64868dzfxi0WFdE1tzePfyuH8Yd39LklEYkxINxY55xYDi+t97c6gx5M9rith1DXTGtW7I984vQ9zpg2lY1stRRSRptOdoj45XF7Jfa+uoXWLZO68ZBg5WWnkZKmZloicvNhtzhXD3lqzmykPLeXZFVtpkWxqpiUintAIPYL2lx7jnpdX8+InxQzq3p7/vno8ozPVTEtEvKFAj6CSo5W8+dlu/nXSQH40MZtWLfQPJBHxjgI9zHaWlPPiJ9v53jn96ZfejnfnnKeLniISFrE3RIyRPi7OOZ5dsZXzH3ybh99Yx5a6ZloKcxEJk9gbocdAH5ct+0qZs6CAZRv3cUb/NO67fBRZaqYlImEWe4EOUd3Hpaq6hqse/4CSo5X86rKRzDy9j5ppiUhExGagR6ENe47Qt7aZ1gNXBJpp9eyo/isiEjmxN4ceZY5V1fDwG+uY+vBSnl62BYAz+ndRmItIxGmE3gyfbDvI7Pn5rN11mOmn9uKrozP8LklEEpgC/SQ98e4mfrmokG6pbXji2hwmDVUzLRHxlwK9ieqaaZ3apyMzx2YyZ9oQOrTRUkQR8Z8CPUSHyiv59eI1tGmZxM8vGc5pfdM4ra+aaYlI9NBF0RC8UbiL8x98m+dXbqVViyQ10xKRqKQR+gnsO1LB3S8XkvtpMUN6pDL3mhxO6dPJ77JERBqkQD+Bw+VVvLV2Nz+ZPIgfTBigZloiEtUU6PUUHzzKwo+388MJA8hKb8d7c87TRU8RiQkK9Fo1NY5nVmzlvlfXUF3juGhkT7LS2ynMRSRmKNCBTXtLmbMgnw827ees7C78+rJRZHZJ8bssEZEmSfhAr6qu4Zt//IBD5ZXc/7VRfD2nN2ZqpiUisSdhA3397sNkdWlHi+QkHvrGqfTtkkL3Dm38LktE5KQl3LKNiqpqHvz7OqY+/A5P1TbTGtsvTWEuIjEvoUboH209wOz5+Xy++wiXj87gcjXTEpE4kjCB/vjSjfzq1c/o2aENT15/OhMHd/O7JBERT8V9oNfUOJKSjDF9O3H1uExmTx1CqpYiikgcittALzlayS8XFdK2ZTJ3Tx+hZloiEvfi8qLoa6t3cv6Db7Pgo+20a91CzbREJCHE1Qh975EKfv7SahYV7GBYzw7Mu+50RmR09LssEZGIiKtAP1JexTuf7+GmCwYz65z+tEyOy3+AiIg0KOYDffvBoyz8qIgfTcwmK70d798yifatY/60RESaLKQhrJlNNbO1ZrbezOY08HprM3u+9vUPzCzL60Lrq6lx/HnZZqY8+DaPvLWBLfvKABTmIpKwGk0/M0sGHgHOB4qAlWaW65wrDDrsBuCAcy7bzGYC/wF8IxwFAxytrObauctZsXk/XxmYzq8uG0mfNDXTEpHEFspwdiyw3jm3EcDMngOmA8GBPh24q/bxfOC/zMxcGJaXOByf7TjEGneI38wYxYzT1ExLRARCC/QMYFvQ8yJg3PGOcc5VmVkJ0AXYG3yQmc0CZgFkZmaeVMHWYxS9Usp5Y9q5dFP/FRGRL4QS6A0Nf+uPvEM5BufcXGAuQE5OzsmN3qfdR4+T+o0iIvEtlIuiRUCfoOe9geLjHWNmLYCOwH4vChQRkdCEEugrgYFm1s/MWgEzgdx6x+QC19Y+ngH8Ixzz5yIicnyNTrnUzonfCLwGJAPznHOrzeweIM85lws8AfzZzNYTGJnPDGfRIiLyZSEt2nbOLQYW1/vanUGPy4Gve1uaiIg0he6NFxGJEwp0EZE4oUAXEYkTCnQRkThhfq0uNLM9wJaT/O3p1LsLNQHonBODzjkxNOec+zrnujb0gm+B3hxmluecy/G7jkjSOScGnXNiCNc5a8pFRCROKNBFROJErAb6XL8L8IHOOTHonBNDWM45JufQRUTky2J1hC4iIvUo0EVE4kRUB3o0bk4dbiGc80/NrNDM8s3sTTPr60edXmrsnIOOm2FmzsxifolbKOdsZlfUfq9Xm9kzka7RayH8bGea2Vtm9nHtz/eFftTpFTObZ2a7zWzVcV43M/t97Z9HvpmNafaHOuei8heBVr0bgP5AK+BTYFi9Y34IPFb7eCbwvN91R+CcJwIptY9/kAjnXHtcKrAUWA7k+F13BL7PA4GPgc61z7v5XXcEztcN4fIAAAKRSURBVHku8IPax8OAzX7X3cxzPgcYA6w6zusXAq8S2PHtDOCD5n5mNI/Qv9ic2jl3DKjbnDrYdOCp2sfzgUkW2ztGN3rOzrm3nHNltU+XE9hBKpaF8n0GuBe4HyiPZHFhEso5fxd4xDl3AMA5tzvCNXotlHN2QIfaxx358s5oMcU5t5QT79w2HXjaBSwHOplZz+Z8ZjQHekObU2cc7xjnXBVQtzl1rArlnIPdQOD/8LGs0XM2s9FAH+fcK5EsLIxC+T4PAgaZ2XtmttzMpkasuvAI5ZzvAr5pZkUE9l/4l8iU5pum/n1vVEgbXPjEs82pY0jI52Nm3wRygHPDWlH4nfCczSwJeAi4LlIFRUAo3+cWBKZdJhD4V9g7ZjbCOXcwzLWFSyjnfCXwJ+fcA2Z2JoFd0EY452rCX54vPM+vaB6hJ+Lm1KGcM2Y2GbgNuNQ5VxGh2sKlsXNOBUYAS8xsM4G5xtwYvzAa6s/2S865SufcJmAtgYCPVaGc8w3AXwCcc8uANgSaWMWrkP6+N0U0B3oibk7d6DnXTj/8gUCYx/q8KjRyzs65EudcunMuyzmXReC6waXOuTx/yvVEKD/bLxK4AI6ZpROYgtkY0Sq9Fco5bwUmAZjZUAKBvieiVUZWLvCt2tUuZwAlzrkdzXpHv68EN3KV+EJgHYGr47fVfu0eAn+hIfAN/yuwHlgB9Pe75gic8xvALuCT2l+5ftcc7nOud+wSYnyVS4jfZwMeBAqBAmCm3zVH4JyHAe8RWAHzCTDF75qbeb7PAjuASgKj8RuA7wPfD/oeP1L751Hgxc+1bv0XEYkT0TzlIiIiTaBAFxGJEwp0EZE4oUAXEYkTCnQRkTihQBcRiRMKdBGROPF/gm7jXiQU/XsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Since this is a multi-class classificationm we need to ensure our labels follow binary classification logic\n",
    "#To achieve this target we can use OneVsRestClassifier\n",
    "#Requirement of OneVsRestClassifier is:\n",
    "# 1. labels must be numeric in nature\n",
    "# 2. model algo must support either predict_proba and decision_function\n",
    "\n",
    "\n",
    "#Lets first encode our labels\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "y_train_lb = label_binarize(y_train_OS, classes=['Negative','Neutral','Positive'])\n",
    "y_test_lb = label_binarize(y_test_OS, classes=['Negative','Neutral','Positive'])\n",
    "\n",
    "n_classes = y_train_lb.shape[1]\n",
    "\n",
    "#Create NaiveBayes OneVsRestClassifier Model\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "multiClassModel = OneVsRestClassifier(MultinomialNB())\n",
    "y_score = multiClassModel.fit(X_train_bow_OS.toarray(),y_train_lb).predict_proba(X_test_bow_OS.toarray())\n",
    "\n",
    "##############################################################################################################\n",
    "#Plot ROC-AUC\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fpr=dict()\n",
    "tpr=dict()\n",
    "auc =dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i],tpr[i],_ = roc_curve(y_test_lb[:,i], y_score[:,i])\n",
    "    auc[i] = roc_auc_score(y_test_lb[:,i], y_score[:,i])\n",
    "\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    print('roc_auc_score:',auc[i])\n",
    "    plt.plot([0,1],[0,1], linestyle = '--')\n",
    "    plt.plot(fpr[i],tpr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach-2:Use of multinomial Naive Bayes classifier with  Undersampling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score is:0.9498207885304659 \n",
      "test score is:0.7083333333333334 \n",
      "classification_report TRAIN Data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.90      0.95        93\n",
      "     Neutral       0.99      0.96      0.97        93\n",
      "    Positive       0.88      0.99      0.93        93\n",
      "\n",
      "    accuracy                           0.95       279\n",
      "   macro avg       0.96      0.95      0.95       279\n",
      "weighted avg       0.96      0.95      0.95       279\n",
      "\n",
      "classification_report TEST Data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.69      0.75      0.72        24\n",
      "     Neutral       0.68      0.62      0.65        24\n",
      "    Positive       0.75      0.75      0.75        24\n",
      "\n",
      "    accuracy                           0.71        72\n",
      "   macro avg       0.71      0.71      0.71        72\n",
      "weighted avg       0.71      0.71      0.71        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model building using multinomial Naive Bayes classifier\n",
    "model_MNB = MultinomialNB()\n",
    "model_MNB.fit( X_train_bow_US.toarray(),y_train_US)\n",
    "\n",
    "#Get Train and Test Accuracy Score\n",
    "train_score=model_MNB.score(X_train_bow_US.toarray(),y_train_US)\n",
    "test_score=model_MNB.score(X_test_bow_US.toarray(),y_test_US)\n",
    "print('train score is:{} '.format(train_score))\n",
    "print('test score is:{} '.format(test_score))\n",
    "\n",
    "#Get precision    recall  and f1-score on Train data\n",
    "cr=classification_report(y_true=y_train_US,y_pred=model_MNB.predict( X_train_bow_US.toarray() ))\n",
    "print('classification_report TRAIN Data\\n',cr)\n",
    "\n",
    "#Get precision    recall  and f1-score on Test data\n",
    "cr=classification_report(y_true=y_test_US,y_pred=model_MNB.predict( X_test_bow_US.toarray() ))\n",
    "print('classification_report TEST Data\\n',cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare  roc and auc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score: 0.8585069444444444\n",
      "roc_auc_score: 0.7109375\n",
      "roc_auc_score: 0.7899305555555556\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXhV5bn+8e9DGBPCEJIQCIQAYSYoGEFRmUVwoioqTlVrD63VY396VHCsSms9WrWnp1bFilVbixZEo2BptUwqKHFKIIIyE8I8BEjI/J4/EvylGMgG9s7KXvv+XBfXtdfeK3s/iyQ3L2u963nNOYeIiIS/Rl4XICIiwaFAFxHxCQW6iIhPKNBFRHxCgS4i4hONvfrg+Ph4l5qa6tXHi4iEpc8++2yXcy6httc8C/TU1FSysrK8+ngRkbBkZhuP9ppOuYiI+IQCXUTEJxToIiI+oUAXEfEJBbqIiE/UGehmNsPMdpjZiqO8bmb2OzNbY2bZZjYo+GWKiEhdAhmh/wkYd4zXxwM9qv9MBp49+bJEROR41TkP3Tm32MxSj7HLBOAVV9WHd5mZtTGzDs65rUGqUUTqS9ZLkDPL6yp8q8I5yioqad7pVBj/WNDfPxjn0JOBzTW286qf+x4zm2xmWWaWtXPnziB8tIgEVc4s2JbjdRW+VHCojOy8fXyz/QCO0KxDEYw7Ra2W52qt1jk3HZgOkJGRoZU1RBqipHS4ca7XVfhGwaEyfj3va2au3kxqu2geu2wA1q1dSD4rGIGeB3Susd0JyA/C+4qIhLWKSsdlz37Mup0H+cnwbtw+pifNm0SF7POCEeiZwK1mNhMYAhTo/LmIRLK9haW0iW5CVCPjzrG96NimOQM6tQn559YZ6Gb2V2AEEG9mecAvgCYAzrnngHnA+cAaoAi4MVTFiog0ZM453vpyCw+/k8uUcb25anAK4/on1dvnBzLL5ao6XnfALUGrSEQkDOXvO8R9c3JYsHonA1PakNGlbb3X4Fn7XBERv3j7yy3cN2cFFZWOBy/sy/VDU4lqVNt8kdBSoIuEi/qYI74tp2qWixyX1i2acGrnNvz60nQ6x0V7VocCXSRcHJ4jHsrATUqH9Imhe3+fKK+o5MUP11NWUcmto3owolciw3smYFb/o/KaFOgi4URzxD2Xm7+fKbOzydlSwAUDOuCcw8w8D3NQoIuIBKSkvILf/2sNzy5cS5voJvzhmkGM75/UIIL8MAW6iEgANuwq4rlFa7n41I48cEFf2sY09bqk71Ggi4gcRWFJOf/M3c4PBibTKymWD+4YQUo77y561kWBLiJSiyXf7uSeN3PYsu8Q/ZNbkZYY26DDHBToIiL/pqCojF/Ny+WNrDy6xcfw+uQzSUuM9bqsgCjQRUSqVVQ6LnvuY9bvKuRnI7pz2+geIW2mFWwKdBGJeHsKS2nToqqZ1l3n9SK5TQv6J7f2uqzjpkWiRSRiOeeY/VkeI3+zkJnLq9bpOa9fUliGOWiELiIRKm9vEffOWcHib3ZyWpe2DO4a53VJJ02BLiIRZ84Xedw/ZwUOePjiflx3RhcaedBMK9gU6CISceJimnFaahyPXtKfTm0b9lTE46FAFxHfK6uo5IUl6yivcNw2ugfDeyYwrEd8g7ptPxgU6CLiayu2FDBldjYr8/dz0SkdG1QzrWBToIuILxWXVfC7D77l+cXraBvdlOeuHcS4/h28LiukFOgi4ksbdxfxwpJ1XDowmfsv6Evr6CZelxRyCnQR8Y3CknLmr9zGpYM60Sspln/91whPVxCqbwp0EfGFRd/s5N43c8gvOMSATq1JS4yNqDAHBbqIhLm9haVMm5vLm59voXtCDH/7Sfg00wo2BbqIhK3DzbQ27i7i1pFp3DoqLayaaQWbAl1Ews7ugyW0jW5KVCNj6rjeJLdtQb+O4dl/JZjUnEtEwoZzjjeyNjPyNwv56/JNAIztl6Qwr6YRuoiEhc17irh3Tg5Lvt3F4NQ4zuzWzuuSGhwFeiTLeglyZnldhQRqWw4kpXtdhSfe/DyP+99agQHTftCfawan+KKZVrAp0CNZzqyIDomwk5QO6RO9rsIT8S2bMbhrHL+6JJ3kNi28LqfBUqBHuqR0uHGu11WI/JuyikqeX7SWikr4+ZgeDOuZwLCeCV6X1eAp0EWkQVmxpYC7ZmXz9db9TDj1/zfTkrop0EWkQSguq+C373/LC0vWERfTlOevO43z+iV5XVZYCWjaopmNM7PVZrbGzKbW8nqKmS0wsy/MLNvMzg9+qSLiZ5v2FPHih+uYOKgT798+XGF+AuocoZtZFPAMcC6QByw3s0znXG6N3e4H3nDOPWtmfYF5QGoI6hURHzlQXMbfV2zj8ozO9Gwfy4I7R/hqBaH6Fsgpl8HAGufcOgAzmwlMAGoGugNaVT9uDeQHs0gR8Z8Fq3Zw35wctu0vZmBKG9ISYxXmJymQQE8GNtfYzgOGHLHPQ8A/zOw/gRhgTG1vZGaTgckAKSkpx1uriPjAnsJSpr2by5wvttAjsSWzbh4asc20gi2QQK/t8rI7Yvsq4E/OuSfN7EzgVTPr75yr/Lcvcm46MB0gIyPjyPcQEZ+rqHRMfPZjNu0p4rbRPbhlZHeaNY7cZlrBFkig5wGda2x34vunVG4CxgE455aaWXMgHtgRjCJFJLztPFBCu5iqZlr3nt+H5LYt6NOhVd1fKMclkFkuy4EeZtbVzJoCk4DMI/bZBIwGMLM+QHNgZzALFZHw45zj9eWbGPXkQl77tKqZ1pi+7RXmIVLnCN05V25mtwLzgShghnNupZk9AmQ55zKB/wJeMLPbqTodc4NzTqdURCLYpt1FTH0zm4/X7mZI1zjOTov3uiTfC+jGIufcPKqmItZ87sEaj3OBs4JbmoiEq1mf5fHAWyuIamT86pL+XHW6mmnVB90pKiJB175VM4Z2b8cvL+lPh9ZqplVfFOgictJKyyt5duFaKp3j9nN7ck6PBM7poWZa9U2BLiIn5avN+7h7Vjartx/g0oHJaqblIQW63x1rEQv1QpeTcKi0gqf+uZoXP1xPYmxz/vjDDMb0be91WRFNge53x1rEIoIXTJCTt3lvES9/vJFJg1OYOr43rZo38bqkiKdAjwRaxEKCZH91M60rqptpLbxrBB21glCDoUAXkYD8a9V27n1zBTsOFDMopS1piS0V5g2MAl1Ejmn3wRIeeTeXt7/Mp1f7WJ677jTSElt6XZbUQoEuIkdVUem4/LmlbN5bxO1jenLziO40bRzQujjiAQW6iHzPjgPFxMc0I6qRcd8FfejUNppeSWpx29Dpn1oR+U5lpeMvn2xk1G8W8ZfqZlqj+7RXmIcJjdD94mjzzTXXXAK0YVchU9/MZtm6PQzt3o7hutMz7CjQ/eJo880111wC8EbWZh54awVNoxrx2KXpXHl6Z93tGYYU6H6i+eZygpLbtGBYzwSmTehPUuvmXpcjJ0iBLhKBSsor+MOCtTjnuGNsL85Ki+cs9SsPewp0kQjzxaa9TJmdzTfbD3LZoE5qpuUjCnSRCFFUWs6T//iGGR+tJ6lVc2bckMGo3mqm5ScKdJEIsWXvIV5dtpFrhqQwZVxvYtVMy3cU6CI+VnCojPdytjJpcAo92sey6K4RWkHIxxToIj71j5XbuP+tFewuLCUjNY60xJYKc59ToIv4zK6DJTyUuZJ3s7fSOymWP16foWZaEUKBLuIjFZWOic9+TP6+Yu4c25OfDO9Okyh1+IgUCnQRH9i+v5iEllXNtH5xUT86tW1Bj/bqvxJp9E+3SBirrHS8umwjo59cxF8+2QjAyN6JCvMIpRG6SJhat/MgU9/M4dP1ezg7LZ4RvRK9Lkk8pkAXCUOvL9/Eg2+vpFnjRjw+cQCXn9ZJd3uKAl0kHHVqG82IXlXNtBJbqZmWVFGgi4SBkvIK/veDNQDceZ6aaUntFOgiDdxnG/dw96xs1u4s5IoMNdOSo1OgizRQhSXlPDF/NS8v3UDH1i14+UeDGd5TqwjJ0QU0bdHMxpnZajNbY2ZTj7LPFWaWa2Yrzey14JYpEnny9x3itU838cMzujD/9mEKc6lTnSN0M4sCngHOBfKA5WaW6ZzLrbFPD+Ae4Czn3F4z0/wpkRNQUFTG3JytXD2kqpnWkrtH0l4XPSVAgZxyGQyscc6tAzCzmcAEILfGPv8BPOOc2wvgnNsR7EJF/O7vK7bxwNsr2FNYypBucXRPaKkwl+MSyCmXZGBzje286udq6gn0NLOPzGyZmY2r7Y3MbLKZZZlZ1s6dO0+sYhGf2XGgmJ/95TN++ufPSGjZjLdvOYvuCWqmJccvkBF6bZfTXS3v0wMYAXQClphZf+fcvn/7IuemA9MBMjIyjnwPkYhTUem44rml5BcUc9d5vZg8rJuaackJCyTQ84DONbY7Afm17LPMOVcGrDez1VQF/PKgVCniM1sLDtE+tnlVM62L+9G5bbRa3MpJCyTQlwM9zKwrsAWYBFx9xD5vAVcBfzKzeKpOwawLZqG+lPUS5MwKzntty4Gk9OC8l4RMZaXjlaUbeHz+aqaO780Pz0xlpHqwSJDUGejOuXIzuxWYD0QBM5xzK83sESDLOZdZ/dpYM8sFKoC7nHO7Q1m4L+TMCl4QJ6VD+sSTfx8JmTU7DjJ1djZZG/cyrGcCo3oryCW4ArqxyDk3D5h3xHMP1njsgDuq/8jxSEqHG+d6XYWE2MxPN/Fg5kpaNIniyctP4dJBybrbU4JOd4qK1IOUdtGM6ZPIwxf3JyG2mdfliE8p0EVCoLisgt998C0Ad4/rzdDu8QztrmZaElqaHyUSZFkb9nD+75bwh4Vr2VNYStUZSZHQ0whdJEgOlpTzxN9X8cqyjSS3acErPxrMMPVfkXqkQBcJkm0Fh5i5fDPXn5nKXef1IqaZfr2kfuknTuQk7C0s5d2crVx3RhfSEquaaWkFIfGKAl3kBDjneG/FNh58ewX7isoY2r0d3RNaKszFUwp0keO0Y38xD7y9gvkrt5Oe3JpXfjREzbSkQVCgixyHikrH5c8vZVtBMfeM781NZ3elsZppSQOhQBcJQP6+QyS1qmqm9ciE/nRu24JuGpVLA6OhhcgxVFQ6XvpoPaOfXMSfP9kIwPCeCQpzaZA0Qhc5ijU7DnD3rGw+37SPEb0SGN2nvdcliRyTAl2kFq99somHMlcS0yyKp688hR+cqmZa0vAp0IPlRHqbq4d5g5UaH83Yfu156OJ+xLdUMy0JDwr0YDmR3ubqYd5gFJdV8PT732AYU8ermZaEJwV6MKm3eVj6ZN1upr6Zw/pdhVwzJAXnnE6vSFhSoEvEOlBcxn//fRV/XraJlLhoXvvxEIamaVQu4UuBLhFr+/4SZn2Wx4/P7sodY3sS3VS/DhLe9BMsEWVPYSlzs/O57sxU0hJbsuTuUVpBSHxDgS4RwTnHu9lbeShzJfuLyzgrLZ5uCS0V5uIrCnTxve37i7lvzgre/3o7Azq15i8Th+hOT/ElBbr4WkWl44rqZlr3nd+HG89KVTMt8S0FuvhS3t4iOrRuQVQjY9qE/qTERZMaH+N1WSIhpaGK+EpFpeOPS9Yx5qlF/HlZVTOtYT0TFOYSETRCF99Yve0Ad8/O5qvN+xjdO5Gx/dRMSyKLAl184c/LNvLwOyuJbd6E/5l0Khef0lF3e0rEUaBLWDt8m35aYkvOT+/Agxf2pZ2aaUmEUqBLWDpUWsFT/1xNo0bGPeP7cEa3dpzRrZ3XZYl4ShdFJewsXbubcf+zmBeWrKeopALnnNcliTQIGqFL2NhfXMav563ir59uoku7aF77jyFqcStSgwJdwsaO/SW89cUWJg/rxu1jetKiaZTXJYk0KAGdcjGzcWa22szWmNnUY+w30cycmWUEr0SJZLsPlvCnj9YDkJbYkg+njOTe8/sozEVqUecI3cyigGeAc4E8YLmZZTrnco/YLxa4DfgkFIVKZHHOkflVPg9lruRgSTnDeibQLaGlZrCIHEMgI/TBwBrn3DrnXCkwE5hQy37TgMeB4iDWJxEof98hbno5i5/P/JIu7WKYe9s5aqYlEoBAzqEnA5trbOcBQ2ruYGYDgc7OuXfN7M6jvZGZTQYmA6SkpBx/teJ75RWVTJq+jJ0HSnjgwr7cMDSVqEa6QUgkEIEEem2/Td/NEzOzRsDTwA11vZFzbjowHSAjI0NzzeQ7m/cU0bFNCxpHNeLRS9JJiYsmpV2012WJhJVATrnkAZ1rbHcC8mtsxwL9gYVmtgE4A8jUhVEJRHlFJdMXr2XMU4t4dekGAM7uEa8wFzkBgYzQlwM9zKwrsAWYBFx9+EXnXAHw3WRgM1sI3OmcywpuqeI3X2/dz5TZ2WTnFXBu3/aMT+/gdUkiYa3OQHfOlZvZrcB8IAqY4ZxbaWaPAFnOucxQF+mJrJcgZ1bg+2/LgaT00NXjM68u3cDD7+TSukUTfn/1QC5I76BmWiInKaAbi5xz84B5Rzz34FH2HXHyZTUAObOOL6ST0iF9Ymhr8oHDzbR6to/lolM68sCFfYmLaep1WSK+oDtFjyUpHW6c63UVvlBUWs5v5n9D4yjj3vP7MKRbO4aomZZIUKk5l4TcR2t2cd5vFzPjo/WUlleqmZZIiGiELiFTcKiMR+d+zetZm+kaH8MbPzmTwV3jvC5LxLcU6BIyuw6W8E52Pj8d3p3/N6YHzZuo/4pIKCnQJah2Hijhna/y+dHZXeme0JIPp4zSRU+ReqJAl6BwzvHWl1t4+J1cikoqGNk7ka7xMQpzkXoU2YF+rLnmmlcesC37DnHfnBwWrt7JoJQ2PD5xAF3jY7wuSyTiRHagH2uuueaVB6SqmdZSdh8s5aGL+nLdmWqmJeKVyA500FzzE7RpdxHJbauaaT126QBS4qLpHKf+KyJe0jx0OS7lFZU8u3AtY55exCtLNwBwVlq8wlykAdAIXQK2Mr+AKbOzWbFlP+f1a88FaqYl0qAo0CUgL3+8gWnv5tImuinPXjNInRFFGiAFuhzT4WZavZNimXBqMg9c2Ic20ZqKKNIQKdClVoUl5TwxfzVNooz7LuirZloiYSAyAv1o880117xWi7/ZyT1v5pBfcIjrz0z9bpQuIg1bZAT60eaba675vykoKmPa3FxmfZZHt4SqZlqnp6qZlki4iIxAB803D8CuwhLey9nKz0Z057bRaqYlEm4iJ9ClVjsOFJP5ZT4/Pqfbd8202qr/ikhYUqBHKOccsz/fwrR3czlUVsHoPu3pGh+jMBcJYwr0CLR5TxH3zslhybe7yOjSlscuUzMtET9QoEeY8opKrnphGXsLS5k2oR/XDOlCIzXTEvEFBXqE2LCrkM5x0TSOasTjE6uaaXVqq/4rIn6i5lw+V1ZRyTML1jD26cXfNdMa2j1eYS7iQxqh+9iKLQXcPSub3K37uSC9AxcO6Oh1SSISQgp0n3rpo/X8cu7XxMU05blrT2Nc/ySvSxKREFOg+8zh2/T7dWzNpQOTuf+CvrSObuJ1WSJSDxToPnGwpJzH/76KplGNuP/CvgzuGsfgrrptXySS6KKoDyxcvYPznl7Mq8s24qgapYtI5NEIPYztLSxl2txc3vx8C2mJLZn106Gc1qWt12WJiEcU6GFsb1Ep/1i5ndtGpXHLqDSaNVYzLZFIFtApFzMbZ2arzWyNmU2t5fU7zCzXzLLN7AMz6xL8UgVgx/5ipi9ei3OObgkt+WjKKO4Y20thLiJ1j9DNLAp4BjgXyAOWm1mmcy63xm5fABnOuSIzuxl4HLgyFAUfk48XsnDO8besPKbNzaW0vJJz+ybRNT5GM1hE5DuBjNAHA2ucc+ucc6XATGBCzR2ccwucc0XVm8uATsEtM0CHF7I4UpgvZLF5TxHXvfgpd8/Opk+HVrz383PUTEtEvieQc+jJwOYa23nAkGPsfxPwXm0vmNlkYDJASkpKgCUeJ58tZHG4mda+ojJ++YP+XD04Rc20RKRWgQR6belR67w4M7sWyACG1/a6c246MB0gIyNDc+uOYf2uQlKqm2k9MfEUurSLpmObFl6XJSINWCCnXPKAzjW2OwH5R+5kZmOA+4CLnXMlwSkv8pRVVPK/H3zLeU8v5uWPNwBwZvd2CnMRqVMgI/TlQA8z6wpsASYBV9fcwcwGAs8D45xzO4JeZYTIztvH3bOyWbXtABed0pGLT1UzLREJXJ2B7pwrN7NbgflAFDDDObfSzB4BspxzmcATQEvgb2YGsMk5d3EI6/adGR+u55dzc0mIbcYLP8zg3L7tvS5JRMJMQDcWOefmAfOOeO7BGo/HBLmuiHG4mdaATq258vTOTB3fh9YtNBVRRI6f7hT1yIHiMh57bxXNGkfx4EV9yUiNIyNVzbRE5MSpOZcHFqzawdinF/PXTzfROMrUTEtEgkIj9Hq0p7CUR95ZyVtf5tOzfUv+cM1QBqaomZaIBIcCvR4VHCrjg6938PPRPbhlZBpNG+s/SCISPAr0ENtWUMxbX27hJ8O60TU+hg+njtJFTxEJCQV6iDjnmLl8M4/O/ZqyykrG9UsiNT5GYS4iIaNAD4GNuwuZOjuHpet2c0a3OB67dACpaqYlIiGmQA+y8opKrn7hEwoOlfHoJelMOr2zmmmJSL0Iv0A/Ws9z8LTv+dqdB+lS3UzrySuqmml1aK3+KyJSf8JvmsXRep6DJ33PS8sr+e373zDut4t5ZelGAM7o1k5hLiL1LvxG6NBgep5/uXkfU2Zls3r7ASac2pEfDEz2uiQRiWDhGegNwIsfrudXc3NJjG3Oi9dnMLqPmmmJiLcU6MfpcDOtUzu3ZtLgFKaO702r5pqKKCLeU6AHaH9xGb+et4rmTRrxi4v6cVqXOE7romZaItJwhN9FUQ+8n7udc59axOvLN9G0cSM10xKRBkkj9GPYfbCEh9/JJfOrfHonxTL9ugxO6dzG67JERGqlQD+GA8XlLFi9g9vH9OTmEd3VTEtEGjQF+hHy9x1izhdb+NmI7qTGx/DR1FG66CkiYUGBXq2y0vHap5t47L1VVFQ6LkjvQGp8jMJcRMKGAh1Yv6uQqbOz+WT9Hs5Ka8evLxlASrtor8sSETkuER/o5RWVXPvHT9hfXMbjlw3g8oxOmKmZloiEn4gN9DU7DpDaLobGUY14+spT6dIumvatmntdlojICYu4aRsl5RU89c9vGPfbJbxc3UxrcNc4hbmIhL2IGqF/vmkvU2Zl8+2Og1w6MJlL1UxLRHwkYgL9hcXrePS9r+nQqjkv3Xg6I3slel2SiEhQ+T7QKysdjRoZg7q04ZohKUwZ15tYTUUUER/ybaAXHCrjV3NzadEkiocn9FczLRHxPV9eFJ2/chvnPrWI2Z9vIaZZYzXTEpGI4KsR+q6DJfzi7ZXMzdlK3w6tmHHD6fRPbu11WSIi9cJXgX6wuJwl3+7krvN6MXlYN5pE+fI/ICIitQr7QN+y7xBzPs/jlpFppMbH8PE9o2nZLOwPS0TkuAU0hDWzcWa22szWmNnUWl5vZmavV7/+iZmlBrvQI1VWOl5duoGxTy3imQVr2bi7CEBhLiIRq870M7Mo4BngXCAPWG5mmc653Bq73QTsdc6lmdkk4L+BK0NRMMChsgqun76MTzfs4Zwe8Tx6STqd49RMS0QiWyDD2cHAGufcOgAzmwlMAGoG+gTgoerHs4Dfm5m5EEwvcTi+3rqfVW4/T0wcwMTT1ExLRAQCC/RkYHON7TxgyNH2cc6Vm1kB0A7YVXMnM5sMTAZISUk5oYItaQAdo4t5f/xwEtV/RUTkO4EEem3D3yNH3oHsg3NuOjAdICMj48RG7+MfI+mEvlBExN8CuSiaB3Susd0JyD/aPmbWGGgN7AlGgSIiEphAAn050MPMuppZU2ASkHnEPpnA9dWPJwL/CsX5cxERObo6T7lUnxO/FZgPRAEznHMrzewRIMs5lwm8CLxqZmuoGplPCmXRIiLyfQFN2nbOzQPmHfHcgzUeFwOXB7c0ERE5Hro3XkTEJxToIiI+oUAXEfEJBbqIiE+YV7MLzWwnsPEEvzyeI+5CjQA65sigY44MJ3PMXZxzCbW94Fmgnwwzy3LOZXhdR33SMUcGHXNkCNUx65SLiIhPKNBFRHwiXAN9utcFeEDHHBl0zJEhJMcclufQRUTk+8J1hC4iIkdQoIuI+ESDDvSGuDh1qAVwzHeYWa6ZZZvZB2bWxYs6g6muY66x30Qzc2YW9lPcAjlmM7ui+nu90sxeq+8agy2An+0UM1tgZl9U/3yf70WdwWJmM8xsh5mtOMrrZma/q/77yDazQSf9oc65BvmHqla9a4FuQFPgK6DvEfv8DHiu+vEk4HWv666HYx4JRFc/vjkSjrl6v1hgMbAMyPC67nr4PvcAvgDaVm8nel13PRzzdODm6sd9gQ1e132SxzwMGASsOMrr5wPvUbXi2xnAJyf7mQ15hP7d4tTOuVLg8OLUNU0AXq5+PAsYbeG9YnSdx+ycW+CcK6reXEbVClLhLJDvM8A04HGguD6LC5FAjvk/gGecc3sBnHM76rnGYAvkmB3Qqvpxa76/MlpYcc4t5tgrt00AXnFVlgFtzKzDyXxmQw702hanTj7aPs65cuDw4tThKpBjrukmqv6FD2d1HrOZDQQ6O+ferc/CQiiQ73NPoKeZfWRmy8xsXL1VFxqBHPNDwLVmlkfV+gv/WT+leeZ4f9/rFNACFx4J2uLUYSTg4zGza4EMYHhIKwq9Yx6zmTUCngZuqK+C6kEg3+fGVJ12GUHV/8KWmFl/59y+ENcWKoEc81XAn5xzT5rZmVStgtbfOVcZ+vI8EfT8asgj9EhcnDqQY8bMxgD3ARc750rqqbZQqeuYY4H+wEIz20DVucbMML8wGujP9tvOuTLn3HpgNVUBH64COeabgDcAnHNLgeZUNbHyq4B+349HQw70SFycus5jrj798DxVYR7u51WhjmN2zhU45+Kdc6nOuVSqrhtc7JzL8qbcoAjkZ/stqi6AY2bxVJ2CWVevVQZXIMe8CRgNYGZ9qAr0nfVaZf3KBH5YPdvlDKDAObf1pN7R6yvBdVwlPh/4hqqr4/dVP/cIVb/QUPUN/xuwBvgU6OZ1zfVwzCDOwL8AAACCSURBVO8D24Evq/9kel1zqI/5iH0XEuazXAL8PhvwFJAL5ACTvK65Ho65L/ARVTNgvgTGel3zSR7vX4GtQBlVo/GbgJ8CP63xPX6m+u8jJxg/17r1X0TEJxryKRcRETkOCnQREZ9QoIuI+IQCXUTEJxToIiI+oUAXEfEJBbqIiE/8H1wGgdBKTz8LAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Since this is a multi-class classificationm we need to ensure our labels follow binary classification logic\n",
    "#To achieve this target we can use OneVsRestClassifier\n",
    "#Requirement of OneVsRestClassifier is:\n",
    "# 1. labels must be numeric in nature\n",
    "# 2. model algo must support either predict_proba and decision_function\n",
    "\n",
    "\n",
    "#Lets first encode our labels\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "y_train_lb = label_binarize(y_train_US, classes=['Negative','Neutral','Positive'])\n",
    "y_test_lb = label_binarize(y_test_US, classes=['Negative','Neutral','Positive'])\n",
    "\n",
    "n_classes = y_train_lb.shape[1]\n",
    "\n",
    "#Create NaiveBayes OneVsRestClassifier Model\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "multiClassModel = OneVsRestClassifier(MultinomialNB())\n",
    "y_score = multiClassModel.fit(X_train_bow_US.toarray(),y_train_lb).predict_proba(X_test_bow_US.toarray())\n",
    "\n",
    "##############################################################################################################\n",
    "#Plot ROC-AUC\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fpr=dict()\n",
    "tpr=dict()\n",
    "auc =dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i],tpr[i],_ = roc_curve(y_test_lb[:,i], y_score[:,i])\n",
    "    auc[i] = roc_auc_score(y_test_lb[:,i], y_score[:,i])\n",
    "\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    print('roc_auc_score:',auc[i])\n",
    "    plt.plot([0,1],[0,1], linestyle = '--')\n",
    "    plt.plot(fpr[i],tpr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach-3:Use of Logistic Regression  with Oversampling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score is:0.9936872054770161 \n",
      "test score is:0.6318036286019211 \n",
      "classification_report TRAIN Data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      1.00      1.00      3749\n",
      "     Neutral       0.99      1.00      0.99      3749\n",
      "    Positive       1.00      0.98      0.99      3749\n",
      "\n",
      "    accuracy                           0.99     11247\n",
      "   macro avg       0.99      0.99      0.99     11247\n",
      "weighted avg       0.99      0.99      0.99     11247\n",
      "\n",
      "classification_report TEST Data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.93      0.52      0.67       937\n",
      "     Neutral       0.73      0.41      0.53       937\n",
      "    Positive       0.51      0.96      0.67       937\n",
      "\n",
      "    accuracy                           0.63      2811\n",
      "   macro avg       0.72      0.63      0.62      2811\n",
      "weighted avg       0.72      0.63      0.62      2811\n",
      "\n",
      "Wall time: 5.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Model building using LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_LR_OS=LogisticRegression()\n",
    "\n",
    "model_LR_OS.fit( X_train_bow_OS.toarray(),y_train_OS)\n",
    "\n",
    "#Get Train and Test Accuracy Score\n",
    "train_score=model_LR_OS.score(X_train_bow_OS.toarray(),y_train_OS)\n",
    "test_score=model_LR_OS.score(X_test_bow_OS.toarray(),y_test_OS)\n",
    "print('train score is:{} '.format(train_score))\n",
    "print('test score is:{} '.format(test_score))\n",
    "\n",
    "#Get precision    recall  and f1-score on Train data\n",
    "cr=classification_report(y_true=y_train_OS,y_pred=model_LR_OS.predict( X_train_bow_OS.toarray() ))\n",
    "print('classification_report TRAIN Data\\n',cr)\n",
    "\n",
    "#Get precision    recall  and f1-score on Test data\n",
    "cr=classification_report(y_true=y_test_OS,y_pred=model_LR_OS.predict( X_test_bow_OS.toarray() ))\n",
    "print('classification_report TEST Data\\n',cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare  roc and auc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score: 0.9200535554216607\n",
      "roc_auc_score: 0.758722688386492\n",
      "roc_auc_score: 0.9138534504065633\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "#Since this is a multi-class classificationm we need to ensure our labels follow binary classification logic\n",
    "#To achieve this target we can use OneVsRestClassifier\n",
    "#Requirement of OneVsRestClassifier is:\n",
    "# 1. labels must be numeric in nature\n",
    "# 2. model algo must support either predict_proba and decision_function\n",
    "\n",
    "\n",
    "#Lets first encode our labels\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "y_train_lb = label_binarize(y_train_OS, classes=['Negative','Neutral','Positive'])\n",
    "y_test_lb = label_binarize(y_test_OS, classes=['Negative','Neutral','Positive'])\n",
    "\n",
    "n_classes = y_train_lb.shape[1]\n",
    "\n",
    "#Create NaiveBayes OneVsRestClassifier Model\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "multiClassModel = OneVsRestClassifier(LogisticRegression())\n",
    "y_score = multiClassModel.fit(X_train_bow_OS.toarray(),y_train_lb).predict_proba(X_test_bow_OS.toarray())\n",
    "\n",
    "##############################################################################################################\n",
    "#Plot ROC-AUC\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fpr=dict()\n",
    "tpr=dict()\n",
    "auc =dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i],tpr[i],_ = roc_curve(y_test_lb[:,i], y_score[:,i])\n",
    "    auc[i] = roc_auc_score(y_test_lb[:,i], y_score[:,i])\n",
    "\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    print('roc_auc_score:',auc[i])\n",
    "    plt.plot([0,1],[0,1], linestyle = '--')\n",
    "    plt.plot(fpr[i],tpr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach-4: Use of Logistic Regression with  Undersampling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score is:0.989247311827957 \n",
      "test score is:0.6666666666666666 \n",
      "classification_report TRAIN Data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.98      0.99        93\n",
      "     Neutral       0.99      1.00      0.99        93\n",
      "    Positive       0.98      0.99      0.98        93\n",
      "\n",
      "    accuracy                           0.99       279\n",
      "   macro avg       0.99      0.99      0.99       279\n",
      "weighted avg       0.99      0.99      0.99       279\n",
      "\n",
      "classification_report Test Data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.63      0.79      0.70        24\n",
      "     Neutral       0.62      0.67      0.64        24\n",
      "    Positive       0.81      0.54      0.65        24\n",
      "\n",
      "    accuracy                           0.67        72\n",
      "   macro avg       0.69      0.67      0.66        72\n",
      "weighted avg       0.69      0.67      0.66        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model building using multinomial LogisticRegression\n",
    "model_LR = LogisticRegression()\n",
    "model_LR.fit( X_train_bow_US.toarray(),y_train_US)\n",
    "\n",
    "#Get Train and Test Accuracy Score\n",
    "train_score=model_LR.score(X_train_bow_US.toarray(),y_train_US)\n",
    "test_score=model_LR.score(X_test_bow_US.toarray(),y_test_US)\n",
    "print('train score is:{} '.format(train_score))\n",
    "print('test score is:{} '.format(test_score))\n",
    "\n",
    "#Get precision    recall  and f1-score on Train data\n",
    "cr=classification_report(y_true=y_train_US,y_pred=model_LR.predict( X_train_bow_US.toarray() ))\n",
    "print('classification_report TRAIN Data\\n',cr)\n",
    "\n",
    "#Get precision    recall  and f1-score on Test data\n",
    "cr=classification_report(y_true=y_test_US,y_pred=model_LR.predict( X_test_bow_US.toarray() ))\n",
    "print('classification_report Test Data\\n',cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare  roc and auc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score: 0.8776041666666666\n",
      "roc_auc_score: 0.7682291666666667\n",
      "roc_auc_score: 0.8342013888888888\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Since this is a multi-class classificationm we need to ensure our labels follow binary classification logic\n",
    "#To achieve this target we can use OneVsRestClassifier\n",
    "#Requirement of OneVsRestClassifier is:\n",
    "# 1. labels must be numeric in nature\n",
    "# 2. model algo must support either predict_proba and decision_function\n",
    "\n",
    "\n",
    "#Lets first encode our labels\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "y_train_lb = label_binarize(y_train_US, classes=['Negative','Neutral','Positive'])\n",
    "y_test_lb = label_binarize(y_test_US, classes=['Negative','Neutral','Positive'])\n",
    "\n",
    "n_classes = y_train_lb.shape[1]\n",
    "\n",
    "#Create NaiveBayes OneVsRestClassifier Model\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "multiClassModel = OneVsRestClassifier(LogisticRegression())\n",
    "y_score = multiClassModel.fit(X_train_bow_US.toarray(),y_train_lb).predict_proba(X_test_bow_US.toarray())\n",
    "\n",
    "##############################################################################################################\n",
    "#Plot ROC-AUC\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fpr=dict()\n",
    "tpr=dict()\n",
    "auc =dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i],tpr[i],_ = roc_curve(y_test_lb[:,i], y_score[:,i])\n",
    "    auc[i] = roc_auc_score(y_test_lb[:,i], y_score[:,i])\n",
    "\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    print('roc_auc_score:',auc[i])\n",
    "    plt.plot([0,1],[0,1], linestyle = '--')\n",
    "    plt.plot(fpr[i],tpr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach-5: Use of Tree-based classifiers - RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score is:1.0 and test score is: 0.954\n",
      "classification_report TRAIN Data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      1.00      1.00        93\n",
      "     Neutral       1.00      1.00      1.00       158\n",
      "    Positive       1.00      1.00      1.00      3749\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "classification_report TEST Data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.29      0.45        24\n",
      "     Neutral       1.00      0.26      0.41        39\n",
      "    Positive       0.95      1.00      0.98       937\n",
      "\n",
      "    accuracy                           0.95      1000\n",
      "   macro avg       0.98      0.52      0.61      1000\n",
      "weighted avg       0.96      0.95      0.94      1000\n",
      "\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#class_weight : {\"balanced\", \"balanced_subsample\"}\n",
    "# Model building using Random Forest classifier\n",
    "model_RFC=RandomForestClassifier(n_estimators=200,class_weight='balanced')\n",
    "model_RFC.fit( X_train_bow.toarray(),y_train)\n",
    "\n",
    "#Get Train and Test Accuracy Score\n",
    "train_score=model_RFC.score(X_train_bow.toarray(),y_train)\n",
    "test_score=model_RFC.score(X_test_bow.toarray(),y_test)\n",
    "print('train score is:{} and test score is: {}'.format(train_score,test_score))\n",
    "\n",
    "#Get precision    recall  and f1-score on Train data\n",
    "cr=classification_report(y_true=y_train,y_pred=model_RFC.predict( X_train_bow.toarray() ))\n",
    "print('classification_report TRAIN Data\\n',cr)\n",
    "\n",
    "#Get precision    recall  and f1-score on Test data\n",
    "cr=classification_report(y_true=y_test,y_pred=model_RFC.predict( X_test_bow.toarray() ))\n",
    "print('classification_report TEST Data\\n',cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach-6: Use of Tree-based classifiers - XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:15:34] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "train score is:0.9905 and test score is: 0.953\n",
      "classification_report TRAIN Data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.96      0.98        93\n",
      "     Neutral       1.00      0.78      0.88       158\n",
      "    Positive       0.99      1.00      0.99      3749\n",
      "\n",
      "    accuracy                           0.99      4000\n",
      "   macro avg       1.00      0.91      0.95      4000\n",
      "weighted avg       0.99      0.99      0.99      4000\n",
      "\n",
      "classification_report TEST Data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.90      0.38      0.53        24\n",
      "     Neutral       0.71      0.26      0.38        39\n",
      "    Positive       0.96      1.00      0.98       937\n",
      "\n",
      "    accuracy                           0.95      1000\n",
      "   macro avg       0.86      0.54      0.63      1000\n",
      "weighted avg       0.95      0.95      0.94      1000\n",
      "\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Model building using XGBoost Classifier\n",
    "model_XGBC=XGBClassifier(scale_pos_weight=98)\n",
    "model_XGBC.fit( X_train_bow.toarray(),y_train)\n",
    "\n",
    "#Get Train and Test Accuracy Score\n",
    "train_score=model_XGBC.score(X_train_bow.toarray(),y_train)\n",
    "test_score=model_XGBC.score(X_test_bow.toarray(),y_test)\n",
    "print('train score is:{} and test score is: {}'.format(train_score,test_score))\n",
    "\n",
    "#Note:The XGBoost documentation suggests a fast way to estimate scale_pos_weight value \n",
    "#using the training dataset as the total number of examples in the majority class \n",
    "#divided by the total number of examples in the minority class\n",
    "\n",
    "#Get precision    recall  and f1-score on Train data\n",
    "cr=classification_report(y_true=y_train,y_pred=model_XGBC.predict( X_train_bow.toarray() ))\n",
    "print('classification_report TRAIN Data\\n',cr)\n",
    "\n",
    "#Get precision    recall  and f1-score on Test data\n",
    "cr=classification_report(y_true=y_test,y_pred=model_XGBC.predict( X_test_bow.toarray() ))\n",
    "print('classification_report TEST Data\\n',cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "\n",
    "**Summary of Model Testing and Evaluation at end of Week-2**\n",
    "\n",
    "| Approach | Avg. F-1 Score(Train) | Avg. F-1 Score(Test) | Wt.Avg. F-1 Score(Test) | Accuracy(Test) |\n",
    "| :--- | :---: | :---: | :---: | :---: |\n",
    "| 1. Oversampling - Naive Bayes | 97 % | 61 % | 61 % | 61 % |\n",
    "| 2. Undersampling - Naive Bayes | 95 % | 71 % | 71 % | 71 % |\n",
    "| 3. Over Sampling - Logistic Regression | 99 % | 62 % | 62 % | 63 % |\n",
    "| 4. Under Sampling - Logistic Regression | 99 % | 66 % | 66 % | 67 % |\n",
    "| 5. Random Forest Classifier | 100 % | 61 % | 94 % | 95.4 % |\n",
    "| 6. XGBoost Classifier | 95 % | 63 % | 94 % | 95.3 % |\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Task: Week 3\n",
    "\n",
    "**Model Selection:**\n",
    "    \n",
    "1. Apply neural nets and multi-class SVM’s. \n",
    "\n",
    "2. Use possible ensemble techniques like: XGboost + oversampled_multinomial_NB.\n",
    "\n",
    "### Code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the train and test dataset \n",
    "# X_train_bow_OS     y_train_OS     --- Over sampling train dataset \n",
    "# X_train_bow_US     y_train_US     ----Undersampling train dataset \n",
    "# X_test_bow_OS      y_test_OS       ----Over sampling Test dataset\n",
    "# X_test_bow_US      y_test_US       ----Under sampling Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Data for Neural Network\n",
    "\n",
    "y_test=test_hidden['sentiment']\n",
    "\n",
    "#Label encoding for Class\n",
    "y_train_NN_OS=y_train_OS.replace(['Positive','Negative','Neutral'],[1,0,2]) # Oversampled\n",
    "y_test_NN_OS=y_test_OS.replace(['Positive','Negative','Neutral'],[1,0,2])   # Oversampled\n",
    "y_train_NN_US=y_train_US.replace(['Positive','Negative','Neutral'],[1,0,2]) # Undersampled \n",
    "y_test_NN_US=y_test_US.replace(['Positive','Negative','Neutral'],[1,0,2])   # Undersampled\n",
    "\n",
    "\n",
    "#Convert class to catagorical\n",
    "y_train_NN_OSC = tf.keras.utils.to_categorical(y_train_NN_OS) # Oversampled\n",
    "y_test_NN_OSC = tf.keras.utils.to_categorical(y_test_NN_OS)   # Oversampled\n",
    "y_train_NN_USC = tf.keras.utils.to_categorical(y_train_NN_US) # Undersampled\n",
    "y_test_NN_USC = tf.keras.utils.to_categorical(y_test_NN_US)   # Undersampled\n",
    "\n",
    "# original dataset\n",
    "y_train_NN=y_train.replace(['Positive','Negative','Neutral'],[1,0,2])\n",
    "y_test_NN=y_test.replace(['Positive','Negative','Neutral'],[1,0,2])\n",
    "y_train_NNC= tf.keras.utils.to_categorical(y_train_NN)\n",
    "y_test_NNC = tf.keras.utils.to_categorical(y_test_NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach-7: Use of Neural Nets with Oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11247 samples, validate on 2811 samples\n",
      "Epoch 1/100\n",
      "11247/11247 [==============================] - 4s 350us/sample - loss: 0.5492 - accuracy: 0.7751 - val_loss: 2.2239 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "11247/11247 [==============================] - 3s 269us/sample - loss: 0.1251 - accuracy: 0.9594 - val_loss: 2.1516 - val_accuracy: 0.5311\n",
      "Epoch 3/100\n",
      "11247/11247 [==============================] - 3s 280us/sample - loss: 0.0805 - accuracy: 0.9755 - val_loss: 2.5313 - val_accuracy: 0.5390\n",
      "Epoch 4/100\n",
      "11247/11247 [==============================] - 3s 277us/sample - loss: 0.0582 - accuracy: 0.9820 - val_loss: 2.3219 - val_accuracy: 0.5841\n",
      "Epoch 5/100\n",
      "11247/11247 [==============================] - 4s 328us/sample - loss: 0.0564 - accuracy: 0.9813 - val_loss: 3.4723 - val_accuracy: 0.5297\n",
      "Epoch 6/100\n",
      "11247/11247 [==============================] - 4s 317us/sample - loss: 0.0505 - accuracy: 0.9839 - val_loss: 3.0897 - val_accuracy: 0.5589\n",
      "Epoch 7/100\n",
      "11247/11247 [==============================] - 3s 280us/sample - loss: 0.0526 - accuracy: 0.9837 - val_loss: 2.2916 - val_accuracy: 0.5930\n",
      "Epoch 8/100\n",
      "11247/11247 [==============================] - 3s 272us/sample - loss: 0.0389 - accuracy: 0.9876 - val_loss: 3.2842 - val_accuracy: 0.5557\n",
      "Epoch 9/100\n",
      "11247/11247 [==============================] - 3s 274us/sample - loss: 0.0405 - accuracy: 0.9867 - val_loss: 3.0045 - val_accuracy: 0.5717\n",
      "Epoch 10/100\n",
      "11247/11247 [==============================] - 3s 273us/sample - loss: 0.0309 - accuracy: 0.9899 - val_loss: 3.2590 - val_accuracy: 0.5688\n",
      "Epoch 11/100\n",
      "11247/11247 [==============================] - 3s 275us/sample - loss: 0.0362 - accuracy: 0.9891 - val_loss: 3.4540 - val_accuracy: 0.5521\n",
      "Epoch 12/100\n",
      "11247/11247 [==============================] - 4s 318us/sample - loss: 0.0387 - accuracy: 0.9881 - val_loss: 3.9891 - val_accuracy: 0.5290\n",
      "Epoch 13/100\n",
      "11247/11247 [==============================] - 3s 300us/sample - loss: 0.0346 - accuracy: 0.9881 - val_loss: 3.2582 - val_accuracy: 0.5735\n",
      "Epoch 14/100\n",
      "11247/11247 [==============================] - 3s 291us/sample - loss: 0.0324 - accuracy: 0.9900 - val_loss: 3.3596 - val_accuracy: 0.5699\n",
      "Epoch 15/100\n",
      "11247/11247 [==============================] - 3s 289us/sample - loss: 0.0260 - accuracy: 0.9919 - val_loss: 3.9859 - val_accuracy: 0.5390\n",
      "Epoch 16/100\n",
      "11247/11247 [==============================] - 3s 297us/sample - loss: 0.0293 - accuracy: 0.9914 - val_loss: 3.6681 - val_accuracy: 0.5503\n",
      "Epoch 17/100\n",
      "11247/11247 [==============================] - 3s 292us/sample - loss: 0.0287 - accuracy: 0.9925 - val_loss: 3.9686 - val_accuracy: 0.5564\n",
      "Epoch 18/100\n",
      "11247/11247 [==============================] - 3s 287us/sample - loss: 0.0303 - accuracy: 0.9900 - val_loss: 3.9459 - val_accuracy: 0.5610\n",
      "Epoch 19/100\n",
      "11247/11247 [==============================] - 3s 288us/sample - loss: 0.0268 - accuracy: 0.9909 - val_loss: 3.6299 - val_accuracy: 0.5582\n",
      "Epoch 20/100\n",
      "11247/11247 [==============================] - 3s 288us/sample - loss: 0.0212 - accuracy: 0.9935 - val_loss: 3.9434 - val_accuracy: 0.5596\n",
      "Epoch 21/100\n",
      "11247/11247 [==============================] - 3s 289us/sample - loss: 0.0257 - accuracy: 0.9920 - val_loss: 3.3303 - val_accuracy: 0.5873\n",
      "Epoch 22/100\n",
      "11247/11247 [==============================] - 3s 285us/sample - loss: 0.0321 - accuracy: 0.9895 - val_loss: 3.4305 - val_accuracy: 0.5671\n",
      "Epoch 23/100\n",
      "11247/11247 [==============================] - 3s 291us/sample - loss: 0.0228 - accuracy: 0.9931 - val_loss: 3.9705 - val_accuracy: 0.5514\n",
      "Epoch 24/100\n",
      "11247/11247 [==============================] - 3s 293us/sample - loss: 0.0201 - accuracy: 0.9945 - val_loss: 3.9316 - val_accuracy: 0.5607\n",
      "Epoch 25/100\n",
      "11247/11247 [==============================] - 3s 291us/sample - loss: 0.0192 - accuracy: 0.9951 - val_loss: 4.8245 - val_accuracy: 0.5297\n",
      "Epoch 26/100\n",
      "11247/11247 [==============================] - 3s 290us/sample - loss: 0.0208 - accuracy: 0.9937 - val_loss: 3.7741 - val_accuracy: 0.5557\n",
      "Epoch 27/100\n",
      "11247/11247 [==============================] - 3s 287us/sample - loss: 0.0202 - accuracy: 0.9938 - val_loss: 3.8783 - val_accuracy: 0.5557\n",
      "Epoch 28/100\n",
      "11247/11247 [==============================] - 3s 286us/sample - loss: 0.0202 - accuracy: 0.9939 - val_loss: 4.1725 - val_accuracy: 0.5468\n",
      "Epoch 29/100\n",
      "11247/11247 [==============================] - 3s 287us/sample - loss: 0.0262 - accuracy: 0.9924 - val_loss: 4.2376 - val_accuracy: 0.5482\n",
      "Epoch 30/100\n",
      "11247/11247 [==============================] - 4s 314us/sample - loss: 0.0197 - accuracy: 0.9936 - val_loss: 3.5749 - val_accuracy: 0.5752\n",
      "Epoch 31/100\n",
      "11247/11247 [==============================] - 4s 312us/sample - loss: 0.0243 - accuracy: 0.9925 - val_loss: 3.6821 - val_accuracy: 0.5578\n",
      "Epoch 32/100\n",
      "11247/11247 [==============================] - 3s 304us/sample - loss: 0.0200 - accuracy: 0.9948 - val_loss: 3.9914 - val_accuracy: 0.5599\n",
      "Epoch 33/100\n",
      "11247/11247 [==============================] - 3s 284us/sample - loss: 0.0134 - accuracy: 0.9964 - val_loss: 3.4859 - val_accuracy: 0.5902\n",
      "Epoch 34/100\n",
      "11247/11247 [==============================] - 3s 285us/sample - loss: 0.0191 - accuracy: 0.9942 - val_loss: 3.5368 - val_accuracy: 0.5838\n",
      "Epoch 35/100\n",
      "11247/11247 [==============================] - 3s 285us/sample - loss: 0.0207 - accuracy: 0.9940 - val_loss: 4.3233 - val_accuracy: 0.5546\n",
      "Epoch 36/100\n",
      "11247/11247 [==============================] - 3s 287us/sample - loss: 0.0167 - accuracy: 0.9950 - val_loss: 3.6656 - val_accuracy: 0.5852\n",
      "Epoch 37/100\n",
      "11247/11247 [==============================] - 3s 286us/sample - loss: 0.0125 - accuracy: 0.9963 - val_loss: 4.4539 - val_accuracy: 0.5582\n",
      "Epoch 38/100\n",
      "11247/11247 [==============================] - 3s 289us/sample - loss: 0.0152 - accuracy: 0.9957 - val_loss: 4.4842 - val_accuracy: 0.5411\n",
      "Epoch 39/100\n",
      "11247/11247 [==============================] - 3s 291us/sample - loss: 0.0176 - accuracy: 0.9947 - val_loss: 3.1575 - val_accuracy: 0.6073\n",
      "Epoch 40/100\n",
      "11247/11247 [==============================] - 3s 289us/sample - loss: 0.0126 - accuracy: 0.9961 - val_loss: 4.1131 - val_accuracy: 0.5710\n",
      "Epoch 41/100\n",
      "11247/11247 [==============================] - 3s 293us/sample - loss: 0.0147 - accuracy: 0.9960 - val_loss: 3.7518 - val_accuracy: 0.5838\n",
      "Epoch 42/100\n",
      "11247/11247 [==============================] - 3s 297us/sample - loss: 0.0147 - accuracy: 0.9950 - val_loss: 4.4551 - val_accuracy: 0.5539\n",
      "Epoch 43/100\n",
      "11247/11247 [==============================] - 3s 294us/sample - loss: 0.0118 - accuracy: 0.9964 - val_loss: 4.1447 - val_accuracy: 0.5738\n",
      "Epoch 44/100\n",
      "11247/11247 [==============================] - 3s 298us/sample - loss: 0.0125 - accuracy: 0.9967 - val_loss: 4.2848 - val_accuracy: 0.5575\n",
      "Epoch 45/100\n",
      "11247/11247 [==============================] - 3s 300us/sample - loss: 0.0211 - accuracy: 0.9942 - val_loss: 4.7339 - val_accuracy: 0.5585\n",
      "Epoch 46/100\n",
      "11247/11247 [==============================] - 3s 290us/sample - loss: 0.0143 - accuracy: 0.9961 - val_loss: 3.9421 - val_accuracy: 0.5777\n",
      "Epoch 47/100\n",
      "11247/11247 [==============================] - 3s 294us/sample - loss: 0.0125 - accuracy: 0.9965 - val_loss: 4.3081 - val_accuracy: 0.5624\n",
      "Epoch 48/100\n",
      "11247/11247 [==============================] - 3s 296us/sample - loss: 0.0107 - accuracy: 0.9969 - val_loss: 4.4584 - val_accuracy: 0.5589\n",
      "Epoch 49/100\n",
      "11247/11247 [==============================] - 3s 291us/sample - loss: 0.0140 - accuracy: 0.9963 - val_loss: 3.9115 - val_accuracy: 0.5774\n",
      "Epoch 50/100\n",
      "11247/11247 [==============================] - 3s 290us/sample - loss: 0.0131 - accuracy: 0.9959 - val_loss: 4.2632 - val_accuracy: 0.5642\n",
      "Epoch 51/100\n",
      "11247/11247 [==============================] - 3s 290us/sample - loss: 0.0120 - accuracy: 0.9965 - val_loss: 4.1763 - val_accuracy: 0.5656\n",
      "Epoch 52/100\n",
      "11247/11247 [==============================] - 3s 288us/sample - loss: 0.0113 - accuracy: 0.9970 - val_loss: 4.6714 - val_accuracy: 0.5535\n",
      "Epoch 53/100\n",
      "11247/11247 [==============================] - 3s 301us/sample - loss: 0.0073 - accuracy: 0.9980 - val_loss: 4.7059 - val_accuracy: 0.5607\n",
      "Epoch 54/100\n",
      "11247/11247 [==============================] - 3s 287us/sample - loss: 0.0126 - accuracy: 0.9958 - val_loss: 4.2046 - val_accuracy: 0.5774\n",
      "Epoch 55/100\n",
      "11247/11247 [==============================] - 3s 289us/sample - loss: 0.0152 - accuracy: 0.9957 - val_loss: 4.6116 - val_accuracy: 0.5557\n",
      "Epoch 56/100\n",
      "11247/11247 [==============================] - 3s 284us/sample - loss: 0.0121 - accuracy: 0.9961 - val_loss: 5.4548 - val_accuracy: 0.5390\n",
      "Epoch 57/100\n",
      "11247/11247 [==============================] - 3s 286us/sample - loss: 0.0107 - accuracy: 0.9964 - val_loss: 4.2153 - val_accuracy: 0.5738\n",
      "Epoch 58/100\n",
      "11247/11247 [==============================] - 3s 285us/sample - loss: 0.0106 - accuracy: 0.9967 - val_loss: 5.3721 - val_accuracy: 0.5454\n",
      "Epoch 59/100\n",
      "11247/11247 [==============================] - 3s 305us/sample - loss: 0.0095 - accuracy: 0.9971 - val_loss: 5.3265 - val_accuracy: 0.5446\n",
      "Epoch 60/100\n",
      "11247/11247 [==============================] - 3s 308us/sample - loss: 0.0129 - accuracy: 0.9957 - val_loss: 4.2956 - val_accuracy: 0.5752\n",
      "Epoch 61/100\n",
      "11247/11247 [==============================] - 3s 307us/sample - loss: 0.0146 - accuracy: 0.9956 - val_loss: 4.5594 - val_accuracy: 0.5695\n",
      "Epoch 62/100\n",
      "11247/11247 [==============================] - 3s 288us/sample - loss: 0.0074 - accuracy: 0.9974 - val_loss: 4.8020 - val_accuracy: 0.5671\n",
      "Epoch 63/100\n",
      "11247/11247 [==============================] - 3s 285us/sample - loss: 0.0091 - accuracy: 0.9975 - val_loss: 4.5800 - val_accuracy: 0.5763\n",
      "Epoch 64/100\n",
      "11247/11247 [==============================] - 3s 284us/sample - loss: 0.0091 - accuracy: 0.9977 - val_loss: 4.9846 - val_accuracy: 0.5518\n",
      "Epoch 65/100\n",
      "11247/11247 [==============================] - 3s 287us/sample - loss: 0.0096 - accuracy: 0.9972 - val_loss: 4.0135 - val_accuracy: 0.5770\n",
      "Epoch 66/100\n",
      "11247/11247 [==============================] - 3s 285us/sample - loss: 0.0067 - accuracy: 0.9986 - val_loss: 4.8264 - val_accuracy: 0.5539\n",
      "Epoch 67/100\n",
      "11247/11247 [==============================] - 3s 284us/sample - loss: 0.0100 - accuracy: 0.9972 - val_loss: 3.9235 - val_accuracy: 0.5827\n",
      "Epoch 68/100\n",
      "11247/11247 [==============================] - 3s 287us/sample - loss: 0.0085 - accuracy: 0.9974 - val_loss: 3.7601 - val_accuracy: 0.6073\n",
      "Epoch 69/100\n",
      "11247/11247 [==============================] - 3s 287us/sample - loss: 0.0089 - accuracy: 0.9973 - val_loss: 4.8620 - val_accuracy: 0.5589\n",
      "Epoch 70/100\n",
      "11247/11247 [==============================] - 3s 286us/sample - loss: 0.0117 - accuracy: 0.9971 - val_loss: 4.5473 - val_accuracy: 0.5667\n",
      "Epoch 71/100\n",
      "11247/11247 [==============================] - 3s 286us/sample - loss: 0.0093 - accuracy: 0.9972 - val_loss: 5.0245 - val_accuracy: 0.5589\n",
      "Epoch 72/100\n",
      "11247/11247 [==============================] - 3s 290us/sample - loss: 0.0073 - accuracy: 0.9982 - val_loss: 4.0770 - val_accuracy: 0.5646\n",
      "Epoch 73/100\n",
      "11247/11247 [==============================] - 3s 290us/sample - loss: 0.0093 - accuracy: 0.9975 - val_loss: 5.7128 - val_accuracy: 0.5379\n",
      "Epoch 74/100\n",
      "11247/11247 [==============================] - 3s 289us/sample - loss: 0.0075 - accuracy: 0.9979 - val_loss: 4.1049 - val_accuracy: 0.5706\n",
      "Epoch 75/100\n",
      "11247/11247 [==============================] - 3s 289us/sample - loss: 0.0068 - accuracy: 0.9983 - val_loss: 4.8975 - val_accuracy: 0.5599\n",
      "Epoch 76/100\n",
      "11247/11247 [==============================] - 3s 290us/sample - loss: 0.0077 - accuracy: 0.9979 - val_loss: 4.2953 - val_accuracy: 0.5763\n",
      "Epoch 77/100\n",
      "11247/11247 [==============================] - 3s 288us/sample - loss: 0.0084 - accuracy: 0.9972 - val_loss: 4.6230 - val_accuracy: 0.5685\n",
      "Epoch 78/100\n",
      "11247/11247 [==============================] - 3s 288us/sample - loss: 0.0077 - accuracy: 0.9977 - val_loss: 4.2035 - val_accuracy: 0.5681\n",
      "Epoch 79/100\n",
      "11247/11247 [==============================] - 3s 288us/sample - loss: 0.0077 - accuracy: 0.9977 - val_loss: 4.4303 - val_accuracy: 0.5603\n",
      "Epoch 80/100\n",
      "11247/11247 [==============================] - 3s 298us/sample - loss: 0.0057 - accuracy: 0.9981 - val_loss: 3.5944 - val_accuracy: 0.6282\n",
      "Epoch 81/100\n",
      "11247/11247 [==============================] - 3s 287us/sample - loss: 0.0060 - accuracy: 0.9979 - val_loss: 5.2119 - val_accuracy: 0.5486\n",
      "Epoch 82/100\n",
      "11247/11247 [==============================] - 3s 286us/sample - loss: 0.0057 - accuracy: 0.9983 - val_loss: 4.5223 - val_accuracy: 0.5663\n",
      "Epoch 83/100\n",
      "11247/11247 [==============================] - 3s 293us/sample - loss: 0.0076 - accuracy: 0.9980 - val_loss: 4.5840 - val_accuracy: 0.5585\n",
      "Epoch 84/100\n",
      "11247/11247 [==============================] - 3s 289us/sample - loss: 0.0057 - accuracy: 0.9979 - val_loss: 4.3932 - val_accuracy: 0.5727\n",
      "Epoch 85/100\n",
      "11247/11247 [==============================] - 4s 311us/sample - loss: 0.0089 - accuracy: 0.9975 - val_loss: 5.0657 - val_accuracy: 0.5567\n",
      "Epoch 86/100\n",
      "11247/11247 [==============================] - 3s 289us/sample - loss: 0.0075 - accuracy: 0.9975 - val_loss: 5.3126 - val_accuracy: 0.5503\n",
      "Epoch 87/100\n",
      "11247/11247 [==============================] - 3s 289us/sample - loss: 0.0049 - accuracy: 0.9986 - val_loss: 4.8083 - val_accuracy: 0.5745\n",
      "Epoch 88/100\n",
      "11247/11247 [==============================] - 3s 305us/sample - loss: 0.0064 - accuracy: 0.9978 - val_loss: 4.5340 - val_accuracy: 0.5912\n",
      "Epoch 89/100\n",
      "11247/11247 [==============================] - 4s 312us/sample - loss: 0.0034 - accuracy: 0.9989 - val_loss: 5.3632 - val_accuracy: 0.5631\n",
      "Epoch 90/100\n",
      "11247/11247 [==============================] - 4s 312us/sample - loss: 0.0071 - accuracy: 0.9983 - val_loss: 3.8534 - val_accuracy: 0.6009\n",
      "Epoch 91/100\n",
      "11247/11247 [==============================] - 3s 289us/sample - loss: 0.0069 - accuracy: 0.9981 - val_loss: 4.8660 - val_accuracy: 0.5678\n",
      "Epoch 92/100\n",
      "11247/11247 [==============================] - 3s 292us/sample - loss: 0.0051 - accuracy: 0.9986 - val_loss: 4.8277 - val_accuracy: 0.5717\n",
      "Epoch 93/100\n",
      "11247/11247 [==============================] - 3s 288us/sample - loss: 0.0047 - accuracy: 0.9986 - val_loss: 4.2006 - val_accuracy: 0.6069\n",
      "Epoch 94/100\n",
      "11247/11247 [==============================] - 3s 286us/sample - loss: 0.0087 - accuracy: 0.9972 - val_loss: 3.8676 - val_accuracy: 0.5969\n",
      "Epoch 95/100\n",
      "11247/11247 [==============================] - 3s 287us/sample - loss: 0.0053 - accuracy: 0.9986 - val_loss: 4.4236 - val_accuracy: 0.5859\n",
      "Epoch 96/100\n",
      "11247/11247 [==============================] - 3s 287us/sample - loss: 0.0064 - accuracy: 0.9980 - val_loss: 4.3826 - val_accuracy: 0.5838\n",
      "Epoch 97/100\n",
      "11247/11247 [==============================] - 3s 286us/sample - loss: 0.0038 - accuracy: 0.9988 - val_loss: 4.3855 - val_accuracy: 0.6033\n",
      "Epoch 98/100\n",
      "11247/11247 [==============================] - 3s 286us/sample - loss: 0.0041 - accuracy: 0.9990 - val_loss: 4.7588 - val_accuracy: 0.5760\n",
      "Epoch 99/100\n",
      "11247/11247 [==============================] - 3s 289us/sample - loss: 0.0085 - accuracy: 0.9976 - val_loss: 4.4732 - val_accuracy: 0.5770\n",
      "Epoch 100/100\n",
      "11247/11247 [==============================] - 3s 295us/sample - loss: 0.0067 - accuracy: 0.9977 - val_loss: 3.6637 - val_accuracy: 0.6087\n",
      "Wall time: 5min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2145c72de88>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Initialize Sequential model\n",
    "modelNN_OS = tf.keras.models.Sequential()\n",
    "# Create Input layer\n",
    "modelNN_OS.add(tf.keras.layers.Reshape((4342,),input_shape=(4342,)))\n",
    "#Normalize the data\n",
    "modelNN_OS.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add 1st hidden layer\n",
    "modelNN_OS.add(tf.keras.layers.Dense(200, activation='relu'))\n",
    "modelNN_OS.add(tf.keras.layers.Dropout(0.5)) #Dropout layer\n",
    "modelNN_OS.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add 2nd hidden layer\n",
    "modelNN_OS.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "modelNN_OS.add(tf.keras.layers.Dropout(0.5)) #Dropout layer\n",
    "modelNN_OS.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "#Add 3rd hidden layer\n",
    "modelNN_OS.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "modelNN_OS.add(tf.keras.layers.Dropout(0.3)) #Dropout layer\n",
    "modelNN_OS.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "#Add OUTPUT layer\n",
    "modelNN_OS.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "#Create optimizer with non-default learning rate\n",
    "#sgd_optimizer = tf.keras.optimizers.SGD(lr=0.1)\n",
    "\n",
    "#Compile the model\n",
    "#modelNN_OS.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Compile the model with adam optimizer\n",
    "modelNN_OS.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "## Train the model\n",
    "modelNN_OS.fit(X_train_bow_OS.toarray(),y_train_NN_OSC,          \n",
    "          validation_data=(X_test_bow_OS.toarray(),y_test_NN_OSC),\n",
    "          epochs=100,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy score is: 0.9985773984173557 and Test Accuracy score is: 0.608680184987549\n",
      "-------------------------------------------------------------------------------------------\n",
      "Classification Report for Train Data \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3749\n",
      "           1       1.00      1.00      1.00      3749\n",
      "           2       1.00      1.00      1.00      3749\n",
      "\n",
      "    accuracy                           1.00     11247\n",
      "   macro avg       1.00      1.00      1.00     11247\n",
      "weighted avg       1.00      1.00      1.00     11247\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "Classification Report for Test Data \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.51      0.65       937\n",
      "           1       0.49      0.95      0.64       937\n",
      "           2       0.76      0.37      0.50       937\n",
      "\n",
      "    accuracy                           0.61      2811\n",
      "   macro avg       0.71      0.61      0.60      2811\n",
      "weighted avg       0.71      0.61      0.60      2811\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict  classes\n",
    "yhat_classes_train = modelNN_OS.predict_classes(X_train_bow_OS.toarray(), verbose=0)\n",
    "yhat_classes_test = modelNN_OS.predict_classes(X_test_bow_OS.toarray(), verbose=0)\n",
    "\n",
    "#Accuracy Score for train Data\n",
    "accuracy_score_train=accuracy_score(y_true=y_train_NN_OS,y_pred=yhat_classes_train)\n",
    "#Accuracy Score for test Data\n",
    "accuracy_score_test=accuracy_score(y_true=y_test_NN_OS,y_pred=yhat_classes_test)\n",
    "print('Train Accuracy score is: {} and Test Accuracy score is: {}'.format(accuracy_score_train,accuracy_score_test))\n",
    "print('-------------------------------------------------------------------------------------------')\n",
    "\n",
    "#Classification Report for Train Data\n",
    "cr=classification_report(y_true=y_train_NN_OS,y_pred=yhat_classes_train)\n",
    "print('Classification Report for Train Data \\n',cr)\n",
    "print('-------------------------------------------------------------------------------------------')\n",
    "\n",
    "#Classification Report for Test Data\n",
    "cr=classification_report(y_true=y_test_NN_OS,y_pred=yhat_classes_test)\n",
    "print('Classification Report for Test Data \\n',cr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations of Neural Network- Oversampled Data\n",
    "# Num of Layers        batch size     Epochs     optimizer         Train Accuracy   Test Accuracy   f1.Score(Test)\n",
    "#       3                  32           10          Adam                99.83 %           57.84 %        55.0 %\n",
    "#       3(WithDropout)     32           10          Adam                99.84 %           55.60 %        53.0 %\n",
    "#       3                  32           10          Adam                99.83 %          100.00 %        55.9 %\n",
    "#       3(WithDropout)     32           10          SGD(lr=0.1)         99.85 %           57.56 %        56.0 %\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach-8: Use of Neural Nets with Undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.48 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2766e0e47c8>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Initialize Sequential model\n",
    "modelNN_US = tf.keras.models.Sequential()\n",
    "# Create Input layer\n",
    "modelNN_US.add(tf.keras.layers.Reshape((4342,),input_shape=(4342,)))\n",
    "#Normalize the data\n",
    "modelNN_US.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add 1st hidden layer\n",
    "modelNN_US.add(tf.keras.layers.Dense(200, activation='relu'))\n",
    "modelNN_OS.add(tf.keras.layers.Dropout(0.5)) #Dropout layer\n",
    "modelNN_US.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add 2nd hidden layer\n",
    "modelNN_US.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "modelNN_OS.add(tf.keras.layers.Dropout(0.5)) #Dropout layer\n",
    "modelNN_US.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add 3rd hidden layer\n",
    "modelNN_US.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "modelNN_OS.add(tf.keras.layers.Dropout(0.2)) #Dropout layer\n",
    "modelNN_US.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "#Add OUTPUT layer\n",
    "modelNN_US.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "#Create optimizer with non-default learning rate\n",
    "#sgd_optimizer = tf.keras.optimizers.SGD(lr=0.1)\n",
    "\n",
    "#Compile the model\n",
    "#modelNN_US.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Compile the model with adam optimizer\n",
    "modelNN_US.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "## Train the model\n",
    "modelNN_US.fit(X_train_bow_US.toarray(),y_train_NN_USC,          \n",
    "          validation_data=(X_test_bow_US.toarray(),y_test_NN_USC),\n",
    "          epochs=50,\n",
    "          batch_size=32,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy score is: 1.0 and Test Accuracy score is: 0.5694444444444444\n",
      "-------------------------------------------------------------------------------------------\n",
      "Classification Report for Train Data \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        93\n",
      "           1       1.00      1.00      1.00        93\n",
      "           2       1.00      1.00      1.00        93\n",
      "\n",
      "    accuracy                           1.00       279\n",
      "   macro avg       1.00      1.00      1.00       279\n",
      "weighted avg       1.00      1.00      1.00       279\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "Classification Report for Test Data \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.42      0.51        24\n",
      "           1       0.68      0.62      0.65        24\n",
      "           2       0.46      0.67      0.54        24\n",
      "\n",
      "    accuracy                           0.57        72\n",
      "   macro avg       0.60      0.57      0.57        72\n",
      "weighted avg       0.60      0.57      0.57        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict  classes\n",
    "yhat_classes_train = modelNN_US.predict_classes(X_train_bow_US.toarray(), verbose=0)\n",
    "yhat_classes_test = modelNN_US.predict_classes(X_test_bow_US.toarray(), verbose=0)\n",
    "\n",
    "#Accuracy Score for train Data\n",
    "accuracy_score_train=accuracy_score(y_true=y_train_NN_US,y_pred=yhat_classes_train)\n",
    "#Accuracy Score for test Data\n",
    "accuracy_score_test=accuracy_score(y_true=y_test_NN_US,y_pred=yhat_classes_test)\n",
    "print('Train Accuracy score is: {} and Test Accuracy score is: {}'.format(accuracy_score_train,accuracy_score_test))\n",
    "print('-------------------------------------------------------------------------------------------')\n",
    "\n",
    "#Classification Report for Train Data\n",
    "cr=classification_report(y_true=y_train_NN_US,y_pred=yhat_classes_train)\n",
    "print('Classification Report for Train Data \\n',cr)\n",
    "print('-------------------------------------------------------------------------------------------')\n",
    "\n",
    "#Classification Report for Test Data\n",
    "cr=classification_report(y_true=y_test_NN_US,y_pred=yhat_classes_test)\n",
    "print('Classification Report for Test Data \\n',cr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations of Neural Network- Undersampled Data\n",
    "# Num of Layers        batch size     Epochs     optimizer         Train Accuracy   Test Accuracy   f1.Score(Test)\n",
    "#      3                  32           50          SGD(lr=0.1)         100.00 %           60.10 %        61.0 %\n",
    "#      3(WithDropout)     32           50          SGD(lr=0.1)         100.00 %           63.88 %        64.0 %\n",
    "#      3(WithDropout)     32           50          adam                 98.92 %           63.88 %        65.3 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach-9: Use of Neural Nets with Original dataset(Imbalance Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 55.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2771039ba88>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Initialize Sequential model\n",
    "modelNN_imb = tf.keras.models.Sequential()\n",
    "# Create Input layer\n",
    "modelNN_imb.add(tf.keras.layers.Reshape((4342,),input_shape=(4342,)))\n",
    "#Normalize the data\n",
    "modelNN_imb.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add 1st hidden layer\n",
    "modelNN_imb.add(tf.keras.layers.Dense(200, activation='relu'))\n",
    "modelNN_imb.add(tf.keras.layers.Dropout(0.5)) #Dropout layer\n",
    "modelNN_imb.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add 2nd hidden layer\n",
    "modelNN_imb.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "modelNN_imb.add(tf.keras.layers.Dropout(0.5)) #Dropout layer\n",
    "modelNN_imb.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "#Add 3rd hidden layer\n",
    "modelNN_imb.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "modelNN_imb.add(tf.keras.layers.Dropout(0.2)) #Dropout layer\n",
    "modelNN_OS.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add OUTPUT layer\n",
    "modelNN_imb.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "#Create optimizer with non-default learning rate\n",
    "#sgd_optimizer = tf.keras.optimizers.SGD(lr=0.1)\n",
    "\n",
    "#Compile the model\n",
    "#modelNN_imb.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Compile the model with adam optimizer\n",
    "modelNN_imb.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "## Train the model\n",
    "modelNN_imb.fit(X_train_bow.toarray(),y_train_NNC,          \n",
    "          validation_data=(X_test_bow.toarray(),y_test_NNC),\n",
    "          epochs=50,\n",
    "          batch_size=32,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy score is: 0.9965 and Test Accuracy score is: 0.935\n",
      "-------------------------------------------------------------------------------------------\n",
      "Classification Report for Train Data \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        93\n",
      "           1       1.00      1.00      1.00      3749\n",
      "           2       0.97      1.00      0.98       158\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       0.96      1.00      0.98      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "Classification Report for Test Data \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.50      0.45        24\n",
      "           1       0.97      0.97      0.97       937\n",
      "           2       0.42      0.44      0.43        39\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.60      0.63      0.62      1000\n",
      "weighted avg       0.94      0.94      0.94      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict  classes\n",
    "yhat_classes_train = modelNN_imb.predict_classes(X_train_bow.toarray(), verbose=0)\n",
    "yhat_classes_test = modelNN_imb.predict_classes(X_test_bow.toarray(), verbose=0)\n",
    "\n",
    "#Accuracy Score for train Data\n",
    "accuracy_score_train=accuracy_score(y_true=y_train_NN,y_pred=yhat_classes_train)\n",
    "#Accuracy Score for test Data\n",
    "accuracy_score_test=accuracy_score(y_true=y_test_NN,y_pred=yhat_classes_test)\n",
    "print('Train Accuracy score is: {} and Test Accuracy score is: {}'.format(accuracy_score_train,accuracy_score_test))\n",
    "print('-------------------------------------------------------------------------------------------')\n",
    "\n",
    "#Classification Report for Train Data\n",
    "cr=classification_report(y_true=y_train_NN,y_pred=yhat_classes_train)\n",
    "print('Classification Report for Train Data \\n',cr)\n",
    "print('-------------------------------------------------------------------------------------------')\n",
    "#Classification Report for Test Data\n",
    "cr=classification_report(y_true=y_test_NN,y_pred=yhat_classes_test)\n",
    "print('Classification Report for Test Data \\n',cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations of Neural Network- Original Imbalanced Dataset\n",
    "# Num of Layers        batch size     Epochs     optimizer         Train Accuracy   Test Accuracy   f1.Score(Test)\n",
    "#       3                  32           50          Adam                99.60 %           92.00 %        58.0 %\n",
    "#       3(WithDropout)     32           10          Adam                99.65 %           93.50 %        62.0 %\n",
    "#       3                  32           10          SGD(lr=0.1)         99.25 %           90.05 %        57.0 %\n",
    "#       3(WithDropout)     32           10          SGD(lr=0.1)         99.60 %           90.70 %        59.0 %\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach-10: Use of Multiclass SVM with Undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score is:1.0 \n",
      "test score is:0.5972222222222222 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      1.00      1.00        93\n",
      "     Neutral       1.00      1.00      1.00        93\n",
      "    Positive       1.00      1.00      1.00        93\n",
      "\n",
      "    accuracy                           1.00       279\n",
      "   macro avg       1.00      1.00      1.00       279\n",
      "weighted avg       1.00      1.00      1.00       279\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.65      0.62      0.64        24\n",
      "     Neutral       0.50      0.71      0.59        24\n",
      "    Positive       0.73      0.46      0.56        24\n",
      "\n",
      "    accuracy                           0.60        72\n",
      "   macro avg       0.63      0.60      0.60        72\n",
      "weighted avg       0.63      0.60      0.60        72\n",
      "\n",
      "Wall time: 1.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "#Model building using Multiclass SVM\n",
    "model_SVC_US = SVC()\n",
    "model_SVC_US.fit( X_train_bow_US.toarray(),y_train_US)\n",
    "\n",
    "#Get Train and Test Accuracy Score\n",
    "train_score=model_SVC_US.score(X_train_bow_US.toarray(),y_train_US)\n",
    "test_score=model_SVC_US.score(X_test_bow_US.toarray(),y_test_US)\n",
    "print('train score is:{} '.format(train_score))\n",
    "print('test score is:{} '.format(test_score))\n",
    "\n",
    "#Get precision    recall  and f1-score on Train data\n",
    "cr=classification_report(y_true=y_train_US,y_pred=model_SVC_US.predict( X_train_bow_US.toarray() ))\n",
    "print(cr)\n",
    "\n",
    "#Get precision    recall  and f1-score on Test data\n",
    "cr=classification_report(y_true=y_test_US,y_pred=model_SVC_US.predict( X_test_bow_US.toarray() ))\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach-11: Use of Multiclass SVM with Oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score is:1.0 \n",
      "test score is:0.954 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      1.00      1.00      3749\n",
      "     Neutral       1.00      1.00      1.00      3749\n",
      "    Positive       1.00      1.00      1.00      3749\n",
      "\n",
      "    accuracy                           1.00     11247\n",
      "   macro avg       1.00      1.00      1.00     11247\n",
      "weighted avg       1.00      1.00      1.00     11247\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.29      0.45        24\n",
      "     Neutral       1.00      0.26      0.41        39\n",
      "    Positive       0.95      1.00      0.98       937\n",
      "\n",
      "    accuracy                           0.95      1000\n",
      "   macro avg       0.98      0.52      0.61      1000\n",
      "weighted avg       0.96      0.95      0.94      1000\n",
      "\n",
      "Wall time: 10min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Model building using Multiclass SVM\n",
    "model_SVC_OS = SVC()\n",
    "model_SVC_OS.fit( X_train_bow_OS.toarray(),y_train_OS)\n",
    "\n",
    "#Get Train and Test Accuracy Score\n",
    "train_score=model_SVC_OS.score(X_train_bow_OS.toarray(),y_train_OS)\n",
    "test_score=model_SVC_OS.score(X_test_bow.toarray(),y_test)\n",
    "print('train score is:{} '.format(train_score))\n",
    "print('test score is:{} '.format(test_score))\n",
    "\n",
    "#Get precision    recall  and f1-score on Train data\n",
    "cr=classification_report(y_true=y_train_OS,y_pred=model_SVC_OS.predict( X_train_bow_OS.toarray() ))\n",
    "print(cr)\n",
    "\n",
    "#Get precision    recall  and f1-score on Test data\n",
    "cr=classification_report(y_true=y_test,y_pred=model_SVC_OS.predict( X_test_bow.toarray() ))\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 12: Use of Ensemble Technique(oversampled multinomial_NB+Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score is:0.9723481817373522 and test score is: 0.6360725720384205\n",
      "classification_report TRAIN Data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.98      1.00      0.99      3749\n",
      "     Neutral       0.94      1.00      0.97      3749\n",
      "    Positive       1.00      0.92      0.96      3749\n",
      "\n",
      "    accuracy                           0.97     11247\n",
      "   macro avg       0.97      0.97      0.97     11247\n",
      "weighted avg       0.97      0.97      0.97     11247\n",
      "\n",
      "classification_report TEST Data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.87      0.59      0.70       937\n",
      "     Neutral       0.65      0.45      0.54       937\n",
      "    Positive       0.53      0.86      0.66       937\n",
      "\n",
      "    accuracy                           0.64      2811\n",
      "   macro avg       0.68      0.64      0.63      2811\n",
      "weighted avg       0.68      0.64      0.63      2811\n",
      "\n",
      "Wall time: 5.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 11.Ensemble Learning\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "model_ensemble = VotingClassifier([('M1', model_MNB_OS), \n",
    "                                  ('M2', model_LR_OS)\n",
    "                                 ]\n",
    "                                )\n",
    "model_ensemble.fit( X_train_bow_OS.toarray(),y_train_OS)\n",
    "#Get Train and Test Accuracy Score\n",
    "train_score=model_ensemble.score(X_train_bow_OS.toarray(),y_train_OS)\n",
    "test_score=model_ensemble.score(X_test_bow_OS.toarray(),y_test_OS)\n",
    "print('train score is:{} and test score is: {}'.format(train_score,test_score))\n",
    "\n",
    "#Get precision    recall  and f1-score on Train data\n",
    "cr=classification_report(y_true=y_train_OS,y_pred=model_ensemble.predict( X_train_bow_OS.toarray() ))\n",
    "print('classification_report TRAIN Data\\n',cr)\n",
    "\n",
    "#Get precision    recall  and f1-score on Test data\n",
    "cr=classification_report(y_true=y_test_OS,y_pred=model_ensemble.predict( X_test_bow_OS.toarray() ))\n",
    "print('classification_report TEST Data\\n',cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 13: Use of Ensemble Technique(oversampled_multinomial_NB+XGboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:16:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "train score is:0.9731483951275895 and test score is: 0.6705798648167912\n",
      "classification_report TRAIN Data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.98      1.00      0.99      3749\n",
      "     Neutral       0.95      1.00      0.97      3749\n",
      "    Positive       1.00      0.92      0.96      3749\n",
      "\n",
      "    accuracy                           0.97     11247\n",
      "   macro avg       0.97      0.97      0.97     11247\n",
      "weighted avg       0.97      0.97      0.97     11247\n",
      "\n",
      "classification_report TEST Data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.84      0.62      0.72       937\n",
      "     Neutral       0.65      0.53      0.58       937\n",
      "    Positive       0.60      0.86      0.71       937\n",
      "\n",
      "    accuracy                           0.67      2811\n",
      "   macro avg       0.69      0.67      0.67      2811\n",
      "weighted avg       0.69      0.67      0.67      2811\n",
      "\n",
      "Wall time: 3min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 11.Ensemble Learning\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "model_ensemble = VotingClassifier([('M1', model_MNB_OS), \n",
    "                                  ('M2', model_XGBC)\n",
    "                                 ]\n",
    "                                )\n",
    "model_ensemble.fit( X_train_bow_OS.toarray(),y_train_OS)\n",
    "#Get Train and Test Accuracy Score\n",
    "train_score=model_ensemble.score(X_train_bow_OS.toarray(),y_train_OS)\n",
    "test_score=model_ensemble.score(X_test_bow_OS.toarray(),y_test_OS)\n",
    "print('train score is:{} and test score is: {}'.format(train_score,test_score))\n",
    "\n",
    "#Get precision    recall  and f1-score on Train data\n",
    "cr=classification_report(y_true=y_train_OS,y_pred=model_ensemble.predict( X_train_bow_OS.toarray() ))\n",
    "print('classification_report TRAIN Data\\n',cr)\n",
    "\n",
    "#Get precision    recall  and f1-score on Test data\n",
    "cr=classification_report(y_true=y_test_OS,y_pred=model_ensemble.predict( X_test_bow_OS.toarray() ))\n",
    "print('classification_report TEST Data\\n',cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "\n",
    "**Summary of Model Testing and Evaluation at end of Week-3**\n",
    "\n",
    "| Approach | Avg. F-1 Score(Train) | Avg. F-1 Score(Test) | Wt.Avg. F-1 Score(Test) | Accuracy(Test) |\n",
    "| :--- | :---: | :---: | :---: | :---: |\n",
    "| 1. Oversampling - Naive Bayes | 97 % | 61 % | 61 % | 61 % |\n",
    "| 2. Undersampling - Naive Bayes | 95 % | 71 % | 71 % | 71 % |\n",
    "| 3. Over Sampling - Logistic Regression | 99 % | 62 % | 62 % | 63 % |\n",
    "| 4. Under Sampling - Logistic Regression | 99 % | 66 % | 66 % | 67 % |\n",
    "| 5. Random Forest Classifier | 100 % | 61 % | 94 % | 95 % |\n",
    "| 6. XGBoost Classifier | 95 % | 63 % | 94 % | 95 % |\n",
    "| 7. Over Sampling - Neural Network | 100 % | 58 % | 58 % | 58 % |\n",
    "| 8. Under Sampling - Neural Network | 100 % | 57 % | 57 % | 57 % |\n",
    "| 9. Neural Network with Original data(imbalance dataset) | 98 % | 62 % | 94 % | 94 % |\n",
    "| 10. Oversampling - SVM | 100 % | 61 % | 94 % | 95 % |\n",
    "| 11. Undersampling - SVM | 100 % | 60 % | 60 % | 60 % |\n",
    "| 12. Ensemble Technique(Oversampled Naive Bayes+LogisticReg) | 97 % | 63 % | 63 % | 64 % |\n",
    "| 13. Ensemble Technique(Oversampled Naive Bayes+XGBoost) | 97 % | 67 % | 67 % | 67 % |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week4 Tasks: Approach 14: Implement LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Task: Week 4\n",
    "\n",
    "**Applying LSTM::**\n",
    "    \n",
    "1. Use LSTM for the previous problem (use parameters of LSTM like top-word, embedding-length, Dropout, epochs, number of layers, etc.). \n",
    "\n",
    "2. Compare the accuracy of neural nets with traditional ML based algorithms.\n",
    "\n",
    "3. Find the best setting of LSTM (Neural Net) that can best classify the reviews as positive, negative, and neutral.\n",
    "\n",
    "\n",
    "### Code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing Step-1:Converting to list for easy manipulation \n",
      " Works as expected. Very easy to use and does not hurt my eyes like a tablet would. \n",
      "\n",
      "Text Preprocessing Step-2&3:Word standardize and Tokenize \n",
      " ['works', 'as', 'expected', '.', 'very', 'easy', 'to', 'use', 'and', 'does', 'not', 'hurt', 'my', 'eyes', 'like', 'a', 'tablet', 'would', '.'] \n",
      "\n",
      "Text Preprocessing Step-5:Remove stop words and punctuations \n",
      " ['works', 'expected', 'easy', 'use', 'hurt', 'eyes', 'like', 'tablet', 'would'] \n",
      "\n",
      "Text Preprocessing Step-6:lemmatized_docs \n",
      " ['work', 'expected', 'easy', 'use', 'hurt', 'eye', 'like', 'tablet', 'would'] \n",
      "\n",
      "Text Preprocessing Step-7:Delete numeric tokens \n",
      " ['work', 'expected', 'easy', 'use', 'hurt', 'eye', 'like', 'tablet', 'would'] \n",
      "\n",
      "Text Preprocessing Step-8:Clean  documents \n",
      " work expected easy use hurt eye like tablet would \n",
      "\n",
      "Text Preprocessing Step-1:Converting to list for easy manipulation \n",
      " Works good. Have to be very careful with kids. Overall good product \n",
      "\n",
      "Text Preprocessing Step-2&3:Word standardize and Tokenize \n",
      " ['works', 'good', '.', 'have', 'to', 'be', 'very', 'careful', 'with', 'kids', '.', 'overall', 'good', 'product'] \n",
      "\n",
      "Text Preprocessing Step-5:Remove stop words and punctuations \n",
      " ['works', 'good', 'careful', 'kids', 'overall', 'good', 'product'] \n",
      "\n",
      "Text Preprocessing Step-6:lemmatized_docs \n",
      " ['work', 'good', 'careful', 'kid', 'overall', 'good', 'product'] \n",
      "\n",
      "Text Preprocessing Step-7:Delete numeric tokens \n",
      " ['work', 'good', 'careful', 'kid', 'overall', 'good', 'product'] \n",
      "\n",
      "Text Preprocessing Step-8:Clean  documents \n",
      " work good careful kid overall good product \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AS LSTM is memory intensive lets take 30% of the data and test it\n",
    "\n",
    "#Lets take only relevent columns for the preprocessing of Train Data(reviews.text and sentiment)\n",
    "traindata=train[['reviews.text','sentiment']]\n",
    "traindata= traindata.sample(frac=0.3,random_state=1)\n",
    "\n",
    "#Lets take only relevent columns for the preprocessing of Test Data (reviews.text and sentiment)\n",
    "testdata=test_hidden[['reviews.text','sentiment']]\n",
    "testdata= testdata.sample(frac=0.3,random_state=1)\n",
    "\n",
    "train_clean_reviews=text_preprocessing(traindata)\n",
    "test_clean_reviews=text_preprocessing(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of X_train and  y_train:  1200 (1200,)\n",
      "the shape of X_test and  y_test:  300 (300,)\n"
     ]
    }
   ],
   "source": [
    "#Prepare Data for Neural Network\n",
    "X_train=train_clean_reviews\n",
    "X_test=test_clean_reviews\n",
    "y_train=traindata['sentiment']\n",
    "y_test=testdata['sentiment']\n",
    "\n",
    "\n",
    "#Label encoding for Class\n",
    "y_train_NN=y_train.replace(['Positive','Negative','Neutral'],[1,0,2])\n",
    "y_test_NN=y_test.replace(['Positive','Negative','Neutral'],[1,0,2])\n",
    "# and Convert class to catagorical\n",
    "y_train_NNC= tf.keras.utils.to_categorical(y_train_NN)\n",
    "y_test_NNC = tf.keras.utils.to_categorical(y_test_NN)\n",
    "\n",
    "print('the shape of X_train and  y_train: ', len(X_train), y_train.shape)\n",
    "print('the shape of X_test and  y_test: ', len(X_test),y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets build the Word2Vec Model from Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "### Convert Review to a Word List\n",
    "#List to hold all words in each review\n",
    "documents = []\n",
    "\n",
    "#Iterate over each review\n",
    "for doc in fulldata_clean_reviews:\n",
    "    documents.append(doc.split(' '))\n",
    "\n",
    "print(len(documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model\n",
    "model= gensim.models.Word2Vec(documents, #Word list\n",
    "                               min_count=10, #Ignore all words with total frequency lower than this                           \n",
    "                               workers=4, #Number of CPU Cores\n",
    "                               size=50,  #Embedding size\n",
    "                               window=5, #Maximum Distance between current and predicted word\n",
    "                               iter=10   #Number of iterations over the text corpus\n",
    "                              )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('word2vec-ecomm')\n",
    "#Load model from memory\n",
    "#model = gensim.models.Word2Vec.load('word2vec-ecomm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Build Tokenizer to get Number sequences for Each review\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#Vocab size\n",
    "top_words = 5000\n",
    "\n",
    "t = Tokenizer(num_words=top_words)\n",
    "t.fit_on_texts(X_train)\n",
    "\n",
    "#2.Get the word index for each of the word in the review\n",
    "X_train = t.texts_to_sequences(X_train)\n",
    "X_test = t.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum review length: 773\n",
      "Minimum review length: 3\n"
     ]
    }
   ],
   "source": [
    "#Maximum review length\n",
    "print('Maximum review length: {}'.format(\n",
    "len(max((X_train + X_test), key=len))))\n",
    "\n",
    "#Minimum review length.\n",
    "print('Minimum review length: {}'.format(\n",
    "len(min((X_test + X_test), key=len))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.Limit the maximum review length to max_words by truncating longer reviews and padding shorter reviews \n",
    "# with a null value.\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "\n",
    "#Each review size\n",
    "max_review_length = 500\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train,maxlen=max_review_length,padding='post')\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Embedding Matrix from Pre-Trained Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded word2vec model..\n",
      "Model shape:  (1009, 50)\n"
     ]
    }
   ],
   "source": [
    "#Load pre-trained model\n",
    "word2vec = gensim.models.Word2Vec.load('word2vec-ecomm')\n",
    "#word2vec = gensim.models.Word2Vec.load('word2vec-movie-ratings')\n",
    "\n",
    "\n",
    "#Embedding Length\n",
    "embedding_vector_length = word2vec.wv.vectors.shape[1]\n",
    "\n",
    "print('Loaded word2vec model..')\n",
    "print('Model shape: ', word2vec.wv.vectors.shape)\n",
    "\n",
    "#Initialize embedding matrix to all zeros\n",
    "embedding_matrix = np.zeros((top_words + 1, embedding_vector_length))\n",
    "\n",
    "#Steps for populating embedding matrix\n",
    "\n",
    "#1. Check each word in tokenizer vocablury to see if it exist in pre-trained\n",
    "# word2vec model.\n",
    "#2. If found, update embedding matrix with embeddings for the word \n",
    "# from word2vec model\n",
    "\n",
    "for word, i in sorted(t.word_index.items(),key=lambda x:x[1]):\n",
    "    if i > top_words:\n",
    "        break\n",
    "    if word in word2vec.wv.vocab:\n",
    "        embedding_vector = word2vec.wv[word]\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dropout, Dense, Embedding, Flatten,LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a sequential model\n",
    "model_LSTM = Sequential()\n",
    "\n",
    "model_LSTM.add(Embedding(top_words + 1, #Indexes that we need to deal with                    \n",
    "                    embedding_vector_length, #embedding_size i.e 50 in this case\n",
    "                    input_length=max_review_length, #Size of each review i.e 300 in this case\n",
    "                    weights=[embedding_matrix], #This can be also a Pre-trained embedding\n",
    "                    trainable=False   #This can set to False incase of pretrained model\n",
    "                   )\n",
    "         )\n",
    "\n",
    "#model_LSTM.add(LSTM(200,activation='relu',return_sequences=True))\n",
    "#model_LSTM.add(Dropout(0.5))\n",
    "#model_LSTM.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#model_LSTM.add(LSTM(100,activation='relu',return_sequences=True))\n",
    "#model_LSTM.add(Dropout(0.4))\n",
    "#model_LSTM.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model_LSTM.add(LSTM(100,activation='relu'))\n",
    "#model_LSTM.add(Dropout(0.3))\n",
    "model_LSTM.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model_LSTM.add(Dense(50,activation='relu'))\n",
    "#model_LSTM.add(Dropout(0.3))\n",
    "model_LSTM.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "model_LSTM.add(Dense(3,activation='softmax'))\n",
    "\n",
    "model_LSTM.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 23s 20ms/sample - loss: 1.0552 - accuracy: 0.7833 - val_loss: 0.9662 - val_accuracy: 0.9500\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 21s 18ms/sample - loss: 0.9284 - accuracy: 0.9300 - val_loss: 0.8253 - val_accuracy: 0.9500\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 22s 18ms/sample - loss: 0.7837 - accuracy: 0.9308 - val_loss: 0.6913 - val_accuracy: 0.9500\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 22s 18ms/sample - loss: 0.6453 - accuracy: 0.9325 - val_loss: 0.5447 - val_accuracy: 0.9500\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 22s 18ms/sample - loss: 0.5213 - accuracy: 0.9308 - val_loss: 0.4390 - val_accuracy: 0.9500\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 22s 18ms/sample - loss: 0.4223 - accuracy: 0.9325 - val_loss: 0.3455 - val_accuracy: 0.9500\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 22s 18ms/sample - loss: 0.3600 - accuracy: 0.9317 - val_loss: 0.3063 - val_accuracy: 0.9500\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 22s 18ms/sample - loss: 0.3269 - accuracy: 0.9325 - val_loss: 0.2736 - val_accuracy: 0.9500\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 22s 18ms/sample - loss: 0.3114 - accuracy: 0.9317 - val_loss: 0.2605 - val_accuracy: 0.9500\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 22s 18ms/sample - loss: 0.3013 - accuracy: 0.9325 - val_loss: 0.2567 - val_accuracy: 0.9500\n",
      "Wall time: 3min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1baa7df0108>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_LSTM.fit(X_train,y_train_NNC,\n",
    "          epochs=10,\n",
    "          batch_size=64,          \n",
    "          validation_data=(X_test, y_test_NNC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Train Data \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       0.93      1.00      0.97      1119\n",
      "           2       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.93      1200\n",
      "   macro avg       0.31      0.33      0.32      1200\n",
      "weighted avg       0.87      0.93      0.90      1200\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "Classification Report for Test Data \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.95      1.00      0.97       285\n",
      "           2       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.95       300\n",
      "   macro avg       0.32      0.33      0.32       300\n",
      "weighted avg       0.90      0.95      0.93       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict  classes\n",
    "yhat_classes_train = model_LSTM.predict_classes(X_train, verbose=0)\n",
    "yhat_classes_test = model_LSTM.predict_classes(X_test, verbose=0)\n",
    "\n",
    "#Classification Report for Train Data\n",
    "cr=classification_report(y_true=y_train_NN,y_pred=yhat_classes_train)\n",
    "print('Classification Report for Train Data \\n',cr)\n",
    "print('-------------------------------------------------------------------------------------------')\n",
    "\n",
    "#Classification Report for Test Data\n",
    "cr=classification_report(y_true=y_test_NN,y_pred=yhat_classes_test)\n",
    "print('Classification Report for Test Data \\n',cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets do Cross validation and see if there is any improvement in the score\n",
    "    We will select top 3 models and perform cross validations and select the best model post crosss validation\n",
    "    Here are the steps for CV \n",
    "    Step1: Cross validate with StratifiedKFold with 10 splits\n",
    "           Select those model which has highest F1 scores with minimum standard deviation \n",
    "    Step2: Identify which splits(among 10 splits) gives the best Train and Test sample\n",
    "    Step3: Extract the best Sample and Refit the model with the best train sample\n",
    "    Step4: Predict with Unseen Test Data and find out Classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_NAMES = [\"Approach\",\"Model Name\", \"F1 Scores\",\"Range of F1 Scores\",\"Std Deviation of F1 Scores\"]\n",
    "df_model_selection = pd.DataFrame(columns=COLUMN_NAMES)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "#from sklearn import metrics\n",
    "\n",
    "def model_traintest_CV(model_obj, model_name, approach, n_splits, X, y):\n",
    "    global df_model_selection\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits, random_state=12,shuffle=True)\n",
    "    \n",
    "    weighted_f1_score = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X,y):\n",
    "        X_train, X_test = X[train_index], X[test_index] \n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        model_obj.fit(X_train,y_train)\n",
    "        \n",
    "        test_ds_predicted = model_obj.predict( X_test )\n",
    "        \n",
    "        weighted_f1_score.append(round(f1_score(y_true=y_test, y_pred=test_ds_predicted , average='weighted'),2))   \n",
    "         \n",
    "    sd_weighted_f1_score = np.std(weighted_f1_score, ddof=1)\n",
    "    range_of_f1_scores = \"{}-{}\".format(min(weighted_f1_score),max(weighted_f1_score))    \n",
    "    df_model_selection = pd.concat([df_model_selection,pd.DataFrame([[approach,model_name,sorted(weighted_f1_score),range_of_f1_scores,sd_weighted_f1_score]], columns =COLUMN_NAMES) ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step1: Cross validate with StratifiedKFold with 10 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "COLUMN_NAMES = [\"Approach\",\"Model Name\", \"F1 Scores\",\"Range of F1 Scores\",\"Std Deviation of F1 Scores\"]\n",
    "df_model_selection = pd.DataFrame(columns=COLUMN_NAMES)\n",
    "\n",
    "\n",
    "n_splits = 10\n",
    "X=X_train_bow.toarray()\n",
    "y=y_train\n",
    "\n",
    "\n",
    "# 1.RandomForestClassifier\n",
    "approach='RandomForestClassifier with Cross Validation'\n",
    "model_RFC=RandomForestClassifier(n_estimators=200,class_weight='balanced')\n",
    "model_obj=model_RFC\n",
    "model_name='RandomForest Classifier'\n",
    "model_traintest_CV(model_obj, model_name, approach, n_splits, X, y)\n",
    "\n",
    "# 2.XGBoost Classifier\n",
    "approach='XGBoost Classifier with Cross Validation'\n",
    "model_XGBC=XGBClassifier()\n",
    "model_obj=model_XGBC\n",
    "model_name='XGBoost Classifier'\n",
    "model_traintest_CV(model_obj, model_name, approach, n_splits, X, y)\n",
    "\n",
    "#3.Undersampling - Naive Bayes\n",
    "X=X_train_bow_US.toarray()\n",
    "y=y_train_US\n",
    "approach='Undersampling - Multinomial Naive Bayes with Cross Validation'\n",
    "model_MNB = MultinomialNB()\n",
    "model_obj=model_MNB\n",
    "model_name='Multinomial Naive Bayes'\n",
    "model_traintest_CV(model_obj, model_name, approach, n_splits, X, y)\n",
    "\n",
    "df_model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approach</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>F1 Scores</th>\n",
       "      <th>Range of F1 Scores</th>\n",
       "      <th>Std Deviation of F1 Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier with Cross Validation</td>\n",
       "      <td>RandomForest Classifier</td>\n",
       "      <td>[0.92, 0.92, 0.92, 0.92, 0.93, 0.93, 0.93, 0.9...</td>\n",
       "      <td>0.92-0.94</td>\n",
       "      <td>0.008756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier with Cross Validation</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>[0.92, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93, 0.9...</td>\n",
       "      <td>0.92-0.94</td>\n",
       "      <td>0.006325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Undersampling - Multinomial Naive Bayes with C...</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>[0.52, 0.53, 0.56, 0.56, 0.58, 0.6, 0.6, 0.61,...</td>\n",
       "      <td>0.52-0.74</td>\n",
       "      <td>0.062370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Approach               Model Name  \\\n",
       "0       RandomForestClassifier with Cross Validation  RandomForest Classifier   \n",
       "0           XGBoost Classifier with Cross Validation       XGBoost Classifier   \n",
       "0  Undersampling - Multinomial Naive Bayes with C...  Multinomial Naive Bayes   \n",
       "\n",
       "                                           F1 Scores Range of F1 Scores  \\\n",
       "0  [0.92, 0.92, 0.92, 0.92, 0.93, 0.93, 0.93, 0.9...          0.92-0.94   \n",
       "0  [0.92, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93, 0.9...          0.92-0.94   \n",
       "0  [0.52, 0.53, 0.56, 0.56, 0.58, 0.6, 0.6, 0.61,...          0.52-0.74   \n",
       "\n",
       "   Std Deviation of F1 Scores  \n",
       "0                    0.008756  \n",
       "0                    0.006325  \n",
       "0                    0.062370  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step2: Identify which splits(among 10 splits) gives the best Train and Test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1-Score: 1.0, Test f1-score: 0.92, for Sample Split: 1\n",
      "Train f1-Score: 1.0, Test f1-score: 0.94, for Sample Split: 2\n",
      "Train f1-Score: 1.0, Test f1-score: 0.93, for Sample Split: 3\n",
      "Train f1-Score: 1.0, Test f1-score: 0.94, for Sample Split: 4\n",
      "Train f1-Score: 1.0, Test f1-score: 0.94, for Sample Split: 5\n",
      "Train f1-Score: 1.0, Test f1-score: 0.93, for Sample Split: 6\n",
      "Train f1-Score: 1.0, Test f1-score: 0.94, for Sample Split: 7\n",
      "Train f1-Score: 1.0, Test f1-score: 0.91, for Sample Split: 8\n",
      "Train f1-Score: 1.0, Test f1-score: 0.93, for Sample Split: 9\n",
      "Train f1-Score: 1.0, Test f1-score: 0.92, for Sample Split: 10\n",
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Now lets try to get the Scores using StratifiedKFold Cross Validation for RandomForest Classifier\n",
    "\n",
    "#Initialize the algo\n",
    "model=RandomForestClassifier(n_estimators=200,class_weight='balanced')\n",
    "X=X_train_bow.toarray()\n",
    "y=y_train\n",
    "\n",
    "#Initialize StratifiedKFold Method\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=10, \n",
    "              random_state=1,\n",
    "              shuffle=True)\n",
    "\n",
    "#Initialize For Loop \n",
    "\n",
    "i=0\n",
    "for train,test in kfold.split(X,y):\n",
    "    i = i+1\n",
    "    X_train,X_test = X[train],X[test]\n",
    "    y_train,y_test = y[train],y[test]\n",
    "    \n",
    "    model.fit(X_train,y_train)\n",
    "    test_ds_predicted=model.predict(X_test)\n",
    "    train_ds_predicted=model.predict(X_train)\n",
    "    \n",
    "    test_f1_score=round(f1_score(y_true=y_test, y_pred=test_ds_predicted , average='weighted'),2)\n",
    "    train_f1_score=round(f1_score(y_true=y_train, y_pred=train_ds_predicted , average='weighted'),2)\n",
    "    \n",
    "    #print(\"Train Score: {}, Test score: {}, for Sample Split: {}\".format(model.score(X_train,y_train),model.score(X_test,y_test),i))\n",
    "    print(\"Train f1-Score: {}, Test f1-score: {}, for Sample Split: {}\".format(train_f1_score,test_f1_score,i))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step3: Extract the best Sample and Refit the model with the best train sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From above results we can extract the best Train and Test sample from either from split 2,4,5 or 7\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=10, #n_splits should be equal to no of cv value in cross_val_score\n",
    "              random_state=1,\n",
    "              shuffle=True)\n",
    "i=0\n",
    "for train,test in kfold.split(X,y):\n",
    "    i = i+1\n",
    "    if i == 2:\n",
    "        X_train,X_test,y_train,y_test = X[train],X[test],y[train],y[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1-Score: 0.99, Test f1-score: 1.0\n",
      "Train Accuracy Score is:1.0 and  Test Accuracy Score:0.95\n"
     ]
    }
   ],
   "source": [
    "#Now Lets fit the model with above X_train,X_test \n",
    "finalModel=RandomForestClassifier(n_estimators=200,class_weight='balanced')\n",
    "finalModel.fit(X_train,y_train)\n",
    "\n",
    "test_ds_predicted=model.predict(X_test)\n",
    "train_ds_predicted=model.predict(X_train)\n",
    "\n",
    "test_f1_score=round(f1_score(y_true=y_test, y_pred=test_ds_predicted , average='weighted'),2)\n",
    "train_f1_score=round(f1_score(y_true=y_train, y_pred=train_ds_predicted , average='weighted'),2)\n",
    "print(\"Train f1-Score: {}, Test f1-score: {}\".format(train_f1_score,test_f1_score))\n",
    "\n",
    "\n",
    "train_score=np.round(finalModel.score(X_train,y_train),2)\n",
    "test_score=np.round(finalModel.score(X_test,y_test),2)\n",
    "print('Train Accuracy Score is:{} and  Test Accuracy Score:{}'.format(train_score,test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step4: Predict with Unseen Test Data and find out Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score is:1.0 and test score is: 0.952\n",
      "classification_report TRAIN Data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      1.00      1.00        84\n",
      "     Neutral       1.00      1.00      1.00       142\n",
      "    Positive       1.00      1.00      1.00      3374\n",
      "\n",
      "    accuracy                           1.00      3600\n",
      "   macro avg       1.00      1.00      1.00      3600\n",
      "weighted avg       1.00      1.00      1.00      3600\n",
      "\n",
      "classification_report TEST Data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.29      0.45        24\n",
      "     Neutral       1.00      0.21      0.34        39\n",
      "    Positive       0.95      1.00      0.98       937\n",
      "\n",
      "    accuracy                           0.95      1000\n",
      "   macro avg       0.98      0.50      0.59      1000\n",
      "weighted avg       0.95      0.95      0.94      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now Lets get the performance Report from Unseen Test Data(X_test_bow)\n",
    "\n",
    "y_test_actual=test_hidden['sentiment']\n",
    "\n",
    "train_score=finalModel.score(X_train,y_train)\n",
    "test_score=finalModel.score(X_test_bow.toarray(),y_test_actual)\n",
    "print('train score is:{} and test score is: {}'.format(train_score,test_score))\n",
    "\n",
    "#Get precision    recall  and f1-score on Train data\n",
    "cr=classification_report(y_true=y_train,y_pred=finalModel.predict( X_train ))\n",
    "print('classification_report TRAIN Data\\n',cr)\n",
    "\n",
    "#Get precision    recall  and f1-score on Test data\n",
    "cr=classification_report(y_true=y_test_actual,y_pred=finalModel.predict( X_test_bow.toarray() ))\n",
    "print('classification_report TEST Data\\n',cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion after Cross Validation\n",
    "    Even after 10 fold Startified Cross validation , the f1 score and accuracy score did not change much.\n",
    "    This clearly explains for the fact that there is no scope for improving the performance unless we optimize the input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "\n",
    "**Summary of Model Testing and Evaluation at end of Week-3**\n",
    "\n",
    "| Approach | Avg. F-1 Score(Train) | Avg. F-1 Score(Test) | Wt.Avg. F-1 Score(Test) | Accuracy(Test) |\n",
    "| :--- | :---: | :---: | :---: | :---: |\n",
    "| 1. Oversampling - Naive Bayes | 97 % | 61 % | 61 % | 61 % |\n",
    "| 2. Undersampling - Naive Bayes | 95 % | 71 % | 71 % | 71 % |\n",
    "| 3. Over Sampling - Logistic Regression | 99 % | 62 % | 62 % | 63 % |\n",
    "| 4. Under Sampling - Logistic Regression | 99 % | 66 % | 66 % | 67 % |\n",
    "| 5. Random Forest Classifier | 100 % | 61 % | 94 % | 95 % |\n",
    "| 6. XGBoost Classifier | 95 % | 63 % | 94 % | 95 % |\n",
    "| 7. Over Sampling - Neural Network | 100 % | 58 % | 58 % | 58 % |\n",
    "| 8. Under Sampling - Neural Network | 100 % | 57 % | 57 % | 57 % |\n",
    "| 9. Neural Network with Original data(imbalance dataset) | 98 % | 62 % | 94 % | 94 % |\n",
    "| 10. Oversampling - SVM | 100 % | 61 % | 94 % | 95 % |\n",
    "| 11. Undersampling - SVM | 100 % | 60 % | 60 % | 60 % |\n",
    "| 12. Ensemble Technique(Oversampled Naive Bayes+LogisticReg) | 97 % | 63 % | 63 % | 64 % |\n",
    "| 13. Ensemble Technique(Oversampled Naive Bayes+XGBoost) | 97 % | 67 % | 67 % | 67 % |\n",
    "| 14. LSTM | 32 % | 32 % | 93 % | 95 % |\n",
    "\n",
    " **Note: Below are some of the different options tried out and summary of observation**\n",
    "    1. Executed LSTM with single layer with whole dataset ( It could not be executed becase of huge resource requirement)\n",
    "    2. Executed LSTM with single layer with 30% of data: Accuracy was around 95%. However   F-1 score for -ve and neutral\n",
    "     sentiments could not be performed well. \n",
    "    3. Tried with valious combinationes of optimizers(SGG, rmsprop).Tried with various combinations of epochs, batch sizes\n",
    "    4. Tried with different combinations of Topwords, Max review lengths, embedding vector length etc.\n",
    "    5. Tried with 2 hidden layers but it could not be executed. \n",
    "    \n",
    "    \n",
    "    In summary, LSTM is the least performing model as compared to  Traditional Neural Network and othef ML models used \n",
    "    for this usecase.\n",
    "    The primary reason for poor LSTM performance is because we need a pretrained  Corpus specific to this domain \n",
    "    so that model can utilize the  power of word embedding. \n",
    "    \n",
    "    The best performing models for this usecase are below\n",
    "    1.Random Forest Classifier with wt.Avg F1-score of 94% \n",
    "    2.XGBoost Classifier with wt.Avg F1-score of 94% \n",
    "    3.Neural Network with Original data(imbalance dataset) wt.Avg F1-score of 94% \n",
    "    \n",
    "    If we consider the Average F1 score criteria, then the best performing model is Naive Bayes with Undersampled data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Task: Week 4\n",
    "\n",
    "**Topic Modeling:**\n",
    "    \n",
    "\n",
    "\n",
    "### Code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train_data.csv')\n",
    "test_hidden=pd.read_csv('test_data_hidden.csv')\n",
    "test=pd.read_csv('test_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of merged data is:  (5000, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>primaryCategories</th>\n",
       "      <th>reviews.date</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All-New Fire HD 8 Tablet, 8\" HD Display, Wi-Fi...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2016-12-26T00:00:00.000Z</td>\n",
       "      <td>Purchased on Black FridayPros - Great Price (e...</td>\n",
       "      <td>Powerful tablet</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon - Echo Plus w/ Built-In Hub - Silver</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Echo,Smart Home,Networking,Home &amp; Tools...</td>\n",
       "      <td>Electronics,Hardware</td>\n",
       "      <td>2018-01-17T00:00:00.000Z</td>\n",
       "      <td>I purchased two Amazon in Echo Plus and two do...</td>\n",
       "      <td>Amazon Echo Plus AWESOME</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon Echo Show Alexa-enabled Bluetooth Speak...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Echo,Virtual Assistant Speakers,Electro...</td>\n",
       "      <td>Electronics,Hardware</td>\n",
       "      <td>2017-12-20T00:00:00.000Z</td>\n",
       "      <td>Just an average Alexa option. Does show a few ...</td>\n",
       "      <td>Average</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fire HD 10 Tablet, 10.1 HD Display, Wi-Fi, 16 ...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>eBook Readers,Fire Tablets,Electronics Feature...</td>\n",
       "      <td>Office Supplies,Electronics</td>\n",
       "      <td>2017-08-04T00:00:00.000Z</td>\n",
       "      <td>very good product. Exactly what I wanted, and ...</td>\n",
       "      <td>Greattttttt</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brand New Amazon Kindle Fire 16gb 7\" Ips Displ...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Computers/Tablets &amp; Networking,Tablets &amp; eBook...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2017-01-23T00:00:00.000Z</td>\n",
       "      <td>This is the 3rd one I've purchased. I've bough...</td>\n",
       "      <td>Very durable!</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name   brand  \\\n",
       "0  All-New Fire HD 8 Tablet, 8\" HD Display, Wi-Fi...  Amazon   \n",
       "1        Amazon - Echo Plus w/ Built-In Hub - Silver  Amazon   \n",
       "2  Amazon Echo Show Alexa-enabled Bluetooth Speak...  Amazon   \n",
       "3  Fire HD 10 Tablet, 10.1 HD Display, Wi-Fi, 16 ...  Amazon   \n",
       "4  Brand New Amazon Kindle Fire 16gb 7\" Ips Displ...  Amazon   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "1  Amazon Echo,Smart Home,Networking,Home & Tools...   \n",
       "2  Amazon Echo,Virtual Assistant Speakers,Electro...   \n",
       "3  eBook Readers,Fire Tablets,Electronics Feature...   \n",
       "4  Computers/Tablets & Networking,Tablets & eBook...   \n",
       "\n",
       "             primaryCategories              reviews.date  \\\n",
       "0                  Electronics  2016-12-26T00:00:00.000Z   \n",
       "1         Electronics,Hardware  2018-01-17T00:00:00.000Z   \n",
       "2         Electronics,Hardware  2017-12-20T00:00:00.000Z   \n",
       "3  Office Supplies,Electronics  2017-08-04T00:00:00.000Z   \n",
       "4                  Electronics  2017-01-23T00:00:00.000Z   \n",
       "\n",
       "                                        reviews.text  \\\n",
       "0  Purchased on Black FridayPros - Great Price (e...   \n",
       "1  I purchased two Amazon in Echo Plus and two do...   \n",
       "2  Just an average Alexa option. Does show a few ...   \n",
       "3  very good product. Exactly what I wanted, and ...   \n",
       "4  This is the 3rd one I've purchased. I've bough...   \n",
       "\n",
       "              reviews.title sentiment  \n",
       "0           Powerful tablet  Positive  \n",
       "1  Amazon Echo Plus AWESOME  Positive  \n",
       "2                   Average   Neutral  \n",
       "3               Greattttttt  Positive  \n",
       "4             Very durable!  Positive  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge Train and Test data for Topic Modeling\n",
    "dataSet=pd.concat([train,test_hidden])\n",
    "print('shape of merged data is: ',dataSet.shape)\n",
    "dataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing Step-1:Converting to list for easy manipulation \n",
      " Purchased on Black FridayPros - Great Price (even off sale)Very powerful and fast with quad core processors Amazing soundWell builtCons -Amazon ads, Amazon need this to subsidize the tablet and will remove the adds if you pay them $15.Inability to access other apps except the ones from Amazon. There is a way which I was able to accomplish to add the Google Play storeNet this is a great tablet for the money \n",
      "\n",
      "Text Preprocessing Step-2&3:Word standardize and Tokenize \n",
      " ['purchased', 'on', 'black', 'fridaypros', '-', 'great', 'price', '(', 'even', 'off', 'sale', ')', 'very', 'powerful', 'and', 'fast', 'with', 'quad', 'core', 'processors', 'amazing', 'soundwell', 'builtcons', '-amazon', 'ads', ',', 'amazon', 'need', 'this', 'to', 'subsidize', 'the', 'tablet', 'and', 'will', 'remove', 'the', 'adds', 'if', 'you', 'pay', 'them', '$', '15.inability', 'to', 'access', 'other', 'apps', 'except', 'the', 'ones', 'from', 'amazon', '.', 'there', 'is', 'a', 'way', 'which', 'i', 'was', 'able', 'to', 'accomplish', 'to', 'add', 'the', 'google', 'play', 'storenet', 'this', 'is', 'a', 'great', 'tablet', 'for', 'the', 'money'] \n",
      "\n",
      "Text Preprocessing Step-5:Remove stop words and punctuations \n",
      " ['purchased', 'black', 'fridaypros', 'great', 'price', 'even', 'sale', 'powerful', 'fast', 'quad', 'core', 'processors', 'amazing', 'soundwell', 'builtcons', '-amazon', 'ads', 'amazon', 'need', 'subsidize', 'tablet', 'remove', 'adds', 'pay', '15.inability', 'access', 'apps', 'except', 'ones', 'amazon', 'way', 'able', 'accomplish', 'add', 'google', 'play', 'storenet', 'great', 'tablet', 'money'] \n",
      "\n",
      "Text Preprocessing Step-6:lemmatized_docs \n",
      " ['purchased', 'black', 'fridaypros', 'great', 'price', 'even', 'sale', 'powerful', 'fast', 'quad', 'core', 'processor', 'amazing', 'soundwell', 'builtcons', '-amazon', 'ad', 'amazon', 'need', 'subsidize', 'tablet', 'remove', 'add', 'pay', '15.inability', 'access', 'apps', 'except', 'one', 'amazon', 'way', 'able', 'accomplish', 'add', 'google', 'play', 'storenet', 'great', 'tablet', 'money'] \n",
      "\n",
      "Text Preprocessing Step-7:Delete numeric tokens \n",
      " ['purchased', 'black', 'fridaypros', 'great', 'price', 'even', 'sale', 'powerful', 'fast', 'quad', 'core', 'processor', 'amazing', 'soundwell', 'builtcons', '-amazon', 'ad', 'amazon', 'need', 'subsidize', 'tablet', 'remove', 'add', 'pay', '15.inability', 'access', 'apps', 'except', 'one', 'amazon', 'way', 'able', 'accomplish', 'add', 'google', 'play', 'storenet', 'great', 'tablet', 'money'] \n",
      "\n",
      "Text Preprocessing Step-8:Clean  documents \n",
      " purchased black fridaypros great price even sale powerful fast quad core processor amazing soundwell builtcons -amazon ad amazon need subsidize tablet remove add pay 15.inability access apps except one amazon way able accomplish add google play storenet great tablet money \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lets take only relevent columns for the preprocessing of Full Dataset (reviews.text and sentiment)\n",
    "fulldata=dataSet[['reviews.text','sentiment']]\n",
    "# Data Preprocessing and getthe clean reviews\n",
    "fulldata_clean_reviews=text_preprocessing(fulldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['average', 'alexa', 'option', 'show', 'thing', 'screen', 'still', 'limited']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets extract  the clean tokens back from each review\n",
    "# Tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokenizedComments=[word_tokenize(doc) for doc in fulldata_clean_reviews]\n",
    "tokenizedComments[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('average', 'JJ'),\n",
       " ('alexa', 'JJ'),\n",
       " ('option', 'NN'),\n",
       " ('show', 'NN'),\n",
       " ('thing', 'NN'),\n",
       " ('screen', 'NN'),\n",
       " ('still', 'RB'),\n",
       " ('limited', 'VBD')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS Tagging\n",
    "# Why POS tagging is done ?\n",
    "#  1. First: For understanding the structure of a sentence.\n",
    "#  2. Second: For being able to extract a perticular kind of words.\n",
    "posTagged=[]\n",
    "for comments in tokenizedComments:\n",
    "    posTagged.append(nltk.pos_tag(comments))\n",
    "posTagged[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out all the POS tags that correspond to nouns OR adjectives.\n",
    "extractedData=[]\n",
    "for posTaggedComment in posTagged:\n",
    "    extractedData.append([word for (word, pos) in posTaggedComment if ((pos[0] == 'N')| (pos[0] == 'J'))])\n",
    "    #onlyNouns.append([word for (word, pos) in posTaggedComment if pos[0] == 'N'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets do LDA ( Latent Dirchlet Allocation) for Topic Modeling\n",
    "#1.Create Dictionary\n",
    "dictionary = gensim.corpora.Dictionary(extractedData)\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in extractedData]\n",
    "\n",
    "# LDA Modeling\n",
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 10, \n",
    "                                   id2word = dictionary,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.033*\"product\" + 0.027*\"great\" + 0.019*\"tablet\" + 0.018*\"best\" + 0.017*\"time\" + 0.016*\"amazon\" + 0.016*\"happy\" + 0.015*\"buy\" + 0.013*\"fire\" + 0.012*\"screen\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.036*\"great\" + 0.019*\"book\" + 0.019*\"daughter\" + 0.018*\"life\" + 0.017*\"tablet\" + 0.017*\"battery\" + 0.017*\"easy\" + 0.016*\"thing\" + 0.014*\"read\" + 0.014*\"awesome\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.044*\"kindle\" + 0.016*\"light\" + 0.015*\"smart\" + 0.015*\"device\" + 0.012*\"hub\" + 0.012*\"second\" + 0.012*\"echo\" + 0.011*\"love\" + 0.011*\"item\" + 0.011*\"fire\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.044*\"love\" + 0.025*\"old\" + 0.021*\"year\" + 0.021*\"great\" + 0.017*\"tablet\" + 0.016*\"gift\" + 0.015*\"kindle\" + 0.015*\"product\" + 0.014*\"christmas\" + 0.014*\"game\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.036*\"music\" + 0.034*\"alexa\" + 0.021*\"great\" + 0.020*\"echo\" + 0.020*\"product\" + 0.018*\"show\" + 0.017*\"family\" + 0.017*\"thing\" + 0.015*\"device\" + 0.014*\"use\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.068*\"use\" + 0.066*\"easy\" + 0.023*\"screen\" + 0.018*\"amazon\" + 0.015*\"love\" + 0.012*\"echo\" + 0.011*\"son\" + 0.010*\"great\" + 0.009*\"tablet\" + 0.009*\"fire\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.095*\"tablet\" + 0.047*\"great\" + 0.039*\"kid\" + 0.024*\"game\" + 0.020*\"price\" + 0.019*\"year\" + 0.019*\"good\" + 0.018*\"perfect\" + 0.017*\"old\" + 0.016*\"use\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.028*\"kindle\" + 0.025*\"size\" + 0.021*\"fire\" + 0.020*\"screen\" + 0.020*\"small\" + 0.019*\"easy\" + 0.017*\"fit\" + 0.015*\"use\" + 0.015*\"good\" + 0.014*\"light\"\n",
      "\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.032*\"book\" + 0.025*\"tablet\" + 0.022*\"amazon\" + 0.022*\"device\" + 0.018*\"apps\" + 0.014*\"use\" + 0.013*\"screen\" + 0.009*\"love\" + 0.009*\"magazine\" + 0.008*\"feature\"\n",
      "\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.067*\"great\" + 0.041*\"work\" + 0.041*\"echo\" + 0.029*\"sound\" + 0.023*\"show\" + 0.022*\"good\" + 0.019*\"video\" + 0.018*\"amazon\" + 0.016*\"use\" + 0.014*\"product\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Print the Topic\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out coherence of the model \n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "def compute_coherence_values(corpus,texts, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=a,\n",
    "                                           eta=b,\n",
    "                                           per_word_topics=True\n",
    "                                          )\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "# Topics range\n",
    "min_topics = 3\n",
    "max_topics = 19\n",
    "step_size = 3\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(bow_corpus)\n",
    "corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \n",
    "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n",
    "               gensim.utils.ClippedCorpus(bow_corpus, num_of_docs*0.75).corpus, \n",
    "               bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                          | 0/126 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▋                                                                                 | 1/126 [00:10<22:09, 10.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 3, a is 0.01, b is 0.01 and final cv is 0.3164943350022172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|█▎                                                                                | 2/126 [00:21<21:53, 10.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 3, a is 0.01, b is 0.31 and final cv is 0.3135951219821799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|█▉                                                                                | 3/126 [00:32<22:02, 10.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 3, a is 0.01, b is 0.61 and final cv is 0.3241904478754909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|██▌                                                                               | 4/126 [00:45<23:14, 11.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 3, a is 0.01, b is 0.9099999999999999 and final cv is 0.31623756107140094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|███▎                                                                              | 5/126 [00:58<24:13, 12.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 3, a is 0.31, b is 0.01 and final cv is 0.32450808891717636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|███▉                                                                              | 6/126 [01:12<25:18, 12.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 3, a is 0.31, b is 0.31 and final cv is 0.3021119765206885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|████▌                                                                             | 7/126 [01:27<26:12, 13.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 3, a is 0.31, b is 0.61 and final cv is 0.3161258703615957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|█████▏                                                                            | 8/126 [01:41<26:36, 13.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 3, a is 0.31, b is 0.9099999999999999 and final cv is 0.3126492957242999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|█████▊                                                                            | 9/126 [01:54<26:18, 13.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 3, a is 0.61, b is 0.01 and final cv is 0.31783566085677745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|██████▍                                                                          | 10/126 [02:09<26:30, 13.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 3, a is 0.61, b is 0.31 and final cv is 0.328794722284171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|███████                                                                          | 11/126 [02:23<26:28, 13.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 3, a is 0.61, b is 0.61 and final cv is 0.3266205412536192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|███████▋                                                                         | 12/126 [02:37<26:41, 14.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 3, a is 0.61, b is 0.9099999999999999 and final cv is 0.3267435146391063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|████████▎                                                                        | 13/126 [02:51<25:59, 13.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 3, a is 0.9099999999999999, b is 0.01 and final cv is 0.3143468216909339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█████████                                                                        | 14/126 [03:03<25:10, 13.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 3, a is 0.9099999999999999, b is 0.31 and final cv is 0.31316458855886004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█████████▋                                                                       | 15/126 [03:17<25:15, 13.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 3, a is 0.9099999999999999, b is 0.61 and final cv is 0.31064036005639034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|██████████▎                                                                      | 16/126 [03:31<25:16, 13.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 3, a is 0.9099999999999999, b is 0.9099999999999999 and final cv is 0.3139895680333741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|██████████▉                                                                      | 17/126 [03:44<24:34, 13.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 6, a is 0.01, b is 0.01 and final cv is 0.4172630712416318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|███████████▌                                                                     | 18/126 [03:58<24:18, 13.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 6, a is 0.01, b is 0.31 and final cv is 0.4184617226099641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|████████████▏                                                                    | 19/126 [04:12<24:16, 13.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 6, a is 0.01, b is 0.61 and final cv is 0.3664145632874985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|████████████▊                                                                    | 20/126 [04:25<23:43, 13.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 6, a is 0.01, b is 0.9099999999999999 and final cv is 0.443990975586899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█████████████▌                                                                   | 21/126 [04:40<24:18, 13.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 6, a is 0.31, b is 0.01 and final cv is 0.4376826357350141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|██████████████▏                                                                  | 22/126 [04:54<24:29, 14.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 6, a is 0.31, b is 0.31 and final cv is 0.4174516664437629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|██████████████▊                                                                  | 23/126 [05:10<24:50, 14.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 6, a is 0.31, b is 0.61 and final cv is 0.4078148828689707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|███████████████▍                                                                 | 24/126 [05:25<25:07, 14.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 6, a is 0.31, b is 0.9099999999999999 and final cv is 0.43793907321156783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|████████████████                                                                 | 25/126 [05:40<24:50, 14.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 6, a is 0.61, b is 0.01 and final cv is 0.4113347020869156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|████████████████▋                                                                | 26/126 [05:53<24:00, 14.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 6, a is 0.61, b is 0.31 and final cv is 0.43375802594199087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|█████████████████▎                                                               | 27/126 [06:08<24:03, 14.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 6, a is 0.61, b is 0.61 and final cv is 0.4212411144859883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██████████████████                                                               | 28/126 [06:23<23:39, 14.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 6, a is 0.61, b is 0.9099999999999999 and final cv is 0.3954595465765303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██████████████████▋                                                              | 29/126 [06:35<22:23, 13.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 6, a is 0.9099999999999999, b is 0.01 and final cv is 0.4095615970444275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|███████████████████▎                                                             | 30/126 [06:48<21:37, 13.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 6, a is 0.9099999999999999, b is 0.31 and final cv is 0.40055688578362475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|███████████████████▉                                                             | 31/126 [07:01<21:16, 13.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 6, a is 0.9099999999999999, b is 0.61 and final cv is 0.4258657423583232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|████████████████████▌                                                            | 32/126 [07:15<21:32, 13.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 6, a is 0.9099999999999999, b is 0.9099999999999999 and final cv is 0.42851301171606176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|█████████████████████▏                                                           | 33/126 [07:30<21:33, 13.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 9, a is 0.01, b is 0.01 and final cv is 0.4072418650433277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|█████████████████████▊                                                           | 34/126 [07:43<21:02, 13.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 9, a is 0.01, b is 0.31 and final cv is 0.36455270087551694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██████████████████████▌                                                          | 35/126 [07:56<20:33, 13.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 9, a is 0.01, b is 0.61 and final cv is 0.4136320741975339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|███████████████████████▏                                                         | 36/126 [08:10<20:24, 13.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 9, a is 0.01, b is 0.9099999999999999 and final cv is 0.3967235693497556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|███████████████████████▊                                                         | 37/126 [08:25<20:50, 14.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 9, a is 0.31, b is 0.01 and final cv is 0.4032362290096397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|████████████████████████▍                                                        | 38/126 [08:40<21:02, 14.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 9, a is 0.31, b is 0.31 and final cv is 0.38536444574940304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|█████████████████████████                                                        | 39/126 [08:55<20:59, 14.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 9, a is 0.31, b is 0.61 and final cv is 0.37868032412200153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|█████████████████████████▋                                                       | 40/126 [09:09<20:45, 14.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 9, a is 0.31, b is 0.9099999999999999 and final cv is 0.4269060059477614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|██████████████████████████▎                                                      | 41/126 [09:23<20:15, 14.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 9, a is 0.61, b is 0.01 and final cv is 0.40742508689164403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███████████████████████████                                                      | 42/126 [09:37<19:40, 14.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 9, a is 0.61, b is 0.31 and final cv is 0.41724052224838776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 34%|███████████████████████████▋                                                     | 43/126 [09:52<20:01, 14.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 9, a is 0.61, b is 0.61 and final cv is 0.40258906379351767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|████████████████████████████▎                                                    | 44/126 [10:07<19:54, 14.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 9, a is 0.61, b is 0.9099999999999999 and final cv is 0.3688942152524696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 36%|████████████████████████████▉                                                    | 45/126 [10:21<19:17, 14.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 9, a is 0.9099999999999999, b is 0.01 and final cv is 0.41722980279142496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|█████████████████████████████▌                                                   | 46/126 [10:35<18:57, 14.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 9, a is 0.9099999999999999, b is 0.31 and final cv is 0.41376443212237357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|██████████████████████████████▏                                                  | 47/126 [10:49<18:36, 14.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 9, a is 0.9099999999999999, b is 0.61 and final cv is 0.3953392699264028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|██████████████████████████████▊                                                  | 48/126 [11:03<18:24, 14.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 9, a is 0.9099999999999999, b is 0.9099999999999999 and final cv is 0.37177289269647695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|███████████████████████████████▌                                                 | 49/126 [11:17<18:08, 14.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 12, a is 0.01, b is 0.01 and final cv is 0.38635651721080005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████████████████████████████████▏                                                | 50/126 [11:31<17:51, 14.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 12, a is 0.01, b is 0.31 and final cv is 0.3892904561150901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████████████████████████████████▊                                                | 51/126 [11:44<17:25, 13.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 12, a is 0.01, b is 0.61 and final cv is 0.43690986613108823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 41%|█████████████████████████████████▍                                               | 52/126 [11:59<17:17, 14.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 12, a is 0.01, b is 0.9099999999999999 and final cv is 0.4493514920109114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|██████████████████████████████████                                               | 53/126 [12:14<17:22, 14.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 12, a is 0.31, b is 0.01 and final cv is 0.35116141741438617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|██████████████████████████████████▋                                              | 54/126 [12:29<17:30, 14.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 12, a is 0.31, b is 0.31 and final cv is 0.3796383758436154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|███████████████████████████████████▎                                             | 55/126 [12:43<17:12, 14.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 12, a is 0.31, b is 0.61 and final cv is 0.4198980138136757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████████████████████████████████████                                             | 56/126 [12:59<17:13, 14.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 12, a is 0.31, b is 0.9099999999999999 and final cv is 0.4563471035769333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████████████████████████████████████▋                                            | 57/126 [13:12<16:35, 14.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 12, a is 0.61, b is 0.01 and final cv is 0.3674082327161345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 46%|█████████████████████████████████████▎                                           | 58/126 [13:26<16:12, 14.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 12, a is 0.61, b is 0.31 and final cv is 0.36518598681226727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|█████████████████████████████████████▉                                           | 59/126 [13:41<16:01, 14.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 12, a is 0.61, b is 0.61 and final cv is 0.3806575902116291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|██████████████████████████████████████▌                                          | 60/126 [13:54<15:34, 14.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 12, a is 0.61, b is 0.9099999999999999 and final cv is 0.3633883483555986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|███████████████████████████████████████▏                                         | 61/126 [14:08<15:04, 13.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 12, a is 0.9099999999999999, b is 0.01 and final cv is 0.3898049063288275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 49%|███████████████████████████████████████▊                                         | 62/126 [14:21<14:36, 13.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 12, a is 0.9099999999999999, b is 0.31 and final cv is 0.3920607078753806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|████████████████████████████████████████▌                                        | 63/126 [14:34<14:11, 13.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 12, a is 0.9099999999999999, b is 0.61 and final cv is 0.3607924261532962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 51%|█████████████████████████████████████████▏                                       | 64/126 [14:47<13:53, 13.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 12, a is 0.9099999999999999, b is 0.9099999999999999 and final cv is 0.30868086388099397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|█████████████████████████████████████████▊                                       | 65/126 [15:02<13:54, 13.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 15, a is 0.01, b is 0.01 and final cv is 0.40379066848170164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|██████████████████████████████████████████▍                                      | 66/126 [15:16<13:54, 13.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 15, a is 0.01, b is 0.31 and final cv is 0.4213895191272592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|███████████████████████████████████████████                                      | 67/126 [15:31<13:51, 14.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 15, a is 0.01, b is 0.61 and final cv is 0.43128851023801246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 54%|███████████████████████████████████████████▋                                     | 68/126 [15:45<13:38, 14.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 15, a is 0.01, b is 0.9099999999999999 and final cv is 0.41883510176852984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|████████████████████████████████████████████▎                                    | 69/126 [16:00<13:46, 14.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 15, a is 0.31, b is 0.01 and final cv is 0.3736658406168471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████████████████████████████████████████████                                    | 70/126 [16:15<13:44, 14.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 15, a is 0.31, b is 0.31 and final cv is 0.38307042191777124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████████████████████████████████████████████▋                                   | 71/126 [16:31<13:39, 14.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 15, a is 0.31, b is 0.61 and final cv is 0.41579240076948326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|██████████████████████████████████████████████▎                                  | 72/126 [16:46<13:27, 14.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 15, a is 0.31, b is 0.9099999999999999 and final cv is 0.4067590300758521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 58%|██████████████████████████████████████████████▉                                  | 73/126 [17:00<13:02, 14.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 15, a is 0.61, b is 0.01 and final cv is 0.3753135390795184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 59%|███████████████████████████████████████████████▌                                 | 74/126 [17:14<12:35, 14.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 15, a is 0.61, b is 0.31 and final cv is 0.38368401495290766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|████████████████████████████████████████████████▏                                | 75/126 [17:28<12:16, 14.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 15, a is 0.61, b is 0.61 and final cv is 0.3971748166982982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|████████████████████████████████████████████████▊                                | 76/126 [17:42<11:58, 14.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 15, a is 0.61, b is 0.9099999999999999 and final cv is 0.36480292719535345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 61%|█████████████████████████████████████████████████▌                               | 77/126 [17:55<11:24, 13.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 15, a is 0.9099999999999999, b is 0.01 and final cv is 0.37749806845730255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|██████████████████████████████████████████████████▏                              | 78/126 [18:09<11:04, 13.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 15, a is 0.9099999999999999, b is 0.31 and final cv is 0.37501003827829693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|██████████████████████████████████████████████████▊                              | 79/126 [18:22<10:42, 13.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 15, a is 0.9099999999999999, b is 0.61 and final cv is 0.3413598319110568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|███████████████████████████████████████████████████▍                             | 80/126 [18:35<10:19, 13.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 15, a is 0.9099999999999999, b is 0.9099999999999999 and final cv is 0.3119917075833492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 64%|████████████████████████████████████████████████████                             | 81/126 [18:50<10:19, 13.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 18, a is 0.01, b is 0.01 and final cv is 0.3722208416719946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|████████████████████████████████████████████████████▋                            | 82/126 [19:04<10:16, 14.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 18, a is 0.01, b is 0.31 and final cv is 0.4038245842279205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 66%|█████████████████████████████████████████████████████▎                           | 83/126 [19:19<10:12, 14.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 18, a is 0.01, b is 0.61 and final cv is 0.4507799654167824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████████████████████████████████████████████████████                           | 84/126 [19:34<10:01, 14.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 18, a is 0.01, b is 0.9099999999999999 and final cv is 0.3926177039478046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████████████████████████████████████████████████████▋                          | 85/126 [19:49<10:05, 14.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 18, a is 0.31, b is 0.01 and final cv is 0.3767833659068646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 68%|███████████████████████████████████████████████████████▎                         | 86/126 [20:05<09:58, 14.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 18, a is 0.31, b is 0.31 and final cv is 0.3967214661989307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 69%|███████████████████████████████████████████████████████▉                         | 87/126 [20:21<09:57, 15.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 18, a is 0.31, b is 0.61 and final cv is 0.4020934440639237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|████████████████████████████████████████████████████████▌                        | 88/126 [20:37<09:47, 15.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 18, a is 0.31, b is 0.9099999999999999 and final cv is 0.4179183928535328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|█████████████████████████████████████████████████████████▏                       | 89/126 [20:51<09:22, 15.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 18, a is 0.61, b is 0.01 and final cv is 0.3681963574300745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|█████████████████████████████████████████████████████████▊                       | 90/126 [21:06<09:01, 15.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 18, a is 0.61, b is 0.31 and final cv is 0.37426686277381155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 72%|██████████████████████████████████████████████████████████▌                      | 91/126 [21:21<08:41, 14.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 18, a is 0.61, b is 0.61 and final cv is 0.35934785591631846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 73%|███████████████████████████████████████████████████████████▏                     | 92/126 [21:35<08:16, 14.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 18, a is 0.61, b is 0.9099999999999999 and final cv is 0.3460408617581806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 74%|███████████████████████████████████████████████████████████▊                     | 93/126 [21:48<07:54, 14.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 18, a is 0.9099999999999999, b is 0.01 and final cv is 0.3662618593442397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|████████████████████████████████████████████████████████████▍                    | 94/126 [22:05<07:59, 14.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 18, a is 0.9099999999999999, b is 0.31 and final cv is 0.35019698540654376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|█████████████████████████████████████████████████████████████                    | 95/126 [22:18<07:32, 14.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 18, a is 0.9099999999999999, b is 0.61 and final cv is 0.3455685784203874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 76%|█████████████████████████████████████████████████████████████▋                   | 96/126 [22:32<07:02, 14.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 0, k is 18, a is 0.9099999999999999, b is 0.9099999999999999 and final cv is 0.32509386663819345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 1, k is 3, a is 0.01, b is 0.01 and final cv is 0.32823221968519595\n",
      "i is 1, k is 3, a is 0.01, b is 0.31 and final cv is 0.3231927571201237\n",
      "i is 1, k is 3, a is 0.01, b is 0.61 and final cv is 0.33354690429912953\n",
      "i is 1, k is 3, a is 0.01, b is 0.9099999999999999 and final cv is 0.30982997636749415\n",
      "i is 1, k is 3, a is 0.31, b is 0.01 and final cv is 0.31708407295046653\n",
      "i is 1, k is 3, a is 0.31, b is 0.31 and final cv is 0.29270873829778404\n",
      "i is 1, k is 3, a is 0.31, b is 0.61 and final cv is 0.31327325610457485\n",
      "i is 1, k is 3, a is 0.31, b is 0.9099999999999999 and final cv is 0.31521228855898126\n",
      "i is 1, k is 3, a is 0.61, b is 0.01 and final cv is 0.33526134410556613\n",
      "i is 1, k is 3, a is 0.61, b is 0.31 and final cv is 0.3394232640254377\n",
      "i is 1, k is 3, a is 0.61, b is 0.61 and final cv is 0.33942326402543777\n",
      "i is 1, k is 3, a is 0.61, b is 0.9099999999999999 and final cv is 0.33257946656801884\n",
      "i is 1, k is 3, a is 0.9099999999999999, b is 0.01 and final cv is 0.31607530608725454\n",
      "i is 1, k is 3, a is 0.9099999999999999, b is 0.31 and final cv is 0.30452908228816444\n",
      "i is 1, k is 3, a is 0.9099999999999999, b is 0.61 and final cv is 0.32467197440796325\n",
      "i is 1, k is 3, a is 0.9099999999999999, b is 0.9099999999999999 and final cv is 0.32260460496314675\n",
      "i is 1, k is 6, a is 0.01, b is 0.01 and final cv is 0.40165194185293845\n",
      "i is 1, k is 6, a is 0.01, b is 0.31 and final cv is 0.4079626153630651\n",
      "i is 1, k is 6, a is 0.01, b is 0.61 and final cv is 0.372533426299759\n",
      "i is 1, k is 6, a is 0.01, b is 0.9099999999999999 and final cv is 0.41955524960619156\n",
      "i is 1, k is 6, a is 0.31, b is 0.01 and final cv is 0.4306468934755077\n",
      "i is 1, k is 6, a is 0.31, b is 0.31 and final cv is 0.42515748922802693\n",
      "i is 1, k is 6, a is 0.31, b is 0.61 and final cv is 0.409362474821858\n",
      "i is 1, k is 6, a is 0.31, b is 0.9099999999999999 and final cv is 0.41989522657598166\n",
      "i is 1, k is 6, a is 0.61, b is 0.01 and final cv is 0.39990646453017775\n",
      "i is 1, k is 6, a is 0.61, b is 0.31 and final cv is 0.4102700444779068\n",
      "i is 1, k is 6, a is 0.61, b is 0.61 and final cv is 0.40529698795624186\n",
      "i is 1, k is 6, a is 0.61, b is 0.9099999999999999 and final cv is 0.402258840101583\n",
      "i is 1, k is 6, a is 0.9099999999999999, b is 0.01 and final cv is 0.4006836652069597\n",
      "i is 1, k is 6, a is 0.9099999999999999, b is 0.31 and final cv is 0.4235093922113658\n",
      "i is 1, k is 6, a is 0.9099999999999999, b is 0.61 and final cv is 0.3989394763196789\n",
      "i is 1, k is 6, a is 0.9099999999999999, b is 0.9099999999999999 and final cv is 0.43449533988913314\n",
      "i is 1, k is 9, a is 0.01, b is 0.01 and final cv is 0.3911789536193608\n",
      "i is 1, k is 9, a is 0.01, b is 0.31 and final cv is 0.42186704018745425\n",
      "i is 1, k is 9, a is 0.01, b is 0.61 and final cv is 0.3736473488092311\n",
      "i is 1, k is 9, a is 0.01, b is 0.9099999999999999 and final cv is 0.4574549389136091\n",
      "i is 1, k is 9, a is 0.31, b is 0.01 and final cv is 0.37360229888601715\n",
      "i is 1, k is 9, a is 0.31, b is 0.31 and final cv is 0.387349365949667\n",
      "i is 1, k is 9, a is 0.31, b is 0.61 and final cv is 0.3863186553496984\n",
      "i is 1, k is 9, a is 0.31, b is 0.9099999999999999 and final cv is 0.3999769534733079\n",
      "i is 1, k is 9, a is 0.61, b is 0.01 and final cv is 0.40931223230169134\n",
      "i is 1, k is 9, a is 0.61, b is 0.31 and final cv is 0.3916266479191899\n",
      "i is 1, k is 9, a is 0.61, b is 0.61 and final cv is 0.39062032812674263\n",
      "i is 1, k is 9, a is 0.61, b is 0.9099999999999999 and final cv is 0.37444734450250566\n",
      "i is 1, k is 9, a is 0.9099999999999999, b is 0.01 and final cv is 0.43563552597245003\n",
      "i is 1, k is 9, a is 0.9099999999999999, b is 0.31 and final cv is 0.4229029178959282\n",
      "i is 1, k is 9, a is 0.9099999999999999, b is 0.61 and final cv is 0.4040868030840309\n",
      "i is 1, k is 9, a is 0.9099999999999999, b is 0.9099999999999999 and final cv is 0.37420446817450226\n",
      "i is 1, k is 12, a is 0.01, b is 0.01 and final cv is 0.3840651866260043\n",
      "i is 1, k is 12, a is 0.01, b is 0.31 and final cv is 0.3789994309881381\n",
      "i is 1, k is 12, a is 0.01, b is 0.61 and final cv is 0.4284173654093357\n",
      "i is 1, k is 12, a is 0.01, b is 0.9099999999999999 and final cv is 0.4044144588884993\n",
      "i is 1, k is 12, a is 0.31, b is 0.01 and final cv is 0.34689884592202774\n",
      "i is 1, k is 12, a is 0.31, b is 0.31 and final cv is 0.37445636789829245\n",
      "i is 1, k is 12, a is 0.31, b is 0.61 and final cv is 0.42152189790214195\n",
      "i is 1, k is 12, a is 0.31, b is 0.9099999999999999 and final cv is 0.4563039290696073\n",
      "i is 1, k is 12, a is 0.61, b is 0.01 and final cv is 0.3765331855637981\n",
      "i is 1, k is 12, a is 0.61, b is 0.31 and final cv is 0.37234802661663174\n",
      "i is 1, k is 12, a is 0.61, b is 0.61 and final cv is 0.3852041530966512\n",
      "i is 1, k is 12, a is 0.61, b is 0.9099999999999999 and final cv is 0.38977419240218203\n",
      "i is 1, k is 12, a is 0.9099999999999999, b is 0.01 and final cv is 0.38727799974011096\n",
      "i is 1, k is 12, a is 0.9099999999999999, b is 0.31 and final cv is 0.41172334956855733\n",
      "i is 1, k is 12, a is 0.9099999999999999, b is 0.61 and final cv is 0.3521406533575127\n",
      "i is 1, k is 12, a is 0.9099999999999999, b is 0.9099999999999999 and final cv is 0.32335113426194234\n",
      "i is 1, k is 15, a is 0.01, b is 0.01 and final cv is 0.3938896020980198\n",
      "i is 1, k is 15, a is 0.01, b is 0.31 and final cv is 0.4109329829915345\n",
      "i is 1, k is 15, a is 0.01, b is 0.61 and final cv is 0.44280235342267493\n",
      "i is 1, k is 15, a is 0.01, b is 0.9099999999999999 and final cv is 0.4334273016485793\n",
      "i is 1, k is 15, a is 0.31, b is 0.01 and final cv is 0.35906755698905707\n",
      "i is 1, k is 15, a is 0.31, b is 0.31 and final cv is 0.40527897220328274\n",
      "i is 1, k is 15, a is 0.31, b is 0.61 and final cv is 0.4279844599085083\n",
      "i is 1, k is 15, a is 0.31, b is 0.9099999999999999 and final cv is 0.4032929896387475\n",
      "i is 1, k is 15, a is 0.61, b is 0.01 and final cv is 0.3547284364191378\n",
      "i is 1, k is 15, a is 0.61, b is 0.31 and final cv is 0.4118393049059242\n",
      "i is 1, k is 15, a is 0.61, b is 0.61 and final cv is 0.39152597169181175\n",
      "i is 1, k is 15, a is 0.61, b is 0.9099999999999999 and final cv is 0.3970033402109917\n",
      "i is 1, k is 15, a is 0.9099999999999999, b is 0.01 and final cv is 0.3613027234828862\n",
      "i is 1, k is 15, a is 0.9099999999999999, b is 0.31 and final cv is 0.3804226620135218\n",
      "i is 1, k is 15, a is 0.9099999999999999, b is 0.61 and final cv is 0.34200115276330295\n",
      "i is 1, k is 15, a is 0.9099999999999999, b is 0.9099999999999999 and final cv is 0.3257463206151408\n",
      "i is 1, k is 18, a is 0.01, b is 0.01 and final cv is 0.38625706982477515\n",
      "i is 1, k is 18, a is 0.01, b is 0.31 and final cv is 0.3971564457153095\n",
      "i is 1, k is 18, a is 0.01, b is 0.61 and final cv is 0.4418222644436323\n",
      "i is 1, k is 18, a is 0.01, b is 0.9099999999999999 and final cv is 0.4068110967791244\n",
      "i is 1, k is 18, a is 0.31, b is 0.01 and final cv is 0.35857144007746106\n",
      "i is 1, k is 18, a is 0.31, b is 0.31 and final cv is 0.38613531343612806\n",
      "i is 1, k is 18, a is 0.31, b is 0.61 and final cv is 0.3939944800165078\n",
      "i is 1, k is 18, a is 0.31, b is 0.9099999999999999 and final cv is 0.43553520649378874\n",
      "i is 1, k is 18, a is 0.61, b is 0.01 and final cv is 0.37492022891957855\n",
      "i is 1, k is 18, a is 0.61, b is 0.31 and final cv is 0.3885060256242359\n",
      "i is 1, k is 18, a is 0.61, b is 0.61 and final cv is 0.3583391154407903\n",
      "i is 1, k is 18, a is 0.61, b is 0.9099999999999999 and final cv is 0.3839029595199241\n",
      "i is 1, k is 18, a is 0.9099999999999999, b is 0.01 and final cv is 0.37263769774710165\n",
      "i is 1, k is 18, a is 0.9099999999999999, b is 0.31 and final cv is 0.33592290248411294\n",
      "i is 1, k is 18, a is 0.9099999999999999, b is 0.61 and final cv is 0.34197686906875047\n",
      "i is 1, k is 18, a is 0.9099999999999999, b is 0.9099999999999999 and final cv is 0.32026973141671483\n",
      "Wall time: 51min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Grid Search Code\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=126)\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv =0\n",
    "                    #print( \"i is {}, k is {}, a is {}, b is {}\".format(i,k,a,b) )\n",
    "                    cv = compute_coherence_values(corpus_sets[i],extractedData, dictionary,k, a, b)\n",
    "                    print( \"i is {}, k is {}, a is {}, b is {} and final cv is {}\".format(i,k,a,b,cv) )\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "        pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "        pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuneResults=pd.read_csv('lda_tuning_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validation_Set</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.457455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Validation_Set  Topics  Alpha  Beta  Coherence\n",
       "131    100% Corpus       9   0.01  0.91   0.457455"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuneResults[tuneResults.Coherence == tuneResults.Coherence.values.ravel().max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validation_Set</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>75% Corpus</td>\n",
       "      <td>12</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.456347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>75% Corpus</td>\n",
       "      <td>18</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.450780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.457455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>12</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.456304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Validation_Set  Topics  Alpha  Beta  Coherence\n",
       "55      75% Corpus      12   0.31  0.91   0.456347\n",
       "82      75% Corpus      18   0.01  0.61   0.450780\n",
       "131    100% Corpus       9   0.01  0.91   0.457455\n",
       "151    100% Corpus      12   0.31  0.91   0.456304"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuneResults[tuneResults.Coherence > 0.45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare final model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus_sets[0],\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=7, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.31,\n",
    "                                           eta=0.91,\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el3380829515342669527945934987\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el3380829515342669527945934987_data = {\"mdsDat\": {\"x\": [-0.19042191570557848, -0.055964675947950716, -0.0334216547674076, 0.037462959008862255, 0.027184760904702007, 0.11017536963739198, 0.10498515686998054], \"y\": [0.05730096398785675, -0.14118646520121322, 0.04573550733128725, 0.08381610732515701, -0.07858779465668687, 0.01513696054720942, 0.017784720666389742], \"topics\": [1, 2, 3, 4, 5, 6, 7], \"cluster\": [1, 1, 1, 1, 1, 1, 1], \"Freq\": [31.55142593383789, 23.71156883239746, 16.301681518554688, 13.25844955444336, 8.192839622497559, 3.5605006217956543, 3.4235284328460693]}, \"tinfo\": {\"Term\": [\"tablet\", \"work\", \"echo\", \"book\", \"great\", \"alexa\", \"product\", \"kindle\", \"lot\", \"kid\", \"music\", \"old\", \"device\", \"sound\", \"show\", \"year\", \"home\", \"read\", \"light\", \"video\", \"price\", \"easy\", \"best\", \"amazon\", \"game\", \"item\", \"smart\", \"love\", \"fire\", \"good\", \"kid\", \"old\", \"child\", \"grandson\", \"year\", \"parental\", \"age\", \"granddaughter\", \"tablet\", \"son\", \"durable\", \"educational\", \"daughter\", \"storage\", \"price\", \"adult\", \"yr\", \"charger\", \"game\", \"grand\", \"young\", \"parent\", \"gift\", \"bought\", \"speed\", \"pleased\", \"toddler\", \"ipad\", \"plenty\", \"appropriate\", \"warranty\", \"apps\", \"christmas\", \"easy\", \"good\", \"hd\", \"perfect\", \"love\", \"use\", \"great\", \"fire\", \"happy\", \"product\", \"time\", \"little\", \"case\", \"nice\", \"size\", \"play\", \"amazon\", \"work\", \"quality\", \"kindle\", \"alexa\", \"sound\", \"house\", \"tap\", \"dot\", \"news\", \"bulb\", \"kitchen\", \"recipe\", \"ask\", \"weather\", \"hue\", \"show\", \"echo\", \"music\", \"room\", \"speaker\", \"it\\u201a\\u00e4\\u00f4s\", \"list\", \"lyric\", \"song\", \"question\", \"bedroom\", \"talk\", \"listen\", \"volume\", \"hear\", \"morning\", \"timer\", \"whole\", \"family\", \"hub\", \"voice\", \"portable\", \"light\", \"fun\", \"thing\", \"able\", \"amazon\", \"great\", \"love\", \"use\", \"play\", \"device\", \"quality\", \"screen\", \"home\", \"feature\", \"video\", \"product\", \"easy\", \"time\", \"good\", \"store\", \"magazine\", \"life\", \"online\", \"menu\", \"customer\", \"photo\", \"service\", \"email\", \"tag\", \"buy\", \"law\", \"battery\", \"best\", \"next\", \"computer\", \"grandkids\", \"subscription\", \"facebook\", \"money\", \"swipe\", \"network\", \"google\", \"digital\", \"keyboard\", \"biggest\", \"third\", \"code\", \"class\", \"watch\", \"version\", \"access\", \"upgrade\", \"prime\", \"experience\", \"app\", \"amazon\", \"internet\", \"screen\", \"download\", \"device\", \"member\", \"kindle\", \"movie\", \"free\", \"fire\", \"day\", \"time\", \"play\", \"tablet\", \"book\", \"much\", \"great\", \"little\", \"new\", \"apps\", \"use\", \"read\", \"reader\", \"paperwhite\", \"oasis\", \"voyage\", \"cover\", \"model\", \"dark\", \"purse\", \"weight\", \"lightweight\", \"paper\", \"eye\", \"book\", \"white\", \"fit\", \"junk\", \"nook\", \"compact\", \"bright\", \"page\", \"sunlight\", \"longer\", \"e\", \"glare\", \"text\", \"ebook\", \"bag\", \"avid\", \"sun\", \"charge\", \"car\", \"night\", \"kindle\", \"last\", \"reading\", \"light\", \"easier\", \"library\", \"hand\", \"small\", \"size\", \"week\", \"new\", \"screen\", \"easy\", \"much\", \"battery\", \"case\", \"able\", \"thing\", \"use\", \"friend\", \"automation\", \"answer\", \"addition\", \"useful\", \"assistant\", \"satisfied\", \"work\", \"informative\", \"mess\", \"recognition\", \"consumer\", \"smart\", \"iphone\", \"people\", \"entertaining\", \"make\", \"connects\", \"knowledgeable\", \"home\", \"associate\", \"integration\", \"owner\", \"basis\", \"appointment\", \"compare\", \"fair\", \"siri\", \"doorbell\", \"man\", \"helpful\", \"video\", \"product\", \"device\", \"security\", \"youtube\", \"call\", \"phone\", \"great\", \"information\", \"wifi\", \"camera\", \"easier\", \"good\", \"echo\", \"voice\", \"nice\", \"anyone\", \"item\", \"need\", \"amazon\", \"sale\", \"family\", \"thing\", \"screen\", \"use\", \"fun\", \"sd\", \"card\", \"slot\", \"instruction\", \"nexus\", \"recipient\", \"savvy\", \"purchased\", \"teenager\", \"alternative\", \"darn\", \"hope\", \"item\", \"transfer\", \"forward\", \".easy\", \"advertised\", \"credit\", \"stair\", \"flight\", \"pre\", \"lucky\", \"mini\", \"senior\", \"desciples\", \"better/faster\", \"saver\", \"hitch\", \"shy\", \"phooey\", \"electronic\", \"data\", \"memory\", \"fact\", \"member\", \"couple\", \"ipad\", \"tech\", \"assistance\", \"money\", \"break\", \"thing\", \"add\", \"cheap\", \"problem\", \"model\", \"family\", \"lot\", \"busy\", \"s2\", \"functionality\", \"manual\", \"squad\", \"in-law\", \"efficient\", \"geek\", \"daughter-in-law\", \"amplitude\", \"netflix\", \"evening\", \"feachers\", \"goodexcellent\", \"screenlike\", \"sweet\", \"sister\", \"easy-to-use\", \"vibrant\", \"well.this\", \"punch..\", \"spouse\", \"headphone\", \"great..i\", \"it..glad\", \"it..my\", \"stand/cover\", \"bed\", \"difficult\", \"clarity\", \"equipment\", \"box\", \"hulu\", \"stream\", \"natural\", \"steal\", \"tab\", \"intuitive\", \"thought\", \"hard\", \"quick\", \"pair\", \"navigate\", \"setup\", \"decent\", \"right\", \"clear\", \"size\", \"thing\", \"screen\", \"easy\", \"inch\", \"good\"], \"Freq\": [1026.0, 323.0, 434.0, 313.0, 1143.0, 307.0, 373.0, 397.0, 119.0, 333.0, 302.0, 316.0, 313.0, 229.0, 274.0, 313.0, 175.0, 124.0, 231.0, 202.0, 357.0, 598.0, 204.0, 473.0, 292.0, 90.0, 104.0, 537.0, 322.0, 475.0, 327.69384765625, 308.13189697265625, 113.78463745117188, 89.4934310913086, 298.91424560546875, 48.03357696533203, 48.035865783691406, 64.3422622680664, 947.8743896484375, 153.34706115722656, 39.69541931152344, 31.751792907714844, 138.01925659179688, 47.85474395751953, 318.4345397949219, 27.828100204467773, 22.717199325561523, 28.50330352783203, 253.22752380371094, 23.205326080322266, 19.456178665161133, 35.022701263427734, 206.36334228515625, 67.84820556640625, 20.993215560913086, 30.23004150390625, 16.34306526184082, 70.15692138671875, 17.783161163330078, 15.216387748718262, 29.12067985534668, 183.70547485351562, 120.10126495361328, 438.9407958984375, 340.333984375, 60.705135345458984, 129.9196319580078, 365.99090576171875, 459.021240234375, 702.5750732421875, 217.9489288330078, 90.0227279663086, 177.36111450195312, 146.61724853515625, 91.27220153808594, 70.39762878417969, 81.59233093261719, 83.14559936523438, 91.67408752441406, 114.34298706054688, 99.19234466552734, 80.07937622070312, 96.81234741210938, 303.1778869628906, 221.87779235839844, 101.26012420654297, 72.19697570800781, 98.13453674316406, 51.173465728759766, 47.918853759765625, 46.681766510009766, 39.800865173339844, 40.72265625, 61.60190200805664, 43.63314437866211, 249.84625244140625, 395.47186279296875, 274.26434326171875, 76.41973114013672, 143.61793518066406, 39.41123962402344, 36.69147872924805, 28.615842819213867, 26.941125869750977, 63.47520065307617, 18.513097763061523, 27.394554138183594, 32.50674057006836, 18.914295196533203, 16.946758270263672, 18.405460357666016, 17.328813552856445, 33.65372085571289, 106.31172180175781, 41.93634796142578, 43.318511962890625, 36.03554153442383, 128.96836853027344, 74.77731323242188, 121.30767059326172, 86.64685821533203, 150.473876953125, 239.2493438720703, 140.695556640625, 149.82192993164062, 82.98011779785156, 95.8145980834961, 66.7297592163086, 86.41089630126953, 65.43083953857422, 65.73444366455078, 67.2056884765625, 76.00054168701172, 83.29953002929688, 71.12762451171875, 64.58345794677734, 84.20744323730469, 31.943824768066406, 89.49772644042969, 38.32514190673828, 13.569926261901855, 20.44540023803711, 25.950159072875977, 33.29824447631836, 26.900774002075195, 9.400836944580078, 83.9420166015625, 11.1906156539917, 86.51136016845703, 141.41058349609375, 19.00336265563965, 19.851961135864258, 17.6594181060791, 9.748957633972168, 15.776713371276855, 46.33970642089844, 7.740373611450195, 12.41739559173584, 56.18706130981445, 11.512680053710938, 9.612556457519531, 9.071887016296387, 12.353745460510254, 5.812025547027588, 7.261280536651611, 51.03175354003906, 42.09951400756836, 37.34101486206055, 32.14006042480469, 53.293113708496094, 16.494220733642578, 46.73762512207031, 182.68844604492188, 47.02851104736328, 134.3169708251953, 32.745323181152344, 109.39970397949219, 21.394264221191406, 116.1560287475586, 44.10493469238281, 37.84651565551758, 80.87857818603516, 40.61195373535156, 55.97010040283203, 49.52790069580078, 73.95842742919922, 51.37774658203125, 42.03850555419922, 63.5531120300293, 39.320289611816406, 40.19456481933594, 40.48634338378906, 38.14065170288086, 118.59119415283203, 66.62184143066406, 43.2950325012207, 34.91543960571289, 39.705650329589844, 48.08636474609375, 58.549007415771484, 21.433427810668945, 21.50200653076172, 23.927021026611328, 19.446205139160156, 15.310347557067871, 22.7708797454834, 255.4981231689453, 17.536237716674805, 36.13557052612305, 12.794242858886719, 11.16746997833252, 18.443748474121094, 14.852424621582031, 42.62240219116211, 7.890079975128174, 7.947912693023682, 8.311640739440918, 7.30114221572876, 15.148080825805664, 8.000872611999512, 9.422690391540527, 8.616250038146973, 7.40735387802124, 44.63603210449219, 11.971715927124023, 17.847288131713867, 182.0599822998047, 38.37827682495117, 37.99382781982422, 95.03553009033203, 29.746822357177734, 17.224201202392578, 33.141090393066406, 43.11842346191406, 47.416805267333984, 24.75665283203125, 48.942142486572266, 60.79859161376953, 65.42693328857422, 37.02738571166992, 32.046791076660156, 29.901866912841797, 27.327177047729492, 26.161500930786133, 27.86347007751465, 35.55250930786133, 13.891663551330566, 16.4772891998291, 30.06268310546875, 19.75642204284668, 12.252696990966797, 10.081402778625488, 173.57269287109375, 4.019327640533447, 4.317684650421143, 5.394582271575928, 3.571761131286621, 52.511940002441406, 4.751450061798096, 12.145373344421387, 3.4718053340911865, 8.287445068359375, 3.2301506996154785, 3.6035139560699463, 82.67758178710938, 4.498311996459961, 5.978837966918945, 4.36965799331665, 3.4134504795074463, 3.0893630981445312, 2.958683490753174, 3.070517063140869, 2.5128302574157715, 6.754270076751709, 2.3745741844177246, 15.137887954711914, 72.57523345947266, 116.08976745605469, 91.14073181152344, 11.516468048095703, 10.352975845336914, 15.819854736328125, 21.838157653808594, 128.66586303710938, 9.577753067016602, 11.013008117675781, 20.135093688964844, 12.754905700683594, 39.00275802612305, 36.500877380371094, 12.207868576049805, 18.397579193115234, 9.89863109588623, 13.626188278198242, 13.635384559631348, 20.8377742767334, 12.239970207214355, 13.742875099182129, 13.889050483703613, 14.266316413879395, 13.513917922973633, 12.3434419631958, 11.161725997924805, 18.58717155456543, 4.40941858291626, 9.747188568115234, 3.705552339553833, 3.8803954124450684, 4.533722877502441, 5.013715744018555, 2.3480191230773926, 4.950949192047119, 1.9989240169525146, 2.9856481552124023, 31.356107711791992, 1.9139238595962524, 2.460815668106079, 1.7098019123077393, 2.0521721839904785, 2.203570604324341, 1.7296338081359863, 1.9254931211471558, 1.7188118696212769, 1.5923044681549072, 4.68515682220459, 1.756051778793335, 1.4512927532196045, 1.4512927532196045, 1.469086766242981, 1.3841365575790405, 1.3841326236724854, 1.4097734689712524, 4.191544055938721, 2.040138006210327, 6.635921478271484, 5.228031158447266, 5.487941741943359, 4.004550933837891, 7.067644119262695, 3.606067419052124, 2.364439010620117, 5.20667028427124, 2.30725359916687, 4.053571701049805, 2.3152308464050293, 2.372852087020874, 2.551010847091675, 2.320148468017578, 2.248182535171509, 71.0159683227539, 7.418426990509033, 3.6724472045898438, 6.816030502319336, 2.5347084999084473, 2.813924551010132, 1.8118634223937988, 1.9202038049697876, 2.9731857776641846, 1.727542519569397, 1.7424465417861938, 6.383386135101318, 1.8152159452438354, 1.4485880136489868, 1.4485880136489868, 1.4485880136489868, 1.4587655067443848, 5.216678619384766, 1.2747594118118286, 1.6414657831192017, 1.1195478439331055, 1.1195478439331055, 1.4276587963104248, 1.8894826173782349, 1.1064202785491943, 1.1064202785491943, 1.1064202785491943, 1.1546415090560913, 3.2995951175689697, 4.76469612121582, 3.492661952972412, 1.99851655960083, 3.3533432483673096, 1.769971489906311, 3.3703434467315674, 1.3460420370101929, 1.546401023864746, 3.173959255218506, 1.9554121494293213, 3.399712085723877, 3.153566837310791, 2.678147554397583, 2.116149663925171, 2.771759510040283, 2.5115511417388916, 2.315709114074707, 2.460228443145752, 2.4216156005859375, 2.4961812496185303, 2.5559322834014893, 2.6054317951202393, 2.315232276916504, 2.0064358711242676, 2.0449233055114746], \"Total\": [1026.0, 323.0, 434.0, 313.0, 1143.0, 307.0, 373.0, 397.0, 119.0, 333.0, 302.0, 316.0, 313.0, 229.0, 274.0, 313.0, 175.0, 124.0, 231.0, 202.0, 357.0, 598.0, 204.0, 473.0, 292.0, 90.0, 104.0, 537.0, 322.0, 475.0, 333.58538818359375, 316.2938232421875, 117.48443603515625, 92.82337188720703, 313.11798095703125, 51.35048294067383, 51.65769958496094, 69.2076644897461, 1026.4581298828125, 166.1103057861328, 43.166351318359375, 35.018653869628906, 152.49160766601562, 53.19822311401367, 357.35394287109375, 31.702381134033203, 26.047813415527344, 32.75296401977539, 292.24017333984375, 26.78594398498535, 22.768903732299805, 41.21589660644531, 243.0684356689453, 80.01119232177734, 24.904197692871094, 36.36137008666992, 19.686344146728516, 84.68941497802734, 21.504863739013672, 18.489166259765625, 35.43350601196289, 229.50253295898438, 149.6445770263672, 598.971923828125, 475.72906494140625, 76.53343200683594, 174.0264434814453, 537.7433471679688, 689.774169921875, 1143.7513427734375, 322.376220703125, 120.59358215332031, 373.4378967285156, 297.6758117675781, 165.35281372070312, 109.57354736328125, 159.8668670654297, 167.64573669433594, 226.49578857421875, 473.2354431152344, 323.4918518066406, 156.00625610351562, 397.2232971191406, 307.583984375, 229.8625030517578, 105.37068176269531, 75.67691802978516, 103.90054321289062, 54.71284103393555, 51.38578796386719, 50.16596221923828, 43.07868957519531, 44.31983947753906, 67.19941711425781, 47.6242790222168, 274.507568359375, 434.80535888671875, 302.76983642578125, 84.49784851074219, 158.9473876953125, 43.7130126953125, 40.912498474121094, 32.02183532714844, 30.399784088134766, 72.1782455444336, 21.77297592163086, 32.231807708740234, 38.31572341918945, 22.345067977905273, 20.19101333618164, 21.967193603515625, 20.800662994384766, 40.74973678588867, 132.7880096435547, 52.92622756958008, 58.30116271972656, 48.7165412902832, 231.54042053222656, 120.7360610961914, 230.0112762451172, 167.11874389648438, 473.2354431152344, 1143.7513427734375, 537.7433471679688, 689.774169921875, 226.49578857421875, 313.16790771484375, 156.00625610351562, 356.5552062988281, 175.63365173339844, 178.11782836914062, 202.59738159179688, 373.4378967285156, 598.971923828125, 297.6758117675781, 475.72906494140625, 89.9577407836914, 35.252845764160156, 102.9762191772461, 46.72018051147461, 16.935888290405273, 25.68267059326172, 32.953433990478516, 42.64980697631836, 34.972503662109375, 12.938455581665039, 116.92020416259766, 16.151321411132812, 124.9554214477539, 204.32730102539062, 27.509889602661133, 28.822355270385742, 25.6908016204834, 14.260746002197266, 23.154558181762695, 68.08570098876953, 11.619997024536133, 18.75094223022461, 86.43822479248047, 17.7723445892334, 14.893213272094727, 14.112689018249512, 19.358341217041016, 9.12407112121582, 11.545819282531738, 81.5006332397461, 67.47166442871094, 60.013893127441406, 51.7424430847168, 87.67870330810547, 26.383668899536133, 81.17208862304688, 473.2354431152344, 95.70308685302734, 356.5552062988281, 64.45453643798828, 313.16790771484375, 37.71354675292969, 397.2232971191406, 103.95030212402344, 90.74812316894531, 322.376220703125, 117.92969512939453, 297.6758117675781, 226.49578857421875, 1026.4581298828125, 313.640625, 170.03741455078125, 1143.7513427734375, 165.35281372070312, 196.883544921875, 229.50253295898438, 689.774169921875, 124.94881439208984, 71.04949188232422, 46.768375396728516, 38.18811798095703, 43.42855453491211, 53.07526397705078, 66.62344360351562, 24.792818069458008, 24.931564331054688, 27.7684383392334, 22.89392852783203, 18.6978816986084, 27.82001304626465, 313.640625, 21.64044761657715, 45.55253601074219, 16.136478424072266, 14.693046569824219, 24.823856353759766, 20.152263641357422, 58.46579360961914, 11.139995574951172, 11.285147666931152, 12.06039047241211, 10.60586166381836, 22.047901153564453, 11.65506649017334, 13.844060897827148, 12.812231063842773, 11.051944732666016, 67.26834106445312, 18.35755729675293, 28.94133949279785, 397.2232971191406, 68.92913055419922, 73.45796203613281, 231.54042053222656, 56.190155029296875, 29.18212127685547, 68.86482238769531, 98.40580749511719, 167.64573669433594, 54.21904373168945, 196.883544921875, 356.5552062988281, 598.971923828125, 170.03741455078125, 124.9554214477539, 109.57354736328125, 167.11874389648438, 230.0112762451172, 689.774169921875, 44.70547866821289, 18.022241592407227, 22.296646118164062, 41.57817459106445, 31.675844192504883, 20.275630950927734, 17.864255905151367, 323.4918518066406, 7.5581512451171875, 8.309259414672852, 10.459456443786621, 7.055852890014648, 104.02848815917969, 9.445897102355957, 24.618804931640625, 7.122593879699707, 17.02587127685547, 6.707918643951416, 7.551472187042236, 175.63365173339844, 9.612749099731445, 12.966318130493164, 9.894391059875488, 7.758249759674072, 7.0992512702941895, 6.98602294921875, 7.310352325439453, 6.021871566772461, 16.26006507873535, 5.78822660446167, 36.94392776489258, 202.59738159179688, 373.4378967285156, 313.16790771484375, 32.36885070800781, 30.288497924804688, 57.703792572021484, 92.42990112304688, 1143.7513427734375, 29.63262939453125, 38.805118560791016, 115.80550384521484, 56.190155029296875, 475.72906494140625, 434.80535888671875, 58.30116271972656, 159.8668670654297, 40.19845199584961, 90.63817596435547, 93.55531311035156, 473.2354431152344, 71.09774017333984, 132.7880096435547, 230.0112762451172, 356.5552062988281, 689.774169921875, 120.7360610961914, 16.921796798706055, 32.74238204956055, 8.310482025146484, 18.649738311767578, 7.267441749572754, 8.062634468078613, 10.30672550201416, 12.650028228759766, 6.014435291290283, 12.895040512084961, 5.517062664031982, 8.274737358093262, 90.63817596435547, 5.570187568664551, 7.507596969604492, 5.41875696182251, 6.533456802368164, 7.024315357208252, 5.545279026031494, 6.295778751373291, 5.644837856292725, 5.281190872192383, 15.57609748840332, 5.929772853851318, 4.9983906745910645, 4.9983906745910645, 5.149621963500977, 4.8539204597473145, 4.8539228439331055, 5.025137901306152, 15.547525405883789, 7.858325004577637, 40.59855651855469, 34.0894889831543, 37.71354675292969, 25.5284481048584, 84.68941497802734, 26.450477600097656, 11.378064155578613, 68.08570098876953, 17.089195251464844, 230.0112762451172, 22.558032989501953, 28.49739646911621, 81.14659118652344, 66.62344360351562, 132.7880096435547, 119.34683227539062, 12.506011009216309, 7.555397987365723, 16.044960021972656, 6.294940948486328, 7.3047332763671875, 5.342653751373291, 5.7234063148498535, 8.89444637298584, 5.287153720855713, 5.44384765625, 20.81955337524414, 5.920711040496826, 4.954575538635254, 4.954575538635254, 4.954575538635254, 5.3227996826171875, 20.832935333251953, 5.116396427154541, 6.672664165496826, 4.634736061096191, 4.634736061096191, 5.9440460205078125, 7.868165016174316, 4.607413291931152, 4.607413291931152, 4.607413291931152, 4.847656726837158, 13.957101821899414, 20.361576080322266, 15.102874755859375, 8.66708755493164, 16.888702392578125, 8.166744232177734, 18.275150299072266, 5.875387668609619, 7.208775043487549, 21.123287200927734, 10.276968955993652, 28.791488647460938, 35.129981994628906, 27.129119873046875, 14.74608039855957, 40.4370002746582, 40.363914489746094, 35.94771194458008, 57.47752380371094, 55.75437927246094, 167.64573669433594, 230.0112762451172, 356.5552062988281, 598.971923828125, 19.134763717651367, 475.72906494140625], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.918100118637085, -3.9797000885009766, -4.975900173187256, -5.216000080108643, -4.010000228881836, -5.8383002281188965, -5.8383002281188965, -5.546000003814697, -2.8559999465942383, -4.677499771118164, -6.0289998054504395, -6.252299785614014, -4.782800197601318, -5.8420000076293945, -3.9467999935150146, -6.384200096130371, -6.587100028991699, -6.360199928283691, -4.175899982452393, -6.565800189971924, -6.742000102996826, -6.154200077056885, -4.3805999755859375, -5.4928998947143555, -6.665999889373779, -6.301400184631348, -6.916399955749512, -5.459499835968018, -6.831999778747559, -6.987800121307373, -6.338799953460693, -4.4969000816345215, -4.921899795532227, -3.6257998943328857, -3.8803000450134277, -5.6041998863220215, -4.843299865722656, -3.8076000213623047, -3.5810999870300293, -3.1554999351501465, -4.325900077819824, -5.210100173950195, -4.5320000648498535, -4.722400188446045, -5.196400165557861, -5.455999851226807, -5.308499813079834, -5.289599895477295, -5.191999912261963, -4.9710001945495605, -5.113100051879883, -5.327199935913086, -5.137400150299072, -3.710200071334839, -4.02239990234375, -4.8069000244140625, -5.145199775695801, -4.838200092315674, -5.489299774169922, -5.554999828338623, -5.581200122833252, -5.740699768066406, -5.717800140380859, -5.303899765014648, -5.64870023727417, -3.903700113296509, -3.444499969482422, -3.810499906539917, -5.0883002281188965, -4.457399845123291, -5.750500202178955, -5.822000026702881, -6.0706000328063965, -6.130899906158447, -5.273900032043457, -6.506100177764893, -6.114200115203857, -5.9430999755859375, -6.484600067138672, -6.5945000648498535, -6.511899948120117, -6.572199821472168, -5.908400058746338, -4.758200168609619, -5.688399791717529, -5.656000137329102, -5.840000152587891, -4.565000057220459, -5.110000133514404, -4.626200199127197, -4.962699890136719, -4.410799980163574, -3.947000026702881, -4.478000164031982, -4.41510009765625, -5.005899906158447, -4.862100124359131, -5.223899841308594, -4.965400218963623, -5.243599891662598, -5.238900184631348, -5.216800212860107, -5.093800067901611, -5.002099990844727, -5.160099983215332, -5.2565999031066895, -4.616600036621094, -5.585899829864502, -4.555600166320801, -5.40369987487793, -6.441999912261963, -6.032100200653076, -5.793700218200684, -5.544400215148926, -5.757699966430664, -6.809100151062012, -4.619699954986572, -6.634799957275391, -4.589600086212158, -4.098199844360352, -6.105199813842773, -6.061600208282471, -6.178599834442139, -6.77269983291626, -6.291299819946289, -5.213900089263916, -7.003399848937988, -6.530799865722656, -5.021200180053711, -6.606400012969971, -6.786799907684326, -6.844699859619141, -6.535900115966797, -7.289899826049805, -7.067299842834473, -5.117400169372559, -5.309800148010254, -5.429800033569336, -5.579800128936768, -5.073999881744385, -6.246799945831299, -5.2052998542785645, -3.842099905014038, -5.199100017547607, -4.149700164794922, -5.561100006103516, -4.354800224304199, -5.986700057983398, -4.294899940490723, -5.263299942016602, -5.416299819946289, -4.656899929046631, -5.345799922943115, -5.025000095367432, -5.147299766540527, -4.746399879455566, -5.110599994659424, -5.311299800872803, -4.8979997634887695, -5.3780999183654785, -5.356100082397461, -5.348899841308594, -5.408599853515625, -4.067500114440918, -4.644199848175049, -5.075200080871582, -5.290299892425537, -5.1616997718811035, -4.970200061798096, -4.773399829864502, -5.778299808502197, -5.775100231170654, -5.6682000160217285, -5.8755998611450195, -6.114699840545654, -5.717700004577637, -3.299999952316284, -5.979000091552734, -5.255899906158447, -6.2941999435424805, -6.430200099945068, -5.928500175476074, -6.145100116729736, -5.090799808502197, -6.777599811553955, -6.770299911499023, -6.725599765777588, -6.855199813842773, -6.12529993057251, -6.763700008392334, -6.600100040435791, -6.689599990844727, -6.840700149536133, -5.0447001457214355, -6.3607001304626465, -5.961400032043457, -3.6389000415802, -5.195700168609619, -5.2058000564575195, -4.289000034332275, -5.450500011444092, -5.9969000816345215, -5.342400074005127, -5.0792999267578125, -4.9842000007629395, -5.634099960327148, -4.952600002288818, -4.7357001304626465, -4.662300109863281, -5.231599807739258, -5.375999927520752, -5.445300102233887, -5.535299777984619, -5.57889986038208, -5.515900135040283, -4.790800094604492, -5.730599880218506, -5.559899806976318, -4.958600044250488, -5.378399848937988, -5.856100082397461, -6.051199913024902, -3.2053000926971436, -6.970699787139893, -6.899099826812744, -6.676499843597412, -7.088799953460693, -4.4008002281188965, -6.803400039672852, -5.8649001121521, -7.117199897766113, -6.247099876403809, -7.189300060272217, -7.079899787902832, -3.946899890899658, -6.858099937438965, -6.573599815368652, -6.887199878692627, -7.134099960327148, -7.23390007019043, -7.277100086212158, -7.239999771118164, -7.440400123596191, -6.451700210571289, -7.497000217437744, -5.644599914550781, -4.077199935913086, -3.6075000762939453, -3.849400043487549, -5.918099880218506, -6.024600028991699, -5.600599765777588, -5.278200149536133, -3.5046000480651855, -6.102399826049805, -5.962800025939941, -5.359399795532227, -5.815899848937988, -4.698200225830078, -4.764500141143799, -5.859799861907959, -5.4496002197265625, -6.069499969482422, -5.749899864196777, -5.749199867248535, -5.325099945068359, -5.857100009918213, -5.741300106048584, -5.7307000160217285, -5.70389986038208, -5.7581000328063965, -5.848700046539307, -5.116000175476074, -4.605999946594238, -6.0447001457214355, -5.251500129699707, -6.218699932098389, -6.172599792480469, -6.016900062561035, -5.916299819946289, -6.674900054931641, -5.928899765014648, -6.835899829864502, -6.434700012207031, -4.083099842071533, -6.879300117492676, -6.627999782562256, -6.992099761962891, -6.809599876403809, -6.738399982452393, -6.980599880218506, -6.873300075531006, -6.9868998527526855, -7.063300132751465, -5.984099864959717, -6.965400218963623, -7.156000137329102, -7.156000137329102, -7.143799781799316, -7.203400135040283, -7.203400135040283, -7.185100078582764, -6.095399856567383, -6.815499782562256, -5.636000156402588, -5.874499797821045, -5.825900077819824, -6.14109992980957, -5.572999954223633, -6.2459001541137695, -6.667900085449219, -5.878499984741211, -6.692399978637695, -6.128900051116943, -6.689000129699707, -6.664400100708008, -6.5920000076293945, -6.6869001388549805, -6.718400001525879, -3.2263998985290527, -5.485300064086914, -6.188399791717529, -5.570000171661377, -6.559199810028076, -6.454699993133545, -6.894899845123291, -6.8368000984191895, -6.399600028991699, -6.942599773406982, -6.934000015258789, -5.6356000900268555, -6.893099784851074, -7.11870002746582, -7.11870002746582, -7.11870002746582, -7.111700057983398, -5.837399959564209, -7.246500015258789, -6.99370002746582, -7.376299858093262, -7.376299858093262, -7.133200168609619, -6.853000164031982, -7.3881001472473145, -7.3881001472473145, -7.3881001472473145, -7.3454999923706055, -6.295499801635742, -5.927999973297119, -6.23859977722168, -6.796899795532227, -6.279300212860107, -6.918300151824951, -6.274199962615967, -7.1921000480651855, -7.053299903869629, -6.3343000411987305, -6.818699836730957, -6.265600204467773, -6.340700149536133, -6.5040998458862305, -6.739699840545654, -6.469799995422363, -6.568399906158447, -6.649499893188477, -6.589000225067139, -6.604800224304199, -6.57450008392334, -6.55079984664917, -6.531700134277344, -6.649700164794922, -6.792900085449219, -6.773900032043457], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.135699987411499, 1.1274000406265259, 1.1216000318527222, 1.1169999837875366, 1.107100009918213, 1.0867999792099, 1.080899953842163, 1.0807000398635864, 1.0738999843597412, 1.0736000537872314, 1.069700002670288, 1.0556000471115112, 1.0537999868392944, 1.047700047492981, 1.0382000207901, 1.0232000350952148, 1.016700029373169, 1.0146000385284424, 1.0103000402450562, 1.01010000705719, 0.9962999820709229, 0.9907000064849854, 0.989799976348877, 0.9886999726295471, 0.982699990272522, 0.9689000248908997, 0.9674000144004822, 0.9653000235557556, 0.9635000228881836, 0.9587000012397766, 0.9573000073432922, 0.9309999942779541, 0.9336000084877014, 0.8427000045776367, 0.8185999989509583, 0.9218999743461609, 0.861299991607666, 0.7688000202178955, 0.7462999820709229, 0.6661999821662903, 0.7620999813079834, 0.8611999750137329, 0.4090000092983246, 0.4453999996185303, 0.5593000054359436, 0.7110999822616577, 0.48089998960494995, 0.4523000121116638, 0.249099999666214, -0.2667999863624573, -0.028599999845027924, 0.48669999837875366, -0.2581999897956848, 1.4248000383377075, 1.4039000272750854, 1.399399995803833, 1.3920999765396118, 1.382099986076355, 1.3723000288009644, 1.3694000244140625, 1.3672000169754028, 1.3601000308990479, 1.354599952697754, 1.3522000312805176, 1.351699948310852, 1.3451000452041626, 1.3444000482559204, 1.3402999639511108, 1.3387000560760498, 1.3378000259399414, 1.3356000185012817, 1.330299973487854, 1.32669997215271, 1.3184000253677368, 1.3107000589370728, 1.2769999504089355, 1.2766000032424927, 1.2747999429702759, 1.2725000381469727, 1.2640000581741333, 1.2623000144958496, 1.256600022315979, 1.2479000091552734, 1.2167999744415283, 1.2065000534057617, 1.142199993133545, 1.1376999616622925, 0.8539999723434448, 0.960099995136261, 0.7993999719619751, 0.7822999954223633, 0.29339998960494995, -0.12540000677108765, 0.09839999675750732, -0.0877000018954277, 0.4350999891757965, 0.2549000084400177, 0.5899999737739563, 0.021800000220537186, 0.45179998874664307, 0.4424000084400177, 0.33570000529289246, -0.15279999375343323, -0.5335999727249146, 0.007699999958276749, -0.557699978351593, 1.7477999925613403, 1.7152999639511108, 1.6735999584197998, 1.6158000230789185, 1.5923000574111938, 1.585800051689148, 1.5750000476837158, 1.5664000511169434, 1.5514999628067017, 1.4945000410079956, 1.4824999570846558, 1.4470000267028809, 1.4462000131607056, 1.4457999467849731, 1.444000005722046, 1.441100001335144, 1.4390000104904175, 1.4335999488830566, 1.4301999807357788, 1.4291000366210938, 1.4076000452041626, 1.4018000364303589, 1.3832000494003296, 1.379699945449829, 1.376099944114685, 1.371999979019165, 1.3646999597549438, 1.3629000186920166, 1.350100040435791, 1.3457000255584717, 1.3422000408172607, 1.339400053024292, 1.3377000093460083, 1.315999984741211, 1.3442000150680542, 1.2618999481201172, 0.8621000051498413, 1.1033999919891357, 0.8375999927520752, 1.1367000341415405, 0.7621999979019165, 1.246999979019165, 0.5842999815940857, 0.95660001039505, 0.9394000172615051, 0.4311000108718872, 0.7479000091552734, 0.14270000159740448, 0.2937000095844269, -0.8165000081062317, 0.004900000058114529, 0.4165000021457672, -1.076300024986267, 0.3776000142097473, 0.22499999403953552, 0.07900000363588333, -1.0812000036239624, 1.9682999849319458, 1.9562000036239624, 1.9434000253677368, 1.930899977684021, 1.930899977684021, 1.9218000173568726, 1.8912999629974365, 1.874899983406067, 1.872499942779541, 1.8716000318527222, 1.857300043106079, 1.8207000494003296, 1.8202999830245972, 1.815500020980835, 1.8101999759674072, 1.7889000177383423, 1.7884000539779663, 1.7461999654769897, 1.7235000133514404, 1.715399980545044, 1.7044999599456787, 1.6756000518798828, 1.6699999570846558, 1.648300051689148, 1.6471999883651733, 1.6452000141143799, 1.6442999839782715, 1.6358000040054321, 1.6238000392913818, 1.6203999519348145, 1.6103999614715576, 1.593000054359436, 1.5370999574661255, 1.240399956703186, 1.4349000453948975, 1.361199975013733, 1.1299999952316284, 1.3845000267028809, 1.493299961090088, 1.289199948310852, 1.1953999996185303, 0.7577000260353088, 1.2366000413894653, 0.628600001335144, 0.2515999972820282, -0.19370000064373016, 0.49619999527931213, 0.6597999930381775, 0.7218999862670898, 0.20970000326633453, -0.15330000221729279, -1.1885000467300415, 2.2727999687194824, 2.2416000366210938, 2.19950008392334, 2.1775999069213867, 2.0297999382019043, 1.9982000589370728, 1.929800033569336, 1.8792999982833862, 1.8703999519348145, 1.8473000526428223, 1.8398000001907349, 1.8210999965667725, 1.8183000087738037, 1.8148000240325928, 1.795300006866455, 1.7833000421524048, 1.7819000482559204, 1.7711000442504883, 1.7620999813079834, 1.7484999895095825, 1.7424999475479126, 1.7278000116348267, 1.6845999956130981, 1.680899977684021, 1.6698999404907227, 1.642699956893921, 1.6345000267028809, 1.6279000043869019, 1.6233999729156494, 1.6109000444412231, 1.6096999645233154, 1.4752999544143677, 1.3335000276565552, 1.2676000595092773, 1.468500018119812, 1.4284000396728516, 1.207900047302246, 1.0591000318527222, 0.31709998846054077, 1.372499942779541, 1.242400050163269, 0.7524999976158142, 1.0190999507904053, 0.000699999975040555, 0.024299999698996544, 0.9383999705314636, 0.33980000019073486, 1.1004999876022339, 0.6069999933242798, 0.5759999752044678, -0.6208999752998352, 0.7426000237464905, 0.2337000072002411, -0.3050999939441681, -0.71670001745224, -1.4306999444961548, 0.22139999270439148, 2.9191999435424805, 2.7690999507904053, 2.7014999389648438, 2.6863999366760254, 2.6617000102996826, 2.6040000915527344, 2.5139999389648438, 2.4098000526428223, 2.394700050354004, 2.378000020980835, 2.319999933242798, 2.3159000873565674, 2.2737998962402344, 2.2669999599456787, 2.2197999954223633, 2.18179988861084, 2.1772000789642334, 2.1760001182556152, 2.1702001094818115, 2.150599956512451, 2.146199941635132, 2.1363000869750977, 2.1338999271392822, 2.1184000968933105, 2.098599910736084, 2.098599910736084, 2.0810000896453857, 2.0806000232696533, 2.0806000232696533, 2.064199924468994, 2.024399995803833, 1.9867000579833984, 1.5240000486373901, 1.4602999687194824, 1.4077999591827393, 1.4829000234603882, 0.8518000245094299, 1.3425999879837036, 1.7640999555587769, 0.7644000053405762, 1.332900047302246, -0.7032999992370605, 1.0586999654769897, 0.8495000004768372, -0.12449999898672104, -0.022199999541044235, -0.743399977684021, 2.8554000854492188, 2.852299928665161, 2.65310001373291, 2.518399953842163, 2.4647998809814453, 2.420599937438965, 2.293100118637085, 2.282399892807007, 2.278700113296509, 2.2558999061584473, 2.235300064086914, 2.1923000812530518, 2.192199945449829, 2.1447999477386475, 2.1447999477386475, 2.1447999477386475, 2.0801000595092773, 1.989799976348877, 1.9847999811172485, 1.972100019454956, 1.9537999629974365, 1.9537999629974365, 1.948099970817566, 1.9479999542236328, 1.9479999542236328, 1.9479999542236328, 1.9479999542236328, 1.9398000240325928, 1.9322999715805054, 1.9220999479293823, 1.9103000164031982, 1.9074000120162964, 1.7577999830245972, 1.8453999757766724, 1.684000015258789, 1.9009000062942505, 1.8351000547409058, 1.479099988937378, 1.7151999473571777, 1.2381000518798828, 0.9639999866485596, 1.059000015258789, 1.4330999851226807, 0.6941999793052673, 0.5975000262260437, 0.632099986076355, 0.22339999675750732, 0.23800000548362732, -0.8325999975204468, -1.1252000331878662, -1.5443999767303467, -2.1812000274658203, 1.1194000244140625, -2.075000047683716]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 6, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5], \"Freq\": [0.184544175863266, 0.184544175863266, 0.184544175863266, 0.184544175863266, 0.184544175863266, 0.369088351726532, 0.2213994562625885, 0.5205879211425781, 0.08377277106046677, 0.1615617722272873, 0.011967538855969906, 0.2832677364349365, 0.033325616270303726, 0.6165239214897156, 0.033325616270303726, 0.016662808135151863, 0.016662808135151863, 0.016662808135151863, 0.13299031555652618, 0.4876311719417572, 0.08866021037101746, 0.08866021037101746, 0.04433010518550873, 0.08866021037101746, 0.024051079526543617, 0.216459721326828, 0.024051079526543617, 0.024051079526543617, 0.72153240442276, 0.8832144141197205, 0.031543370336294174, 0.031543370336294174, 0.031543370336294174, 0.031543370336294174, 0.15305833518505096, 0.15305833518505096, 0.15305833518505096, 0.15305833518505096, 0.15305833518505096, 0.30611667037010193, 0.9291934967041016, 0.01935819908976555, 0.01935819908976555, 0.01935819908976555, 0.01935819908976555, 0.003251144662499428, 0.98509681224823, 0.003251144662499428, 0.003251144662499428, 0.006502289324998856, 0.3877459764480591, 0.07754919677972794, 0.07754919677972794, 0.07754919677972794, 0.3877459764480591, 0.2408948838710785, 0.3169669508934021, 0.38669970631599426, 0.008452452719211578, 0.04437537491321564, 0.18369360268115997, 0.18369360268115997, 0.18369360268115997, 0.18369360268115997, 0.36738720536231995, 0.04484979435801506, 0.13454937934875488, 0.04484979435801506, 0.04484979435801506, 0.717596709728241, 0.3980252742767334, 0.14925947785377502, 0.12438289821147919, 0.049753159284591675, 0.24876579642295837, 0.17247307300567627, 0.22175109386444092, 0.5790167450904846, 0.012319505214691162, 0.012319505214691162, 0.1408599317073822, 0.1408599317073822, 0.1408599317073822, 0.1408599317073822, 0.4225797653198242, 0.8112859129905701, 0.05408572778105736, 0.05408572778105736, 0.05408572778105736, 0.8017340898513794, 0.004357250407338142, 0.1742900162935257, 0.004357250407338142, 0.008714500814676285, 0.004357250407338142, 0.004357250407338142, 0.022563258185982704, 0.9250935912132263, 0.022563258185982704, 0.022563258185982704, 0.022563258185982704, 0.17577682435512543, 0.08788841217756271, 0.35155364871025085, 0.08788841217756271, 0.08788841217756271, 0.17577682435512543, 0.049320291727781296, 0.24660144746303558, 0.049320291727781296, 0.049320291727781296, 0.5918434858322144, 0.049320291727781296, 0.10402851551771164, 0.10402851551771164, 0.20805703103542328, 0.10402851551771164, 0.41611406207084656, 0.05548699200153351, 0.05548699200153351, 0.05548699200153351, 0.05548699200153351, 0.7768179178237915, 0.07805041968822479, 0.07805041968822479, 0.07805041968822479, 0.7024537920951843, 0.07805041968822479, 0.14446628093719482, 0.07223314046859741, 0.07223314046859741, 0.6500982642173767, 0.12889504432678223, 0.12889504432678223, 0.12889504432678223, 0.12889504432678223, 0.38668516278266907, 0.03201141580939293, 0.008002853952348232, 0.6962482929229736, 0.25609132647514343, 0.008002853952348232, 0.07164811342954636, 0.2865924537181854, 0.07164811342954636, 0.21494433283805847, 0.1432962268590927, 0.21494433283805847, 0.04592849314212799, 0.872641384601593, 0.04592849314212799, 0.04592849314212799, 0.04592849314212799, 0.1076703891158104, 0.15171736478805542, 0.690069317817688, 0.03915286809206009, 0.004894108511507511, 0.20006439089775085, 0.20006439089775085, 0.20006439089775085, 0.20006439089775085, 0.20006439089775085, 0.07085821777582169, 0.07085821777582169, 0.637723982334137, 0.14171643555164337, 0.07085821777582169, 0.012753450311720371, 0.003188362577930093, 0.16260649263858795, 0.8130324482917786, 0.003188362577930093, 0.003188362577930093, 0.849881112575531, 0.06249125674366951, 0.04999300464987755, 0.024996502324938774, 0.012498251162469387, 0.2960559129714966, 0.05921117961406708, 0.35526707768440247, 0.05921117961406708, 0.05921117961406708, 0.17763353884220123, 0.7021980881690979, 0.05851650610566139, 0.05851650610566139, 0.05851650610566139, 0.05851650610566139, 0.11703301221132278, 0.04962221533060074, 0.04962221533060074, 0.04962221533060074, 0.7443332672119141, 0.09924443066120148, 0.019460633397102356, 0.9341104030609131, 0.019460633397102356, 0.019460633397102356, 0.019460633397102356, 0.15992309153079987, 0.07996154576539993, 0.07996154576539993, 0.07996154576539993, 0.07996154576539993, 0.5597308278083801, 0.05131705105304718, 0.1453983038663864, 0.7184386849403381, 0.07697557657957077, 0.00855284184217453, 0.08664941787719727, 0.5892160534858704, 0.017329882830381393, 0.017329882830381393, 0.2772781252861023, 0.27632537484169006, 0.47493425011634827, 0.060446176677942276, 0.008635167963802814, 0.17270337045192719, 0.008635167963802814, 0.21789391338825226, 0.054473478347063065, 0.054473478347063065, 0.653681755065918, 0.054473478347063065, 0.03054145537316799, 0.03054145537316799, 0.33595600724220276, 0.03054145537316799, 0.03054145537316799, 0.5802876353263855, 0.6388403177261353, 0.009126290678977966, 0.0547577403485775, 0.273788720369339, 0.009126290678977966, 0.009126290678977966, 0.22298751771450043, 0.014865834265947342, 0.07432916760444641, 0.6689625382423401, 0.014865834265947342, 0.8854160308837891, 0.030531587079167366, 0.030531587079167366, 0.030531587079167366, 0.030531587079167366, 0.5614547729492188, 0.03509092330932617, 0.17545463144779205, 0.1403636932373047, 0.03509092330932617, 0.07018184661865234, 0.9703413248062134, 0.008511765860021114, 0.008511765860021114, 0.008511765860021114, 0.008511765860021114, 0.008511765860021114, 0.8019000887870789, 0.1737450212240219, 0.006682500708848238, 0.006682500708848238, 0.006682500708848238, 0.06621255725622177, 0.1986376792192459, 0.06621255725622177, 0.3972753584384918, 0.06621255725622177, 0.1986376792192459, 0.08661143481731415, 0.08661143481731415, 0.6062800884246826, 0.08661143481731415, 0.08661143481731415, 0.3766520321369171, 0.21522973477840424, 0.16142229735851288, 0.17935810983181, 0.01793581061065197, 0.03587162122130394, 0.10960020124912262, 0.10960020124912262, 0.6576011776924133, 0.10960020124912262, 0.10960020124912262, 0.08056765794754028, 0.04028382897377014, 0.08056765794754028, 0.7251089215278625, 0.04028382897377014, 0.1431429535150528, 0.1431429535150528, 0.1431429535150528, 0.1431429535150528, 0.4294288754463196, 0.06939058005809784, 0.03469529002904892, 0.6939058303833008, 0.10408587008714676, 0.03469529002904892, 0.03469529002904892, 0.14907753467559814, 0.14907753467559814, 0.14907753467559814, 0.14907753467559814, 0.44723260402679443, 0.1417263150215149, 0.1417263150215149, 0.1417263150215149, 0.1417263150215149, 0.5669052600860596, 0.039171986281871796, 0.35254788398742676, 0.31337589025497437, 0.039171986281871796, 0.07834397256374359, 0.15668794512748718, 0.01884116791188717, 0.01884116791188717, 0.01884116791188717, 0.9043760895729065, 0.01884116791188717, 0.14236262440681458, 0.14236262440681458, 0.28472524881362915, 0.14236262440681458, 0.28472524881362915, 0.038936760276556015, 0.07787352055311203, 0.7787352204322815, 0.038936760276556015, 0.038936760276556015, 0.04033426195383072, 0.04033426195383072, 0.04033426195383072, 0.8470194935798645, 0.18125587701797485, 0.18125587701797485, 0.18125587701797485, 0.18125587701797485, 0.3625117540359497, 0.12725357711315155, 0.12725357711315155, 0.38176074624061584, 0.12725357711315155, 0.12725357711315155, 0.2545071542263031, 0.9049678444862366, 0.01311547588557005, 0.06557738035917282, 0.006557737942785025, 0.006557737942785025, 0.18913768231868744, 0.18913768231868744, 0.18913768231868744, 0.18913768231868744, 0.3782753646373749, 0.1017555445432663, 0.3391851484775543, 0.3476647734642029, 0.18655182421207428, 0.008479628711938858, 0.4450909197330475, 0.22254545986652374, 0.19472727179527283, 0.027818182483315468, 0.027818182483315468, 0.027818182483315468, 0.055636364966630936, 0.20006439089775085, 0.20006439089775085, 0.20006439089775085, 0.20006439089775085, 0.20006439089775085, 0.006386350374668837, 0.30654481053352356, 0.3480561077594757, 0.04470445215702057, 0.2905789315700531, 0.04911211133003235, 0.04911211133003235, 0.5402332544326782, 0.04911211133003235, 0.04911211133003235, 0.04911211133003235, 0.24556055665016174, 0.05626719444990158, 0.16880159080028534, 0.6752063632011414, 0.05626719444990158, 0.05626719444990158, 0.05626719444990158, 0.061500370502471924, 0.43050259351730347, 0.061500370502471924, 0.061500370502471924, 0.43050259351730347, 0.009624588303267956, 0.943209707736969, 0.009624588303267956, 0.009624588303267956, 0.028873765841126442, 0.3102962374687195, 0.015514811500906944, 0.5119887590408325, 0.12411849200725555, 0.03102962300181389, 0.9266477227210999, 0.023166192695498466, 0.023166192695498466, 0.023166192695498466, 0.023166192695498466, 0.08291605859994888, 0.08291605859994888, 0.08291605859994888, 0.6633284687995911, 0.08291605859994888, 0.0177967119961977, 0.12457698583602905, 0.0711868479847908, 0.5339013338088989, 0.23135726153850555, 0.0177967119961977, 0.7329224944114685, 0.13857077062129974, 0.00834763702005148, 0.10851927846670151, 0.005008582025766373, 0.0016695273807272315, 0.003339054761454463, 0.1954500675201416, 0.1954500675201416, 0.1954500675201416, 0.1954500675201416, 0.1954500675201416, 0.1954500675201416, 0.08579959720373154, 0.08579959720373154, 0.08579959720373154, 0.6863967776298523, 0.08579959720373154, 0.002299879677593708, 0.9084524512290955, 0.002299879677593708, 0.002299879677593708, 0.08509554713964462, 0.9137986898422241, 0.028556209057569504, 0.028556209057569504, 0.028556209057569504, 0.028556209057569504, 0.1747211217880249, 0.1747211217880249, 0.1747211217880249, 0.1747211217880249, 0.1747211217880249, 0.3494422435760498, 0.06431891769170761, 0.32159459590911865, 0.06431891769170761, 0.25727567076683044, 0.06431891769170761, 0.25727567076683044, 0.14296945929527283, 0.028593892231583595, 0.7720350623130798, 0.028593892231583595, 0.028593892231583595, 0.1403982937335968, 0.1403982937335968, 0.1403982937335968, 0.1403982937335968, 0.4211948812007904, 0.11537901312112808, 0.34613704681396484, 0.11537901312112808, 0.11537901312112808, 0.11537901312112808, 0.23075802624225616, 0.16889862716197968, 0.16889862716197968, 0.16889862716197968, 0.16889862716197968, 0.16889862716197968, 0.33779725432395935, 0.07580447196960449, 0.037902235984802246, 0.6064357757568359, 0.11370670050382614, 0.15160894393920898, 0.0359453447163105, 0.0359453447163105, 0.071890689432621, 0.826742947101593, 0.0359453447163105, 0.17275215685367584, 0.04318803921341896, 0.6910086274147034, 0.08637607842683792, 0.04318803921341896, 0.17600733041763306, 0.2640109956264496, 0.058669108897447586, 0.29334554076194763, 0.029334554448723793, 0.14667277038097382, 0.13679231703281403, 0.13679231703281403, 0.13679231703281403, 0.13679231703281403, 0.4103769361972809, 0.06024640426039696, 0.7982648611068726, 0.00753080053254962, 0.00753080053254962, 0.1054312065243721, 0.01506160106509924, 0.20183363556861877, 0.20183363556861877, 0.20183363556861877, 0.20183363556861877, 0.20183363556861877, 0.3480841815471649, 0.3705412447452545, 0.10667096078395844, 0.10105670243501663, 0.06737112998962402, 0.005614261142909527, 0.6762285232543945, 0.0031019658781588078, 0.2512592375278473, 0.06514128297567368, 0.0031019658781588078, 0.0031019658781588078, 0.1317160427570343, 0.02195267379283905, 0.02195267379283905, 0.7902962565422058, 0.02195267379283905, 0.15883658826351166, 0.15883658826351166, 0.15883658826351166, 0.15883658826351166, 0.15883658826351166, 0.3176731765270233, 0.13319841027259827, 0.13319841027259827, 0.13319841027259827, 0.26639682054519653, 0.26639682054519653, 0.3416048586368561, 0.1983512043952942, 0.4187414348125458, 0.022039024159312248, 0.011019512079656124, 0.04473724588751793, 0.04473724588751793, 0.08947449177503586, 0.022368622943758965, 0.8052704334259033, 0.19878071546554565, 0.6211897134780884, 0.049695178866386414, 0.01656505838036537, 0.09939035773277283, 0.008282529190182686, 0.06232486665248871, 0.12464973330497742, 0.24929946660995483, 0.06232486665248871, 0.06232486665248871, 0.43627408146858215, 0.8657262921333313, 0.006843686103820801, 0.11634266376495361, 0.0034218430519104004, 0.0034218430519104004, 0.0034218430519104004, 0.33728912472724915, 0.11242970824241638, 0.11242970824241638, 0.11242970824241638, 0.11242970824241638, 0.11242970824241638, 0.33728912472724915, 0.8474979400634766, 0.09873762726783752, 0.04114067554473877, 0.004114067647606134, 0.004114067647606134, 0.09428748488426208, 0.09428748488426208, 0.09428748488426208, 0.6600123643875122, 0.7146925330162048, 0.13663239777088165, 0.021020367741584778, 0.042040735483169556, 0.08197943866252899, 0.004204073455184698, 0.20183363556861877, 0.20183363556861877, 0.20183363556861877, 0.20183363556861877, 0.20183363556861877, 0.11568956077098846, 0.11568956077098846, 0.6478615403175354, 0.011568956077098846, 0.09255164861679077, 0.8586593270301819, 0.037333011627197266, 0.037333011627197266, 0.037333011627197266, 0.037333011627197266, 0.9247530698776245, 0.014449266716837883, 0.028898533433675766, 0.014449266716837883, 0.014449266716837883, 0.0778488740324974, 0.1556977480649948, 0.7006398439407349, 0.0389244370162487, 0.0389244370162487, 0.0389244370162487, 0.9588102698326111, 0.010773148387670517, 0.010773148387670517, 0.010773148387670517, 0.010773148387670517, 0.6146441102027893, 0.20896150171756744, 0.055956218391656876, 0.0069945272989571095, 0.11278675496578217, 0.0017486318247392774, 0.0008743159123696387, 0.2170415222644806, 0.2170415222644806, 0.2170415222644806, 0.2170415222644806, 0.2170415222644806, 0.014521202072501183, 0.24686042964458466, 0.21781803667545319, 0.47919967770576477, 0.014521202072501183, 0.7463083863258362, 0.11609241366386414, 0.03316926211118698, 0.09121546894311905, 0.008292315527796745, 0.45545142889022827, 0.14232856035232544, 0.170794278383255, 0.11386285722255707, 0.028465714305639267, 0.0853971391916275, 0.7970373034477234, 0.013066185638308525, 0.16986040771007538, 0.013066185638308525, 0.013066185638308525, 0.12709443271160126, 0.12709443271160126, 0.38128331303596497, 0.12709443271160126, 0.12709443271160126, 0.2541888654232025, 0.04952698573470116, 0.84195876121521, 0.04952698573470116, 0.04952698573470116, 0.04952698573470116, 0.10827218741178513, 0.4330887496471405, 0.02706804685294628, 0.02706804685294628, 0.40602073073387146, 0.20601902902126312, 0.20601902902126312, 0.20601902902126312, 0.20601902902126312, 0.20601902902126312, 0.005693669896572828, 0.37008851766586304, 0.142341747879982, 0.005693669896572828, 0.4725745916366577, 0.12084975838661194, 0.24169951677322388, 0.12084975838661194, 0.12084975838661194, 0.12084975838661194, 0.3625492751598358, 0.009490305557847023, 0.9585208892822266, 0.009490305557847023, 0.009490305557847023, 0.009490305557847023, 0.018894223496317863, 0.7935574054718018, 0.018894223496317863, 0.018894223496317863, 0.1511537879705429, 0.02099769376218319, 0.9238985180854797, 0.02099769376218319, 0.02099769376218319, 0.02099769376218319, 0.3673434555530548, 0.12244781851768494, 0.12244781851768494, 0.12244781851768494, 0.12244781851768494, 0.24489563703536987, 0.18717290461063385, 0.18717290461063385, 0.18717290461063385, 0.18717290461063385, 0.3743458092212677, 0.3658263087272644, 0.052260901778936386, 0.3658263087272644, 0.052260901778936386, 0.052260901778936386, 0.10452180355787277, 0.06749317049980164, 0.43870559334754944, 0.13498634099960327, 0.03374658524990082, 0.3374658226966858, 0.1323074847459793, 0.1323074847459793, 0.1323074847459793, 0.1323074847459793, 0.5292299389839172, 0.05362005531787872, 0.05362005531787872, 0.2144802212715149, 0.05362005531787872, 0.05362005531787872, 0.5362005829811096, 0.10724011063575745, 0.07712289690971375, 0.23136869072914124, 0.1542457938194275, 0.07712289690971375, 0.46273738145828247, 0.44930630922317505, 0.010448983870446682, 0.4911022484302521, 0.010448983870446682, 0.020897967740893364, 0.010448983870446682, 0.19460991024971008, 0.09730495512485504, 0.29191485047340393, 0.09730495512485504, 0.09730495512485504, 0.19460991024971008, 0.8265495896339417, 0.023615702986717224, 0.035423554480075836, 0.011807851493358612, 0.011807851493358612, 0.08265496045351028, 0.011807851493358612, 0.10586606711149216, 0.10586606711149216, 0.10586606711149216, 0.10586606711149216, 0.5293303728103638, 0.2170415222644806, 0.2170415222644806, 0.2170415222644806, 0.2170415222644806, 0.2170415222644806, 0.2170415222644806, 0.2170415222644806, 0.2170415222644806, 0.2170415222644806, 0.2170415222644806, 0.02206575684249401, 0.26478907465934753, 0.19859181344509125, 0.011032878421247005, 0.15446029603481293, 0.3420192301273346, 0.02287648245692253, 0.8921828269958496, 0.02287648245692253, 0.02287648245692253, 0.04575296491384506, 0.06197138875722885, 0.06197138875722885, 0.06197138875722885, 0.8056280612945557, 0.06714467704296112, 0.06714467704296112, 0.6714468002319336, 0.20143403112888336, 0.06714467704296112, 0.9832565188407898, 0.005995466373860836, 0.002997733186930418, 0.002997733186930418, 0.002997733186930418, 0.002997733186930418, 0.2441951483488083, 0.0025174757465720177, 0.29202717542648315, 0.45818057656288147, 0.0025174757465720177, 0.019933834671974182, 0.9368902444839478, 0.019933834671974182, 0.019933834671974182, 0.019933834671974182, 0.1324245035648346, 0.1324245035648346, 0.1324245035648346, 0.1324245035648346, 0.5296980142593384, 0.20310716331005096, 0.014507654123008251, 0.18859951198101044, 0.5512908697128296, 0.014507654123008251, 0.029015308246016502, 0.12382888048887253, 0.061914440244436264, 0.6810588240623474, 0.061914440244436264, 0.061914440244436264, 0.03426755592226982, 0.13707022368907928, 0.20560534298419952, 0.5825484395027161, 0.03426755592226982, 0.019421959295868874, 0.06797686219215393, 0.8642772436141968, 0.03884391859173775, 0.009710979647934437, 0.004318900406360626, 0.5571381449699402, 0.017275601625442505, 0.4102955460548401, 0.008637800812721252, 0.043679703027009964, 0.043679703027009964, 0.043679703027009964, 0.8299143314361572, 0.043679703027009964, 0.024442408233880997, 0.9043691158294678, 0.024442408233880997, 0.024442408233880997, 0.024442408233880997, 0.0260989461094141, 0.861265242099762, 0.0260989461094141, 0.07829684019088745, 0.0260989461094141, 0.5503383874893188, 0.1632872074842453, 0.23585930466651917, 0.030238373205065727, 0.012095348909497261, 0.08861204236745834, 0.08861204236745834, 0.08861204236745834, 0.7088963389396667, 0.05865258350968361, 0.05865258350968361, 0.13406305015087128, 0.13406305015087128, 0.008378940634429455, 0.5949047803878784, 0.6806221008300781, 0.26220688223838806, 0.014876985922455788, 0.0390520878136158, 0.0018596232403069735, 0.0018596232403069735, 0.18935123085975647, 0.18935123085975647, 0.18935123085975647, 0.18935123085975647, 0.18935123085975647, 0.37870246171951294, 0.031228691339492798, 0.9056320190429688, 0.031228691339492798, 0.031228691339492798, 0.031228691339492798, 0.02836650423705578, 0.02836650423705578, 0.9077281355857849, 0.02836650423705578, 0.058734145015478134, 0.058734145015478134, 0.23493658006191254, 0.11746829003095627, 0.4698731601238251, 0.058734145015478134, 0.17276448011398315, 0.17276448011398315, 0.17276448011398315, 0.17276448011398315, 0.3455289602279663, 0.15885771811008453, 0.15885771811008453, 0.15885771811008453, 0.15885771811008453, 0.15885771811008453, 0.4765731692314148, 0.026515671983361244, 0.21212537586688995, 0.5568290948867798, 0.026515671983361244, 0.026515671983361244, 0.13257835805416107, 0.5418912172317505, 0.04926283657550812, 0.19705134630203247, 0.02463141828775406, 0.02463141828775406, 0.17241992056369781, 0.05904620885848999, 0.05904620885848999, 0.8266469240188599, 0.05904620885848999, 0.05904620885848999, 0.12034767121076584, 0.12034767121076584, 0.12034767121076584, 0.12034767121076584, 0.48139068484306335, 0.12840186059474945, 0.2568037211894989, 0.12840186059474945, 0.12840186059474945, 0.06420093029737473, 0.3210046589374542, 0.06420093029737473, 0.01500973105430603, 0.01500973105430603, 0.03001946210861206, 0.8855741620063782, 0.01500973105430603, 0.03001946210861206, 0.01500973105430603, 0.08812423050403595, 0.0293747428804636, 0.6756191253662109, 0.1174989715218544, 0.0146873714402318, 0.07343685626983643, 0.045522429049015045, 0.8194037079811096, 0.045522429049015045, 0.045522429049015045, 0.045522429049015045, 0.48099908232688904, 0.057719890028238297, 0.42327919602394104, 0.009619981981813908, 0.009619981981813908, 0.009619981981813908, 0.009619981981813908, 0.14702646434307098, 0.34110140800476074, 0.2470044642686844, 0.21759916841983795, 0.04704846814274788, 0.003302838886156678, 0.9049778580665588, 0.06935961544513702, 0.003302838886156678, 0.016514195129275322, 0.17020153999328613, 0.17020153999328613, 0.17020153999328613, 0.17020153999328613, 0.17020153999328613, 0.17020153999328613, 0.7418947815895081, 0.02472982555627823, 0.02472982555627823, 0.12364913523197174, 0.02472982555627823, 0.07418947666883469, 0.5665097832679749, 0.042755454778671265, 0.1923995465040207, 0.05344431847333908, 0.14964409172534943, 0.144095316529274, 0.0480317696928978, 0.43228593468666077, 0.0480317696928978, 0.0480317696928978, 0.288190633058548, 0.05333065241575241, 0.15999196469783783, 0.6399678587913513, 0.05333065241575241, 0.05333065241575241, 0.28951123356819153, 0.2488780915737152, 0.20316578447818756, 0.2488780915737152, 0.005079144611954689, 0.0182772446423769, 0.93213951587677, 0.0182772446423769, 0.0182772446423769, 0.0182772446423769, 0.07270112633705139, 0.07270112633705139, 0.6906607151031494, 0.07270112633705139, 0.036350563168525696, 0.13760000467300415, 0.13760000467300415, 0.13760000467300415, 0.13760000467300415, 0.5504000186920166, 0.5129268169403076, 0.18765614926815033, 0.13761450350284576, 0.037531230598688126, 0.11259368807077408, 0.006255204789340496, 0.03455265238881111, 0.10365795344114304, 0.17276325821876526, 0.621947705745697, 0.03455265238881111, 0.06805940717458725, 0.06805940717458725, 0.06805940717458725, 0.7486534714698792, 0.026186155155301094, 0.026186155155301094, 0.026186155155301094, 0.9165154695510864, 0.9737781286239624, 0.006323234643787146, 0.009484851732850075, 0.009484851732850075, 0.003161617321893573, 0.06421208381652832, 0.021404026076197624, 0.8133530020713806, 0.021404026076197624, 0.06421208381652832, 0.021404026076197624, 0.10106736421585083, 0.10106736421585083, 0.10106736421585083, 0.20213472843170166, 0.4042694568634033, 0.017104018479585648, 0.017104018479585648, 0.22235223650932312, 0.7354727983474731, 0.017104018479585648, 0.06781463325023651, 0.40688779950141907, 0.27125853300094604, 0.06781463325023651, 0.06781463325023651, 0.13562926650047302, 0.053481992334127426, 0.053481992334127426, 0.053481992334127426, 0.8022299408912659, 0.02138197049498558, 0.02138197049498558, 0.02138197049498558, 0.9194247126579285, 0.02138197049498558, 0.849186897277832, 0.07278744876384735, 0.024262482300400734, 0.024262482300400734, 0.024262482300400734, 0.9347526431083679, 0.019474012777209282, 0.019474012777209282, 0.019474012777209282, 0.019474012777209282, 0.04061935469508171, 0.04061935469508171, 0.28433549404144287, 0.08123870939016342, 0.4874322712421417, 0.7470129132270813, 0.08044754713773727, 0.05171627923846245, 0.09768630564212799, 0.017238760367035866, 0.010819009505212307, 0.33538931608200073, 0.3029322624206543, 0.09737108647823334, 0.2380182147026062, 0.19899950921535492, 0.19899950921535492, 0.19899950921535492, 0.19899950921535492, 0.19899950921535492, 0.030345851555466652, 0.060691703110933304, 0.7889921069145203, 0.030345851555466652, 0.060691703110933304, 0.030345851555466652, 0.40618857741355896, 0.36645272374153137, 0.22075465321540833, 0.0044150929898023605, 0.0044150929898023605, 0.0044150929898023605, 0.8250514268875122, 0.05500342696905136, 0.02750171348452568, 0.05500342696905136, 0.02750171348452568, 0.8370199799537659, 0.04650110751390457, 0.04650110751390457, 0.04650110751390457, 0.04650110751390457, 0.020526908338069916, 0.7389687299728394, 0.04105381667613983, 0.14368836581707, 0.020526908338069916, 0.17715300619602203, 0.17715300619602203, 0.17715300619602203, 0.17715300619602203, 0.17715300619602203, 0.35430601239204407, 0.8898740410804749, 0.005596692208200693, 0.06156361475586891, 0.022386768832802773, 0.016790077090263367, 0.15967389941215515, 0.1824844479560852, 0.6044797301292419, 0.011405277997255325, 0.02281055599451065, 0.011405277997255325, 0.5791987180709839, 0.07394026219844818, 0.1725272685289383, 0.09858701378107071, 0.049293506890535355, 0.03697013109922409, 0.47397440671920776, 0.20351442694664001, 0.005355642642825842, 0.002677821321412921, 0.310627281665802, 0.21576201915740967, 0.21576201915740967, 0.21576201915740967, 0.21576201915740967, 0.21576201915740967, 0.15810240805149078, 0.23715361952781677, 0.07905120402574539, 0.07905120402574539, 0.07905120402574539, 0.39525604248046875, 0.040109798312187195, 0.040109798312187195, 0.040109798312187195, 0.8824155330657959, 0.040109798312187195, 0.5127999186515808, 0.4294699430465698, 0.02563999779522419, 0.01922999881207943, 0.012819998897612095, 0.013854590244591236, 0.8728391528129578, 0.013854590244591236, 0.027709180489182472, 0.055418360978364944, 0.18430380523204803, 0.2948860824108124, 0.22116456925868988, 0.11058228462934494, 0.11058228462934494, 0.11058228462934494, 0.008003276772797108, 0.008003276772797108, 0.024009831249713898, 0.9523900151252747, 0.008003276772797108, 0.014074696227908134, 0.014074696227908134, 0.02814939245581627, 0.9430046081542969, 0.014074696227908134, 0.23142488300800323, 0.013613227754831314, 0.21781164407730103, 0.5173026919364929, 0.013613227754831314, 0.013613227754831314, 0.023213334381580353, 0.9285333752632141, 0.023213334381580353, 0.023213334381580353, 0.023213334381580353, 0.12402893602848053, 0.12402893602848053, 0.12402893602848053, 0.12402893602848053, 0.12402893602848053, 0.4961157441139221, 0.09560726583003998, 0.19121453166007996, 0.09560726583003998, 0.09560726583003998, 0.4780363142490387, 0.2783696949481964, 0.15658295154571533, 0.2783696949481964, 0.2087772637605667, 0.03479621186852455, 0.03479621186852455, 0.011834620498120785, 0.8994311690330505, 0.011834620498120785, 0.0591731034219265, 0.011834620498120785, 0.1323557049036026, 0.1323557049036026, 0.1323557049036026, 0.1323557049036026, 0.5294228196144104, 0.26723775267601013, 0.1547165960073471, 0.36569374799728394, 0.014065144583582878, 0.16878174245357513, 0.055977702140808105, 0.22391080856323242, 0.055977702140808105, 0.055977702140808105, 0.559777021408081, 0.19418901205062866, 0.19418901205062866, 0.19418901205062866, 0.19418901205062866, 0.19418901205062866, 0.09702402353286743, 0.09702402353286743, 0.09702402353286743, 0.09702402353286743, 0.19404804706573486, 0.48512011766433716, 0.1626676619052887, 0.241196870803833, 0.3758183717727661, 0.17108149826526642, 0.039264608174562454, 0.0028046148363500834, 0.008413844741880894, 0.20183363556861877, 0.20183363556861877, 0.20183363556861877, 0.20183363556861877, 0.20183363556861877, 0.05909537896513939, 0.05909537896513939, 0.11819075793027878, 0.05909537896513939, 0.05909537896513939, 0.6500491499900818, 0.030893899500370026, 0.5560901761054993, 0.030893899500370026, 0.030893899500370026, 0.3707267940044403, 0.16864052414894104, 0.16864052414894104, 0.16864052414894104, 0.16864052414894104, 0.3372810482978821, 0.023446764796972275, 0.023446764796972275, 0.7737432718276978, 0.023446764796972275, 0.14068059623241425, 0.4211682677268982, 0.34684446454048157, 0.04954920709133148, 0.02477460354566574, 0.09909841418266296, 0.07432381063699722, 0.0036428868770599365, 0.9107217192649841, 0.0400717556476593, 0.0036428868770599365, 0.0400717556476593, 0.20601892471313477, 0.20601892471313477, 0.20601892471313477, 0.20601892471313477, 0.20601892471313477, 0.16606132686138153, 0.16606132686138153, 0.16606132686138153, 0.16606132686138153, 0.4981839954853058, 0.19200366735458374, 0.1440027505159378, 0.33600643277168274, 0.048000916838645935, 0.048000916838645935, 0.24000458419322968, 0.49509161710739136, 0.023859838023781776, 0.178948774933815, 0.2803530991077423, 0.005964959505945444, 0.011929919011890888, 0.12032996118068695, 0.12032996118068695, 0.12032996118068695, 0.12032996118068695, 0.4813198447227478, 0.3150220513343811, 0.14226803183555603, 0.09145801514387131, 0.43696609139442444, 0.010162001475691795, 0.009612751193344593, 0.4710248112678528, 0.009612751193344593, 0.009612751193344593, 0.509475827217102, 0.9210746884346008, 0.05418086424469948, 0.012040192261338234, 0.006020096130669117, 0.006020096130669117, 0.03289496898651123, 0.888164222240448, 0.03289496898651123, 0.03289496898651123, 0.03289496898651123, 0.004350426606833935, 0.9657947421073914, 0.01740170642733574, 0.004350426606833935, 0.004350426606833935, 0.0062913899309933186, 0.9059601426124573, 0.04403972998261452, 0.031456951051950455, 0.0062913899309933186, 0.0062913899309933186, 0.8432313203811646, 0.0401538722217083, 0.0401538722217083, 0.0401538722217083, 0.0401538722217083, 0.16823557019233704, 0.16823557019233704, 0.16823557019233704, 0.16823557019233704, 0.16823557019233704, 0.16823557019233704, 0.13689753413200378, 0.13689753413200378, 0.13689753413200378, 0.13689753413200378, 0.13689753413200378, 0.13689753413200378, 0.41069260239601135, 0.18033356964588165, 0.18033356964588165, 0.18033356964588165, 0.18033356964588165, 0.3606671392917633, 0.2062852382659912, 0.2062852382659912, 0.2062852382659912, 0.2062852382659912, 0.2062852382659912, 0.2774396538734436, 0.1387198269367218, 0.1387198269367218, 0.1387198269367218, 0.1387198269367218, 0.2774396538734436, 0.9022857546806335, 0.0187976211309433, 0.0187976211309433, 0.0375952422618866, 0.0187976211309433, 0.0187976211309433, 0.033348992466926575, 0.011116330511868, 0.9337717890739441, 0.011116330511868, 0.011116330511868, 0.05471911281347275, 0.5471911430358887, 0.05471911281347275, 0.1094382256269455, 0.05471911281347275, 0.16415733098983765, 0.07012256234884262, 0.07012256234884262, 0.7012255787849426, 0.07012256234884262, 0.07012256234884262, 0.09048181027173996, 0.09048181027173996, 0.09048181027173996, 0.6333726644515991, 0.09048181027173996, 0.08976664394140244, 0.08976664394140244, 0.08976664394140244, 0.7181331515312195, 0.187871053814888, 0.187871053814888, 0.187871053814888, 0.187871053814888, 0.187871053814888, 0.187871053814888, 0.08605854213237762, 0.08605854213237762, 0.688468337059021, 0.08605854213237762, 0.08605854213237762, 0.7101167440414429, 0.04734111577272415, 0.04734111577272415, 0.04734111577272415, 0.04734111577272415, 0.14202335476875305, 0.9235641956329346, 0.0009742238325998187, 0.07209256291389465, 0.0019484476651996374, 0.0009742238325998187, 0.0009742238325998187, 0.07728897780179977, 0.07728897780179977, 0.6956008076667786, 0.07728897780179977, 0.031025253236293793, 0.8376818299293518, 0.031025253236293793, 0.031025253236293793, 0.031025253236293793, 0.013214068487286568, 0.9514129757881165, 0.013214068487286568, 0.013214068487286568, 0.013214068487286568, 0.1512259989976883, 0.1512259989976883, 0.18903250992298126, 0.07561299949884415, 0.264645516872406, 0.1512259989976883, 0.16626664996147156, 0.16626664996147156, 0.16626664996147156, 0.16626664996147156, 0.3325332999229431, 0.04535578936338425, 0.0907115787267685, 0.13606737554073334, 0.6803368926048279, 0.04535578936338425, 0.04535578936338425, 0.2130330353975296, 0.5260611772537231, 0.05651896819472313, 0.11303793638944626, 0.060866579413414, 0.017390452325344086, 0.013042839244008064, 0.15497195720672607, 0.05165731906890869, 0.6198878288269043, 0.10331463813781738, 0.05165731906890869, 0.24312740564346313, 0.3473248779773712, 0.06946497410535812, 0.1736624389886856, 0.03473248705267906, 0.10419745743274689, 0.4938258230686188, 0.2385145127773285, 0.18812412023544312, 0.06718718260526657, 0.010078078135848045, 0.003359359223395586, 0.04807538911700249, 0.8172816634178162, 0.04807538911700249, 0.04807538911700249, 0.04807538911700249, 0.8127461075782776, 0.05079663172364235, 0.05079663172364235, 0.05079663172364235, 0.05079663172364235, 0.1795271635055542, 0.1795271635055542, 0.1795271635055542, 0.1795271635055542, 0.3590543270111084, 0.03865298628807068, 0.07730597257614136, 0.6184477806091309, 0.21259142458438873, 0.01932649314403534, 0.6654351949691772, 0.2174624800682068, 0.05509049445390701, 0.040592994540929794, 0.020296497270464897, 0.001449749805033207, 0.001449749805033207, 0.18941879272460938, 0.09470939636230469, 0.03156979754567146, 0.03156979754567146, 0.6313959360122681, 0.03156979754567146, 0.13338932394981384, 0.07410518079996109, 0.6224835515022278, 0.13338932394981384, 0.014821036718785763, 0.14986518025398254, 0.14986518025398254, 0.14986518025398254, 0.14986518025398254, 0.14986518025398254, 0.2997303605079651, 0.18756411969661713, 0.3307051658630371, 0.10858975350856781, 0.009871795773506165, 0.3603205382823944, 0.017152316868305206, 0.7375496029853821, 0.017152316868305206, 0.017152316868305206, 0.20582780241966248, 0.04475260525941849, 0.8502994775772095, 0.04475260525941849, 0.04475260525941849, 0.04475260525941849, 0.023026324808597565, 0.023026324808597565, 0.023026324808597565, 0.9210529923439026, 0.8184344172477722, 0.028221875429153442, 0.11288750171661377, 0.028221875429153442, 0.028221875429153442, 0.09815874695777893, 0.24539686739444733, 0.6257619857788086, 0.012269843369722366, 0.012269843369722366, 0.014881081879138947, 0.9226270318031311, 0.04464324563741684, 0.014881081879138947, 0.014881081879138947, 0.018443703651428223, 0.2582118511199951, 0.22132444381713867, 0.46109259128570557, 0.018443703651428223, 0.036012109369039536, 0.036012109369039536, 0.036012109369039536, 0.8642905950546265, 0.036012109369039536, 0.21576201915740967, 0.21576201915740967, 0.21576201915740967, 0.21576201915740967, 0.21576201915740967, 0.04620976373553276, 0.04620976373553276, 0.04620976373553276, 0.8317757844924927, 0.04620976373553276, 0.02454003505408764, 0.83436119556427, 0.02454003505408764, 0.07362011075019836, 0.02454003505408764, 0.02454003505408764, 0.02576979622244835, 0.0515395924448967, 0.5669355392456055, 0.02576979622244835, 0.28346776962280273, 0.30603551864624023, 0.08037296682596207, 0.06800789386034012, 0.006182536017149687, 0.5378805994987488, 0.9549116492271423, 0.00958105269819498, 0.028743159025907516, 0.0031936843879520893, 0.0031936843879520893, 0.8344714641571045, 0.04391954839229584, 0.04391954839229584, 0.04391954839229584, 0.04391954839229584, 0.06603166460990906, 0.26412665843963623, 0.26412665843963623, 0.03301583230495453, 0.3301583230495453, 0.03301583230495453, 0.88299161195755, 0.03839093819260597, 0.03839093819260597, 0.03839093819260597, 0.03839093819260597], \"Term\": [\".easy\", \".easy\", \".easy\", \".easy\", \".easy\", \".easy\", \"able\", \"able\", \"able\", \"able\", \"able\", \"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"add\", \"add\", \"add\", \"add\", \"add\", \"add\", \"addition\", \"addition\", \"addition\", \"addition\", \"addition\", \"adult\", \"adult\", \"adult\", \"adult\", \"adult\", \"advertised\", \"advertised\", \"advertised\", \"advertised\", \"advertised\", \"advertised\", \"age\", \"age\", \"age\", \"age\", \"age\", \"alexa\", \"alexa\", \"alexa\", \"alexa\", \"alexa\", \"alternative\", \"alternative\", \"alternative\", \"alternative\", \"alternative\", \"amazon\", \"amazon\", \"amazon\", \"amazon\", \"amazon\", \"amplitude\", \"amplitude\", \"amplitude\", \"amplitude\", \"amplitude\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"anyone\", \"anyone\", \"anyone\", \"anyone\", \"anyone\", \"app\", \"app\", \"app\", \"app\", \"app\", \"appointment\", \"appointment\", \"appointment\", \"appointment\", \"appointment\", \"appropriate\", \"appropriate\", \"appropriate\", \"appropriate\", \"apps\", \"apps\", \"apps\", \"apps\", \"apps\", \"apps\", \"apps\", \"ask\", \"ask\", \"ask\", \"ask\", \"ask\", \"assistance\", \"assistance\", \"assistance\", \"assistance\", \"assistance\", \"assistance\", \"assistant\", \"assistant\", \"assistant\", \"assistant\", \"assistant\", \"assistant\", \"associate\", \"associate\", \"associate\", \"associate\", \"associate\", \"automation\", \"automation\", \"automation\", \"automation\", \"automation\", \"avid\", \"avid\", \"avid\", \"avid\", \"avid\", \"bag\", \"bag\", \"bag\", \"bag\", \"basis\", \"basis\", \"basis\", \"basis\", \"basis\", \"battery\", \"battery\", \"battery\", \"battery\", \"battery\", \"bed\", \"bed\", \"bed\", \"bed\", \"bed\", \"bed\", \"bedroom\", \"bedroom\", \"bedroom\", \"bedroom\", \"bedroom\", \"best\", \"best\", \"best\", \"best\", \"best\", \"better/faster\", \"better/faster\", \"better/faster\", \"better/faster\", \"better/faster\", \"biggest\", \"biggest\", \"biggest\", \"biggest\", \"biggest\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"box\", \"box\", \"box\", \"box\", \"box\", \"box\", \"break\", \"break\", \"break\", \"break\", \"break\", \"break\", \"bright\", \"bright\", \"bright\", \"bright\", \"bright\", \"bulb\", \"bulb\", \"bulb\", \"bulb\", \"bulb\", \"busy\", \"busy\", \"busy\", \"busy\", \"busy\", \"busy\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"call\", \"call\", \"call\", \"call\", \"call\", \"camera\", \"camera\", \"camera\", \"camera\", \"camera\", \"camera\", \"car\", \"car\", \"car\", \"car\", \"car\", \"card\", \"card\", \"card\", \"card\", \"card\", \"card\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"charge\", \"charge\", \"charge\", \"charge\", \"charge\", \"charger\", \"charger\", \"charger\", \"charger\", \"charger\", \"cheap\", \"cheap\", \"cheap\", \"cheap\", \"cheap\", \"cheap\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"christmas\", \"christmas\", \"christmas\", \"christmas\", \"christmas\", \"clarity\", \"clarity\", \"clarity\", \"clarity\", \"clarity\", \"clarity\", \"class\", \"class\", \"class\", \"class\", \"class\", \"clear\", \"clear\", \"clear\", \"clear\", \"clear\", \"clear\", \"code\", \"code\", \"code\", \"code\", \"code\", \"compact\", \"compact\", \"compact\", \"compact\", \"compact\", \"compare\", \"compare\", \"compare\", \"compare\", \"compare\", \"computer\", \"computer\", \"computer\", \"computer\", \"computer\", \"computer\", \"connects\", \"connects\", \"connects\", \"connects\", \"connects\", \"consumer\", \"consumer\", \"consumer\", \"consumer\", \"consumer\", \"couple\", \"couple\", \"couple\", \"couple\", \"couple\", \"couple\", \"cover\", \"cover\", \"cover\", \"cover\", \"cover\", \"credit\", \"credit\", \"credit\", \"credit\", \"credit\", \"customer\", \"customer\", \"customer\", \"customer\", \"customer\", \"dark\", \"dark\", \"dark\", \"dark\", \"darn\", \"darn\", \"darn\", \"darn\", \"darn\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"daughter\", \"daughter\", \"daughter\", \"daughter\", \"daughter\", \"daughter-in-law\", \"daughter-in-law\", \"daughter-in-law\", \"daughter-in-law\", \"daughter-in-law\", \"day\", \"day\", \"day\", \"day\", \"day\", \"decent\", \"decent\", \"decent\", \"decent\", \"decent\", \"decent\", \"decent\", \"desciples\", \"desciples\", \"desciples\", \"desciples\", \"desciples\", \"device\", \"device\", \"device\", \"device\", \"device\", \"difficult\", \"difficult\", \"difficult\", \"difficult\", \"difficult\", \"difficult\", \"difficult\", \"digital\", \"digital\", \"digital\", \"digital\", \"digital\", \"digital\", \"doorbell\", \"doorbell\", \"doorbell\", \"doorbell\", \"doorbell\", \"dot\", \"dot\", \"dot\", \"dot\", \"dot\", \"download\", \"download\", \"download\", \"download\", \"download\", \"durable\", \"durable\", \"durable\", \"durable\", \"durable\", \"e\", \"e\", \"e\", \"e\", \"e\", \"easier\", \"easier\", \"easier\", \"easier\", \"easier\", \"easier\", \"easy\", \"easy\", \"easy\", \"easy\", \"easy\", \"easy\", \"easy\", \"easy-to-use\", \"easy-to-use\", \"easy-to-use\", \"easy-to-use\", \"easy-to-use\", \"easy-to-use\", \"ebook\", \"ebook\", \"ebook\", \"ebook\", \"ebook\", \"echo\", \"echo\", \"echo\", \"echo\", \"echo\", \"educational\", \"educational\", \"educational\", \"educational\", \"educational\", \"efficient\", \"efficient\", \"efficient\", \"efficient\", \"efficient\", \"efficient\", \"electronic\", \"electronic\", \"electronic\", \"electronic\", \"electronic\", \"electronic\", \"email\", \"email\", \"email\", \"email\", \"email\", \"entertaining\", \"entertaining\", \"entertaining\", \"entertaining\", \"entertaining\", \"equipment\", \"equipment\", \"equipment\", \"equipment\", \"equipment\", \"equipment\", \"evening\", \"evening\", \"evening\", \"evening\", \"evening\", \"evening\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"facebook\", \"facebook\", \"facebook\", \"facebook\", \"facebook\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fair\", \"fair\", \"fair\", \"fair\", \"fair\", \"family\", \"family\", \"family\", \"family\", \"family\", \"family\", \"feachers\", \"feachers\", \"feachers\", \"feachers\", \"feachers\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"fire\", \"fire\", \"fire\", \"fire\", \"fire\", \"fire\", \"fit\", \"fit\", \"fit\", \"fit\", \"fit\", \"flight\", \"flight\", \"flight\", \"flight\", \"flight\", \"flight\", \"forward\", \"forward\", \"forward\", \"forward\", \"forward\", \"free\", \"free\", \"free\", \"free\", \"free\", \"friend\", \"friend\", \"friend\", \"friend\", \"friend\", \"fun\", \"fun\", \"fun\", \"fun\", \"fun\", \"fun\", \"functionality\", \"functionality\", \"functionality\", \"functionality\", \"functionality\", \"functionality\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"geek\", \"geek\", \"geek\", \"geek\", \"geek\", \"geek\", \"geek\", \"gift\", \"gift\", \"gift\", \"gift\", \"gift\", \"glare\", \"glare\", \"glare\", \"glare\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"goodexcellent\", \"goodexcellent\", \"goodexcellent\", \"goodexcellent\", \"goodexcellent\", \"google\", \"google\", \"google\", \"google\", \"google\", \"grand\", \"grand\", \"grand\", \"grand\", \"grand\", \"granddaughter\", \"granddaughter\", \"granddaughter\", \"granddaughter\", \"granddaughter\", \"grandkids\", \"grandkids\", \"grandkids\", \"grandkids\", \"grandkids\", \"grandkids\", \"grandson\", \"grandson\", \"grandson\", \"grandson\", \"grandson\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great..i\", \"great..i\", \"great..i\", \"great..i\", \"great..i\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"happy\", \"happy\", \"happy\", \"happy\", \"happy\", \"hard\", \"hard\", \"hard\", \"hard\", \"hard\", \"hard\", \"hd\", \"hd\", \"hd\", \"hd\", \"hd\", \"headphone\", \"headphone\", \"headphone\", \"headphone\", \"headphone\", \"headphone\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"helpful\", \"helpful\", \"helpful\", \"helpful\", \"helpful\", \"hitch\", \"hitch\", \"hitch\", \"hitch\", \"hitch\", \"home\", \"home\", \"home\", \"home\", \"home\", \"hope\", \"hope\", \"hope\", \"hope\", \"hope\", \"hope\", \"house\", \"house\", \"house\", \"house\", \"house\", \"hub\", \"hub\", \"hub\", \"hub\", \"hub\", \"hue\", \"hue\", \"hue\", \"hue\", \"hue\", \"hulu\", \"hulu\", \"hulu\", \"hulu\", \"hulu\", \"hulu\", \"in-law\", \"in-law\", \"in-law\", \"in-law\", \"in-law\", \"inch\", \"inch\", \"inch\", \"inch\", \"inch\", \"inch\", \"information\", \"information\", \"information\", \"information\", \"information\", \"informative\", \"informative\", \"informative\", \"informative\", \"informative\", \"instruction\", \"instruction\", \"instruction\", \"instruction\", \"instruction\", \"instruction\", \"instruction\", \"integration\", \"integration\", \"integration\", \"integration\", \"integration\", \"internet\", \"internet\", \"internet\", \"internet\", \"internet\", \"internet\", \"intuitive\", \"intuitive\", \"intuitive\", \"intuitive\", \"intuitive\", \"intuitive\", \"ipad\", \"ipad\", \"ipad\", \"ipad\", \"ipad\", \"ipad\", \"ipad\", \"iphone\", \"iphone\", \"iphone\", \"iphone\", \"iphone\", \"it..glad\", \"it..glad\", \"it..glad\", \"it..glad\", \"it..glad\", \"it..my\", \"it..my\", \"it..my\", \"it..my\", \"it..my\", \"item\", \"item\", \"item\", \"item\", \"item\", \"item\", \"it\\u201a\\u00e4\\u00f4s\", \"it\\u201a\\u00e4\\u00f4s\", \"it\\u201a\\u00e4\\u00f4s\", \"it\\u201a\\u00e4\\u00f4s\", \"it\\u201a\\u00e4\\u00f4s\", \"junk\", \"junk\", \"junk\", \"junk\", \"keyboard\", \"keyboard\", \"keyboard\", \"keyboard\", \"keyboard\", \"kid\", \"kid\", \"kid\", \"kid\", \"kid\", \"kid\", \"kindle\", \"kindle\", \"kindle\", \"kindle\", \"kindle\", \"kitchen\", \"kitchen\", \"kitchen\", \"kitchen\", \"kitchen\", \"knowledgeable\", \"knowledgeable\", \"knowledgeable\", \"knowledgeable\", \"knowledgeable\", \"last\", \"last\", \"last\", \"last\", \"last\", \"last\", \"law\", \"law\", \"law\", \"law\", \"law\", \"library\", \"library\", \"library\", \"library\", \"library\", \"life\", \"life\", \"life\", \"life\", \"life\", \"light\", \"light\", \"light\", \"light\", \"light\", \"lightweight\", \"lightweight\", \"lightweight\", \"lightweight\", \"lightweight\", \"list\", \"list\", \"list\", \"list\", \"list\", \"listen\", \"listen\", \"listen\", \"listen\", \"listen\", \"little\", \"little\", \"little\", \"little\", \"little\", \"longer\", \"longer\", \"longer\", \"longer\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"lucky\", \"lucky\", \"lucky\", \"lucky\", \"lucky\", \"lucky\", \"lyric\", \"lyric\", \"lyric\", \"lyric\", \"lyric\", \"magazine\", \"magazine\", \"magazine\", \"magazine\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"man\", \"man\", \"man\", \"man\", \"man\", \"manual\", \"manual\", \"manual\", \"manual\", \"manual\", \"manual\", \"member\", \"member\", \"member\", \"member\", \"member\", \"member\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"menu\", \"menu\", \"menu\", \"menu\", \"menu\", \"mess\", \"mess\", \"mess\", \"mess\", \"mess\", \"mini\", \"mini\", \"mini\", \"mini\", \"mini\", \"mini\", \"mini\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"money\", \"money\", \"money\", \"money\", \"money\", \"money\", \"morning\", \"morning\", \"morning\", \"morning\", \"morning\", \"movie\", \"movie\", \"movie\", \"movie\", \"movie\", \"movie\", \"movie\", \"much\", \"much\", \"much\", \"much\", \"much\", \"music\", \"music\", \"music\", \"music\", \"music\", \"natural\", \"natural\", \"natural\", \"natural\", \"natural\", \"natural\", \"navigate\", \"navigate\", \"navigate\", \"navigate\", \"navigate\", \"navigate\", \"need\", \"need\", \"need\", \"need\", \"need\", \"netflix\", \"netflix\", \"netflix\", \"netflix\", \"netflix\", \"netflix\", \"network\", \"network\", \"network\", \"network\", \"network\", \"new\", \"new\", \"new\", \"new\", \"new\", \"news\", \"news\", \"news\", \"news\", \"news\", \"next\", \"next\", \"next\", \"next\", \"next\", \"nexus\", \"nexus\", \"nexus\", \"nexus\", \"nexus\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"night\", \"night\", \"night\", \"night\", \"night\", \"nook\", \"nook\", \"nook\", \"nook\", \"oasis\", \"oasis\", \"oasis\", \"oasis\", \"old\", \"old\", \"old\", \"old\", \"old\", \"online\", \"online\", \"online\", \"online\", \"online\", \"online\", \"owner\", \"owner\", \"owner\", \"owner\", \"owner\", \"page\", \"page\", \"page\", \"page\", \"page\", \"pair\", \"pair\", \"pair\", \"pair\", \"pair\", \"pair\", \"paper\", \"paper\", \"paper\", \"paper\", \"paperwhite\", \"paperwhite\", \"paperwhite\", \"paperwhite\", \"paperwhite\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"parental\", \"parental\", \"parental\", \"parental\", \"parental\", \"people\", \"people\", \"people\", \"people\", \"people\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"phone\", \"phone\", \"phone\", \"phone\", \"phone\", \"phooey\", \"phooey\", \"phooey\", \"phooey\", \"phooey\", \"photo\", \"photo\", \"photo\", \"photo\", \"photo\", \"photo\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"pleased\", \"pleased\", \"pleased\", \"pleased\", \"pleased\", \"plenty\", \"plenty\", \"plenty\", \"plenty\", \"plenty\", \"portable\", \"portable\", \"portable\", \"portable\", \"portable\", \"pre\", \"pre\", \"pre\", \"pre\", \"pre\", \"pre\", \"price\", \"price\", \"price\", \"price\", \"price\", \"prime\", \"prime\", \"prime\", \"prime\", \"prime\", \"prime\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"product\", \"product\", \"product\", \"product\", \"product\", \"punch..\", \"punch..\", \"punch..\", \"punch..\", \"punch..\", \"purchased\", \"purchased\", \"purchased\", \"purchased\", \"purchased\", \"purchased\", \"purse\", \"purse\", \"purse\", \"purse\", \"purse\", \"quality\", \"quality\", \"quality\", \"quality\", \"quality\", \"question\", \"question\", \"question\", \"question\", \"question\", \"quick\", \"quick\", \"quick\", \"quick\", \"quick\", \"quick\", \"read\", \"read\", \"read\", \"read\", \"read\", \"reader\", \"reader\", \"reader\", \"reader\", \"reader\", \"reading\", \"reading\", \"reading\", \"reading\", \"reading\", \"reading\", \"recipe\", \"recipe\", \"recipe\", \"recipe\", \"recipe\", \"recipient\", \"recipient\", \"recipient\", \"recipient\", \"recipient\", \"recipient\", \"recognition\", \"recognition\", \"recognition\", \"recognition\", \"recognition\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"room\", \"room\", \"room\", \"room\", \"room\", \"s2\", \"s2\", \"s2\", \"s2\", \"s2\", \"sale\", \"sale\", \"sale\", \"sale\", \"sale\", \"satisfied\", \"satisfied\", \"satisfied\", \"satisfied\", \"satisfied\", \"saver\", \"saver\", \"saver\", \"saver\", \"saver\", \"savvy\", \"savvy\", \"savvy\", \"savvy\", \"savvy\", \"savvy\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screenlike\", \"screenlike\", \"screenlike\", \"screenlike\", \"screenlike\", \"sd\", \"sd\", \"sd\", \"sd\", \"sd\", \"sd\", \"security\", \"security\", \"security\", \"security\", \"security\", \"senior\", \"senior\", \"senior\", \"senior\", \"senior\", \"service\", \"service\", \"service\", \"service\", \"service\", \"setup\", \"setup\", \"setup\", \"setup\", \"setup\", \"setup\", \"show\", \"show\", \"show\", \"show\", \"show\", \"shy\", \"shy\", \"shy\", \"shy\", \"shy\", \"siri\", \"siri\", \"siri\", \"siri\", \"siri\", \"sister\", \"sister\", \"sister\", \"sister\", \"sister\", \"sister\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"slot\", \"slot\", \"slot\", \"slot\", \"slot\", \"small\", \"small\", \"small\", \"small\", \"small\", \"smart\", \"smart\", \"smart\", \"smart\", \"smart\", \"son\", \"son\", \"son\", \"son\", \"son\", \"song\", \"song\", \"song\", \"song\", \"song\", \"sound\", \"sound\", \"sound\", \"sound\", \"sound\", \"speaker\", \"speaker\", \"speaker\", \"speaker\", \"speaker\", \"speaker\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"spouse\", \"spouse\", \"spouse\", \"spouse\", \"spouse\", \"spouse\", \"squad\", \"squad\", \"squad\", \"squad\", \"squad\", \"squad\", \"squad\", \"stair\", \"stair\", \"stair\", \"stair\", \"stair\", \"stand/cover\", \"stand/cover\", \"stand/cover\", \"stand/cover\", \"stand/cover\", \"steal\", \"steal\", \"steal\", \"steal\", \"steal\", \"steal\", \"storage\", \"storage\", \"storage\", \"storage\", \"storage\", \"storage\", \"store\", \"store\", \"store\", \"store\", \"store\", \"stream\", \"stream\", \"stream\", \"stream\", \"stream\", \"stream\", \"subscription\", \"subscription\", \"subscription\", \"subscription\", \"subscription\", \"sun\", \"sun\", \"sun\", \"sun\", \"sun\", \"sunlight\", \"sunlight\", \"sunlight\", \"sunlight\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"swipe\", \"swipe\", \"swipe\", \"swipe\", \"swipe\", \"tab\", \"tab\", \"tab\", \"tab\", \"tab\", \"tab\", \"tablet\", \"tablet\", \"tablet\", \"tablet\", \"tablet\", \"tablet\", \"tag\", \"tag\", \"tag\", \"tag\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"tap\", \"tap\", \"tap\", \"tap\", \"tap\", \"tech\", \"tech\", \"tech\", \"tech\", \"tech\", \"tech\", \"teenager\", \"teenager\", \"teenager\", \"teenager\", \"teenager\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"third\", \"third\", \"third\", \"third\", \"third\", \"thought\", \"thought\", \"thought\", \"thought\", \"thought\", \"thought\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"timer\", \"timer\", \"timer\", \"timer\", \"timer\", \"toddler\", \"toddler\", \"toddler\", \"toddler\", \"toddler\", \"transfer\", \"transfer\", \"transfer\", \"transfer\", \"transfer\", \"upgrade\", \"upgrade\", \"upgrade\", \"upgrade\", \"upgrade\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"useful\", \"useful\", \"useful\", \"useful\", \"useful\", \"useful\", \"version\", \"version\", \"version\", \"version\", \"version\", \"vibrant\", \"vibrant\", \"vibrant\", \"vibrant\", \"vibrant\", \"vibrant\", \"video\", \"video\", \"video\", \"video\", \"video\", \"voice\", \"voice\", \"voice\", \"voice\", \"voice\", \"volume\", \"volume\", \"volume\", \"volume\", \"volume\", \"voyage\", \"voyage\", \"voyage\", \"voyage\", \"warranty\", \"warranty\", \"warranty\", \"warranty\", \"warranty\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"weather\", \"weather\", \"weather\", \"weather\", \"weather\", \"week\", \"week\", \"week\", \"week\", \"week\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"well.this\", \"well.this\", \"well.this\", \"well.this\", \"well.this\", \"white\", \"white\", \"white\", \"white\", \"white\", \"whole\", \"whole\", \"whole\", \"whole\", \"whole\", \"whole\", \"wifi\", \"wifi\", \"wifi\", \"wifi\", \"wifi\", \"work\", \"work\", \"work\", \"work\", \"work\", \"year\", \"year\", \"year\", \"year\", \"year\", \"young\", \"young\", \"young\", \"young\", \"young\", \"youtube\", \"youtube\", \"youtube\", \"youtube\", \"youtube\", \"youtube\", \"yr\", \"yr\", \"yr\", \"yr\", \"yr\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 3, 7, 5, 2, 1, 6]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el3380829515342669527945934987\", ldavis_el3380829515342669527945934987_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el3380829515342669527945934987\", ldavis_el3380829515342669527945934987_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el3380829515342669527945934987\", ldavis_el3380829515342669527945934987_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "3     -0.190422  0.057301       1        1  31.551426\n",
       "2     -0.055965 -0.141186       2        1  23.711569\n",
       "6     -0.033422  0.045736       3        1  16.301682\n",
       "4      0.037463  0.083816       4        1  13.258450\n",
       "1      0.027185 -0.078588       5        1   8.192840\n",
       "0      0.110175  0.015137       6        1   3.560501\n",
       "5      0.104985  0.017785       7        1   3.423528, topic_info=       Term         Freq        Total Category  logprob  loglift\n",
       "23   tablet  1026.000000  1026.000000  Default  30.0000  30.0000\n",
       "165    work   323.000000   323.000000  Default  29.0000  29.0000\n",
       "35     echo   434.000000   434.000000  Default  28.0000  28.0000\n",
       "86     book   313.000000   313.000000  Default  27.0000  27.0000\n",
       "12    great  1143.000000  1143.000000  Default  26.0000  26.0000\n",
       "..      ...          ...          ...      ...      ...      ...\n",
       "67    thing     2.555932   230.011276   Topic7  -6.5508  -1.1252\n",
       "65   screen     2.605432   356.555206   Topic7  -6.5317  -1.5444\n",
       "154    easy     2.315232   598.971924   Topic7  -6.6497  -2.1812\n",
       "711    inch     2.006436    19.134764   Topic7  -6.7929   1.1194\n",
       "68     good     2.044923   475.729065   Topic7  -6.7739  -2.0750\n",
       "\n",
       "[403 rows x 6 columns], token_table=      Topic      Freq   Term\n",
       "term                        \n",
       "2278      1  0.184544  .easy\n",
       "2278      2  0.184544  .easy\n",
       "2278      3  0.184544  .easy\n",
       "2278      4  0.184544  .easy\n",
       "2278      5  0.184544  .easy\n",
       "...     ...       ...    ...\n",
       "405       1  0.882992     yr\n",
       "405       2  0.038391     yr\n",
       "405       3  0.038391     yr\n",
       "405       4  0.038391     yr\n",
       "405       5  0.038391     yr\n",
       "\n",
       "[1656 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 3, 7, 5, 2, 1, 6])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus_sets[0], dictionary)\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.4478553981780152\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score using c_v\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=extractedData, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "\n",
    "**Summary of Top Topics**\n",
    "\n",
    "| Topic No. | Topic Name | Topic Description | Top Words |\n",
    "| :--- | :---: | :---: | :---: |\n",
    "| 1 | Buying Product as a Gift | Purchasing Tablet. Its a great  gift to a child during christmas | Tablet,Easy to Use, Great for Kids |\n",
    "| 2 | Product Review | This is about product review on Amazon Alexa | Alexa, Echo, Music, Sound, Great  |\n",
    "| 3  |Product Features | there are talks about Tablet screen , battery life,Prime movie | Tablet,Screen, Battery,Prime,Movie |\n",
    "| 4 | Amazon Book Review | Amazon Book Review | Book, Read, Light, Easy, Reader |\n",
    "| 5 | Product and Customer Service Experience | Product and Customer Service Experience on Echo,Camera | Great, Product, Device |\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
